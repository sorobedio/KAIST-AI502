{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "KAIST_AI605_ass1_20205677.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d6147df7b8c54b3a9c0f301c2148c279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ccdec5127b9a4f6c84681b441ab7e156",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2a9a83bfe45d4f659dad51686adaf423",
              "IPY_MODEL_8027dc80b6f445b08d9f16114e91430e",
              "IPY_MODEL_fcba449ccd6146d9aa3bee46dd3452ca"
            ]
          }
        },
        "ccdec5127b9a4f6c84681b441ab7e156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a9a83bfe45d4f659dad51686adaf423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e9c00fe6f37244009514eabc1129257c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c829fcd3735347198c07621d81995217"
          }
        },
        "8027dc80b6f445b08d9f16114e91430e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7edd3c1cd5d046dbaa0cea623f0c035b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2590,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2590,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1939851c46464dbebfd307afe625ae94"
          }
        },
        "fcba449ccd6146d9aa3bee46dd3452ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f3715cb85af64652b35f04d5923c91d0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9.13k/? [00:00&lt;00:00, 156kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fce7bad3af0c4dd6bf5e3c26b06f9cee"
          }
        },
        "e9c00fe6f37244009514eabc1129257c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c829fcd3735347198c07621d81995217": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7edd3c1cd5d046dbaa0cea623f0c035b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1939851c46464dbebfd307afe625ae94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3715cb85af64652b35f04d5923c91d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fce7bad3af0c4dd6bf5e3c26b06f9cee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e506e20a99e4903abd1d92695d8abd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_772355f889454cb4927349449c481d99",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a04fad0d589045109bf2170b25642fd0",
              "IPY_MODEL_14997b3558414efb84a2a20038f4627b",
              "IPY_MODEL_4cb6d94b13334eb0b94f944a02ef7368"
            ]
          }
        },
        "772355f889454cb4927349449c481d99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a04fad0d589045109bf2170b25642fd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_12a8359f44644382aa12a7acebb8a530",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b845dadf859142dfbfb8f7a8c77a548d"
          }
        },
        "14997b3558414efb84a2a20038f4627b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dca5aa97c6574d54afa684e51eea005a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1173,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1173,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25314c7d27da4c8eb43dc08b8008b374"
          }
        },
        "4cb6d94b13334eb0b94f944a02ef7368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f0ed32d3d6484e9f800f1a068146f6ab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.99k/? [00:00&lt;00:00, 149kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5392db62675f4448ab22c7b4948841ee"
          }
        },
        "12a8359f44644382aa12a7acebb8a530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b845dadf859142dfbfb8f7a8c77a548d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dca5aa97c6574d54afa684e51eea005a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "25314c7d27da4c8eb43dc08b8008b374": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0ed32d3d6484e9f800f1a068146f6ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5392db62675f4448ab22c7b4948841ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35b838c5350149fb8fcd8b0e623dc897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_acad2c3d03ca44868181b59be4e637d0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_05465c7d7ddb4a828330cac3e3040e62",
              "IPY_MODEL_23de16b80ed5423ab43c7cfe90453e50",
              "IPY_MODEL_0119f3e02b5747c98ddce8d75974476e"
            ]
          }
        },
        "acad2c3d03ca44868181b59be4e637d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "05465c7d7ddb4a828330cac3e3040e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2d60d67cf9e944c38fb664260cad2104",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9019245d109469a9f32b49b550d40af"
          }
        },
        "23de16b80ed5423ab43c7cfe90453e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_11f9e3bf79e94af38988ffef7fb709c8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 6372817,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6372817,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9f75e0b6468430aa4a01f5b87f4d09a"
          }
        },
        "0119f3e02b5747c98ddce8d75974476e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1002a535c62449c99a2d3ec6ed28bd34",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6.37M/6.37M [00:01&lt;00:00, 7.27MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9be73cebf3314417b253ae05edca863e"
          }
        },
        "2d60d67cf9e944c38fb664260cad2104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9019245d109469a9f32b49b550d40af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11f9e3bf79e94af38988ffef7fb709c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9f75e0b6468430aa4a01f5b87f4d09a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1002a535c62449c99a2d3ec6ed28bd34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9be73cebf3314417b253ae05edca863e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "578d24fc876446c08b4a02942b47af39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cbf94dc724964c3998dac2c631e1174a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_60ab1c0d01214984984cda8ba163b802",
              "IPY_MODEL_2f61a0b328a245038254f4a14d6fc074",
              "IPY_MODEL_5a2ab4057dd14135abce19387f16a9d1"
            ]
          }
        },
        "cbf94dc724964c3998dac2c631e1174a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60ab1c0d01214984984cda8ba163b802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_568912e89ea0457f8d68b5fcf70cfedf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d884e88a4f6b46f3a0e0d2111df01179"
          }
        },
        "2f61a0b328a245038254f4a14d6fc074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7571d935a33e4d149cb3beaeee8808c2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 789539,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 789539,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_04f8f6f470574996b6ef4b76361f2465"
          }
        },
        "5a2ab4057dd14135abce19387f16a9d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2df56543ea24400383f9706dc75c428b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 790k/790k [00:00&lt;00:00, 1.23MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c0d299ed63524685b7fc1b1de34bd3ca"
          }
        },
        "568912e89ea0457f8d68b5fcf70cfedf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d884e88a4f6b46f3a0e0d2111df01179": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7571d935a33e4d149cb3beaeee8808c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "04f8f6f470574996b6ef4b76361f2465": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2df56543ea24400383f9706dc75c428b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c0d299ed63524685b7fc1b1de34bd3ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "05a99493561549bca88bf07127be5c0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8edbb1c68a4547c59e03cfdd257fb092",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2ea87a6e0367432297b61c6b9a93f3a2",
              "IPY_MODEL_3ac9c9d0a4344733802174ec75a1a964",
              "IPY_MODEL_6a26fc3782db488c8cfccaa8807ed745"
            ]
          }
        },
        "8edbb1c68a4547c59e03cfdd257fb092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ea87a6e0367432297b61c6b9a93f3a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bea0748076564195b77d29c5ca294461",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aeffd49d353c403c989d0ef8e15e1866"
          }
        },
        "3ac9c9d0a4344733802174ec75a1a964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_465bca1f8a924713af1fe441287f0781",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_acada50ce90845c982a1d04e66001c15"
          }
        },
        "6a26fc3782db488c8cfccaa8807ed745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5129bff5671e4ba5af664e1c43099f84",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6976/0 [00:01&lt;00:00, 7785.24 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6d04f266a8a487d9e03a9439deba64c"
          }
        },
        "bea0748076564195b77d29c5ca294461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aeffd49d353c403c989d0ef8e15e1866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "465bca1f8a924713af1fe441287f0781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "acada50ce90845c982a1d04e66001c15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5129bff5671e4ba5af664e1c43099f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6d04f266a8a487d9e03a9439deba64c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf259cb5685a4765b931a4276f22ba26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9760d62e16be4458b716f8629deecb83",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_10128fb0845447d2a69d364559d8a423",
              "IPY_MODEL_ac933984dbb642c490c9f6fdb247582b",
              "IPY_MODEL_99479e802d4a4552b945655628dc216d"
            ]
          }
        },
        "9760d62e16be4458b716f8629deecb83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10128fb0845447d2a69d364559d8a423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_224d0a77346143dca2dd4f707a07a16f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e3541830ce204d0f9569a491e34f9698"
          }
        },
        "ac933984dbb642c490c9f6fdb247582b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b3804bb1053844058f59c280d0e6d7a8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_05b5b66f019c417593494e54f00befd4"
          }
        },
        "99479e802d4a4552b945655628dc216d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_10063088a65f4e57a6c8242505df144f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/0 [00:01&lt;00:00,  1.33s/ examples]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1449b42aa4c546f58ac9c412490a8892"
          }
        },
        "224d0a77346143dca2dd4f707a07a16f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e3541830ce204d0f9569a491e34f9698": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3804bb1053844058f59c280d0e6d7a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "05b5b66f019c417593494e54f00befd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10063088a65f4e57a6c8242505df144f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1449b42aa4c546f58ac9c412490a8892": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0ccb9b989d048eb953b9348d2fd516e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_da516bb89f3b4df2bbe7f1e982c96931",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b3e88b7ddc044147a60bf5c57c3a8452",
              "IPY_MODEL_ab1c55fb1a26498f91d3ecddd84e6a71",
              "IPY_MODEL_de6f2fc2e8644c41a42408e525c5c398"
            ]
          }
        },
        "da516bb89f3b4df2bbe7f1e982c96931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3e88b7ddc044147a60bf5c57c3a8452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9717494595ab48cd9b3c27d0033bc206",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22f44086502645f593454462638de632"
          }
        },
        "ab1c55fb1a26498f91d3ecddd84e6a71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5c741b258f6141c7976d5d9e7d1d9577",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_676d3e7e84fb45d09a9737a32b1c6126"
          }
        },
        "de6f2fc2e8644c41a42408e525c5c398": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0f2a57ae8d614e1ab6383f86a5e60377",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1070/0 [00:01&lt;00:00, 1058.06 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a5ca10c22a0c482fb4a2cd75723b9ca5"
          }
        },
        "9717494595ab48cd9b3c27d0033bc206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22f44086502645f593454462638de632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c741b258f6141c7976d5d9e7d1d9577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "676d3e7e84fb45d09a9737a32b1c6126": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f2a57ae8d614e1ab6383f86a5e60377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a5ca10c22a0c482fb4a2cd75723b9ca5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd4056b8c69f478ca281175b9fd67fbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_16d906893024425686aabb2a3c74ede9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_134cba1d68d840c1af1a470b6b959318",
              "IPY_MODEL_8136a5bd92e642d4a162c6ec02444133",
              "IPY_MODEL_09e509f9b02b4ff0a4d906206c567c58"
            ]
          }
        },
        "16d906893024425686aabb2a3c74ede9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "134cba1d68d840c1af1a470b6b959318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4e1cc8c0a73a486489d133c072d02dc5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb428fa22df644c7b0f822453a313665"
          }
        },
        "8136a5bd92e642d4a162c6ec02444133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_055c39afe6694bf9b3a04e9a83de6a75",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d7bfd4df44c4276a9486e46fa199074"
          }
        },
        "09e509f9b02b4ff0a4d906206c567c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_13e9053c7c5a427585da9892080a0f2a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 59.48it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c92f2f444224213a447c204a6399ac0"
          }
        },
        "4e1cc8c0a73a486489d133c072d02dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb428fa22df644c7b0f822453a313665": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "055c39afe6694bf9b3a04e9a83de6a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d7bfd4df44c4276a9486e46fa199074": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13e9053c7c5a427585da9892080a0f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c92f2f444224213a447c204a6399ac0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "762c5543e56f40e3bbd39dc576069cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_180fd0aaaddd4f3c974f752c5c64cc38",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3c711a549bd541438a374a71ece88158",
              "IPY_MODEL_b2c58741b3ac407bb23642a6cee00100",
              "IPY_MODEL_62c1473f2ba647808e51c7b095d6f216"
            ]
          }
        },
        "180fd0aaaddd4f3c974f752c5c64cc38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c711a549bd541438a374a71ece88158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_524f30a5d0ce42e1b8d3cb78599606c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c6b657a4548e48988b685939816759f0"
          }
        },
        "b2c58741b3ac407bb23642a6cee00100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_684ac74a543649b4a9db7e1763bb83f0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_29dc6609ddbd4731bb02b9230c7e3c37"
          }
        },
        "62c1473f2ba647808e51c7b095d6f216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b03436550ccf4a9c9b0f97800ff76df6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 48.30it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_92505e40939f48dd93857144cdd1e8f1"
          }
        },
        "524f30a5d0ce42e1b8d3cb78599606c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c6b657a4548e48988b685939816759f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "684ac74a543649b4a9db7e1763bb83f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "29dc6609ddbd4731bb02b9230c7e3c37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b03436550ccf4a9c9b0f97800ff76df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "92505e40939f48dd93857144cdd1e8f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "138336a4a3954b4da1c89174f61b2387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bd92fe9ab32e45ad873522c8d3009aa7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c5b3f7c9155c43d6a7fd677902269524",
              "IPY_MODEL_11963c590cb04622aaf95f96a5729bd2",
              "IPY_MODEL_445288e609da4a81ae57beead2050433"
            ]
          }
        },
        "bd92fe9ab32e45ad873522c8d3009aa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5b3f7c9155c43d6a7fd677902269524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bd528ae35f054690846520154e21fe59",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9fda14b143574334baca91e28c1979e4"
          }
        },
        "11963c590cb04622aaf95f96a5729bd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a891dfad1c9b486aa91478540a15c80d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_78bed69b9299479686530ca4c85d5617"
          }
        },
        "445288e609da4a81ae57beead2050433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b3da00daef95433f9d43090cfa093367",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 54.31it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d63708a742b4b349f86010e03f836f1"
          }
        },
        "bd528ae35f054690846520154e21fe59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9fda14b143574334baca91e28c1979e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a891dfad1c9b486aa91478540a15c80d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "78bed69b9299479686530ca4c85d5617": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3da00daef95433f9d43090cfa093367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d63708a742b4b349f86010e03f836f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "17c1527582dd4716b9fad7ed7a4474e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e99fcc27e3f54c55a66b70fd5d5a270b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e4e30c51be97429b817f20e8f5704e0e",
              "IPY_MODEL_a2ffeb6e121f4fcfb8dc8e119cdec2f9",
              "IPY_MODEL_ee4cff9d698147a7970b7d4e2c4854b9"
            ]
          }
        },
        "e99fcc27e3f54c55a66b70fd5d5a270b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4e30c51be97429b817f20e8f5704e0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5906c4ea645049d88e5dd6069ff288e3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4fdf152c5e3a41f1990c8c30c231036d"
          }
        },
        "a2ffeb6e121f4fcfb8dc8e119cdec2f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2029126ef59f4e9e816398f789c2db5a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ce461a946af24591a701475774bfe1bb"
          }
        },
        "ee4cff9d698147a7970b7d4e2c4854b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a71837a02b454912a5ae47f2635da3a5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 50.13it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_15b7e82f57ad47aa93a6dc0587e2b6c8"
          }
        },
        "5906c4ea645049d88e5dd6069ff288e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4fdf152c5e3a41f1990c8c30c231036d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2029126ef59f4e9e816398f789c2db5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ce461a946af24591a701475774bfe1bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a71837a02b454912a5ae47f2635da3a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "15b7e82f57ad47aa93a6dc0587e2b6c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff0f0422b49f4aa9b0632a0573d30b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5471e625cda04393bc4bfbb9f904eb5d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3c8f00b706c743a89b2dab5b2851d4b2",
              "IPY_MODEL_b6434c2ded094f8f84ee2ee495bcd4a8",
              "IPY_MODEL_ebe4053d9b2c4971918ef75a0251c2ff"
            ]
          }
        },
        "5471e625cda04393bc4bfbb9f904eb5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c8f00b706c743a89b2dab5b2851d4b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_401e1dd788914e61be8942864c72e90f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_965d8a17c0b646cbad7d290ad5b654d3"
          }
        },
        "b6434c2ded094f8f84ee2ee495bcd4a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_61ab58a234114f459aec31ad33094f61",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_19ea265e8f6247f1bf2912d9abab1d15"
          }
        },
        "ebe4053d9b2c4971918ef75a0251c2ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d09769c62a8b4cf5a8c565ec5ab7e263",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 52.36it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9f2cc3ccd387455796011c91b6a594e6"
          }
        },
        "401e1dd788914e61be8942864c72e90f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "965d8a17c0b646cbad7d290ad5b654d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61ab58a234114f459aec31ad33094f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "19ea265e8f6247f1bf2912d9abab1d15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d09769c62a8b4cf5a8c565ec5ab7e263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9f2cc3ccd387455796011c91b6a594e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76ed78523e9f49d9aa33597d12814e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_880c591e25e049a1b43b131cbcaeece4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bd7fa21cef2a40a6895542fb5f9efc5c",
              "IPY_MODEL_e1bd892d78544ffb981687bec0eb7fca",
              "IPY_MODEL_57939930f8744c0f81754e704aa851c4"
            ]
          }
        },
        "880c591e25e049a1b43b131cbcaeece4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd7fa21cef2a40a6895542fb5f9efc5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9396f93d9ae74486a5bc5553e2e047c2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_643d6f34d22a45ec841020bf0b275584"
          }
        },
        "e1bd892d78544ffb981687bec0eb7fca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7b618d5d6e1d47ddb8c40b757bee2ead",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67454987b54140ecbe376830d8b02668"
          }
        },
        "57939930f8744c0f81754e704aa851c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9606c1fbb96542f1a35da57282af127e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 59.81it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d87ab20d6ee44413a6ff95e2c0004a75"
          }
        },
        "9396f93d9ae74486a5bc5553e2e047c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "643d6f34d22a45ec841020bf0b275584": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b618d5d6e1d47ddb8c40b757bee2ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67454987b54140ecbe376830d8b02668": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9606c1fbb96542f1a35da57282af127e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d87ab20d6ee44413a6ff95e2c0004a75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9689c5de89f84b13985a2610d8a1d313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_24503e44982349f88202f2ac5f134c5d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3e560d6f559946d38f3d83afafebbbff",
              "IPY_MODEL_d794b264dc8d408da2bd626fe891dfa4",
              "IPY_MODEL_4a3be46d5ba64e1f975d26a183de7a95"
            ]
          }
        },
        "24503e44982349f88202f2ac5f134c5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e560d6f559946d38f3d83afafebbbff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9165b9e490b44d249910e7ce03b2d984",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b8543c81b654904821020d377acc2b2"
          }
        },
        "d794b264dc8d408da2bd626fe891dfa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_743409abc24740f9934cda54d756aa62",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a78ca3fee82f4a9a939e7e16ebde8498"
          }
        },
        "4a3be46d5ba64e1f975d26a183de7a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e9240153b022496094e76eab5857c358",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 50.13it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_90fdd4db3cbc48c88dd72ff03eeb8480"
          }
        },
        "9165b9e490b44d249910e7ce03b2d984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b8543c81b654904821020d377acc2b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "743409abc24740f9934cda54d756aa62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a78ca3fee82f4a9a939e7e16ebde8498": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9240153b022496094e76eab5857c358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "90fdd4db3cbc48c88dd72ff03eeb8480": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sorobedio/KAIST-AI502/blob/main/KAIST_AI605_ass1_20205677.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbGnNWI1lRy_"
      },
      "source": [
        "# KAIST AI605 Assignment 1: Text Classification\n",
        "TA in charge: Miyoung Ko (miyoungko@kaist.ac.kr)\n",
        "\n",
        "**Due Date:** September 29 (Wed) 11:00pm, 2021\n",
        "\n",
        "## Your Submission\n",
        "If you are a KAIST student, you will submit your assignment via [KLMS](https://klms.kaist.ac.kr). If you are a NAVER student, you will submit via [Google Form](https://forms.gle/aGZZ86YpCdv2zEVt9). \n",
        "\n",
        "You need to submit both (1) a PDF of this notebook, and (2) a link to CoLab for execution (.ipynb file is also allowed).\n",
        "\n",
        "Use in-line LaTeX (see below) for mathematical expressions. Collaboration among students is allowed but it is not a group assignment so make sure your answer and code are your own. Make sure to mention your collaborators in your assignment with their names and their student ids.\n",
        "\n",
        "## Grading\n",
        "The entire assignment is out of 20 points. You can obtain up to 5 bonus points (i.e. max score is 25 points). For every late day, your grade will be deducted by 2 points (KAIST students only). You can use one of your no-penalty late days (7 days in total). Make sure to mention this in your submission. You will receive a grade of zero if you submit after 7 days.\n",
        "\n",
        "\n",
        "## Environment\n",
        "You will only use Python 3.7 and PyTorch 1.9, which is already available on Colab:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si2JCEbudQnb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYxEp1XMpxem",
        "outputId": "a420a7d6-904a-4fcd-e972-7b9da9422f61"
      },
      "source": [
        "from platform import python_version\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "print(\"python\", python_version())\n",
        "print(\"torch\", torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python 3.7.12\n",
            "torch 1.9.0+cu102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHX8TmFkg-9x"
      },
      "source": [
        "## 1. Limitations of Vanilla RNNs\n",
        "In Lecture 02, we saw that a multi-layer perceptron (MLP) without activation function is equivalent to a single linear transformation with respect to the inputs. One can define a vanilla recurrent neural network without activation as, given inputs $\\textbf{x}_1 \\dots \\textbf{x}_T$, the outputs $\\textbf{h}_t$ is obtained by\n",
        "$$\\textbf{h}_t = \\textbf{V}\\textbf{h}_{t-1} + \\textbf{U}\\textbf{x}_t + \\textbf{b},$$\n",
        "where $\\textbf{V}, \\textbf{U}, \\textbf{b}$ are trainable weights. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS5it_c8hM1R"
      },
      "source": [
        ">**Problem 1.1** *(2 point)* Show that such recurrent neural network (RNN) without activation function is equivalent to a single linear transformation with respect to the inputs, which means each $\\textbf{h}_t$ is a linear combination of the inputs.\n",
        "#### $\\color{red}{\\text{Solution 1.1}}$\n",
        "<font color='red'> **Solution:**  Let's define the weight matrix between the input layer and the hidden layer by $W_{x2h}$ , the weight tensor between hidden layer by $W_{h2h}$ and  the bias by $b_h$. We want to prove $P_t$: each $h_t$ is a linear combination of the input, $$ h_t= W_{x2h} x_t+ W_{h2h}h_{t-1}+b_h$$\n",
        "\n",
        "<font color='red'>**Resolution by induction**: Base case: $h_0=0$ and $$ h_1= W_{x2h} x_1+ b_h$$. The statement is true for $t=1$. For $t=2$ we have $$ h_2= W_{x2h} x_2+ W_{h2h}h_{1}+b_h$$\n",
        "$$ h_2= W_{x2h} x_2+ W_{h2h}(W_{x2h} x_1+ b_h)+b_h$$\n",
        "$$ h_2= W_{x2h} x_2+ W_{h2h}W_{x2h} x_1+ W_{h2h}b_h+b_h$$, The statement is true for $t \\leq2$.  Assuming that the statement is true for a certain $t=n-1>2$ that is $h_{n-1}$ is a linear combination of the input. $$ h_n= W_{x2h} x_n+ W_{h2h}h_{n-1}+b_h$$. Given that $h_{n-1}$ is already a linear combination of the inputs, multiplying by $W_{h2h}$ does not change the linearity. Thus $h_n$ is also a linear combination of the inputs. We can also notice that the linear combination is done in a auto regressive way were $h_t$ is linear combination of $t$ inputs sequence. Which conclude that  such a recurrent neural network without activation function is equivalent to a single linear transformation with respect to the inputs, which means each $\\textbf{h}_t$ is a linear combination of the inputs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5DZ9xKehThT"
      },
      "source": [
        "In Lecture 05 and 06, we will see how RNNs can model non-linearity via activation function, but they still suffer from exploding or vanishing gradients. We can mathematically show that, if the recurrent relation is\n",
        "$$ \\textbf{h}_t = \\sigma (\\textbf{V}\\textbf{h}_{t-1} + \\textbf{U}\\textbf{x}_t + \\textbf{b}) $$\n",
        "then\n",
        "$$ \\frac{\\partial \\textbf{h}_t}{\\partial \\textbf{h}_{t-1}} = \\text{diag}(\\sigma' (\\textbf{V}\\textbf{h}_{t-1} + \\textbf{U}\\textbf{x}_t + \\textbf{b}))\\textbf{V}$$\n",
        "so\n",
        "$$\\frac{\\partial \\textbf{h}_T}{\\partial \\textbf{h}_1} \\propto \\textbf{V}^{T-1}$$\n",
        "which means this term will be very close to zero if the norm of $\\bf{V}$ is smaller than 1 and really big otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB7xyzIgnnkA"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "> **Problem 1.2** *(2 points)* Explain how exploding gradient can be mitigated if we use gradient clipping.\n",
        "#### $\\color{red}{\\text{Solution 1.2}}$\n",
        "<font color='red'> **Solution:** \n",
        "The exploding gradients problem occurs when the norm of the gradient largely increases during training. \n",
        "One option is to clip the parameter gradient from a minibatch\n",
        "element-wise, just before the parameter update. Another is to clip the norm $||g||$ of the gradient $g$ just before the parameter update\n",
        "$$ if \\quad ||g||>v$$\n",
        "$$g \\leftarrow v * \\frac{g}{||g||}$$\n",
        "where $v$ is the norm threshold.  The gradient cliping ensures that the norm of gradient is bounded. This bounded\n",
        "gradient avoids performing a detrimental step when the gradient explodes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIYqmjnXheni"
      },
      "source": [
        "\n",
        "> **Problem 1.3** *(2 points)* Explain how vanishing gradient can be mitigated if we use LSTM. See the Lecture 05 and 06 slides for the definition of LSTM.\n",
        "#### $\\color{red}{\\text{Solution 1.3}}$\n",
        "\n",
        "<font color='red'>The error gradient is given as sum of T gradients \n",
        "\\begin{equation}\n",
        "\\frac{\\partial E}{\\partial W}=\\sum_{t=1}^{T}\\frac{\\partial E_t}{\\partial W}\n",
        "\\end{equation}\n",
        "\n",
        "<font color='red'>The gradient vanishes if the sum of sub-gradients vanishes. We can control the sub-gradient to make the sum not converge to zero. he gradient of the error for some time step k has the form:\n",
        "\\begin{equation}\n",
        "\\frac{\\partial E_k}{\\partial W}=\\frac{\\partial E_k}{\\partial h_k}\\frac{\\partial h_k}{\\partial c_k}( \\prod_{t=2}^{T}\\frac{\\partial c_t}{\\partial c_{t-1}})\\frac{\\partial c_1}{\\partial W}\n",
        "\\end{equation}\n",
        "The gradient vanishing is due to $\\prod_{t=2}^{T}\\frac{\\partial c_t}{\\partial c_{t-1}}$. In an LSTM the stae vector$c_t$ is the form:\n",
        "\\begin{align}\n",
        "c_t &= c_{t-1}\\otimes \\sigma(W_f.[h_{t-1},x_t])\\oplus tanh(W_c.[h_{t-1},x_t])\\otimes\\sigma(W_i.[h_{t-1},x_t]) \\\\\n",
        "&=c_{t-1}\\otimes f_t\\oplus \\tilde{c_t}\\otimes i_t\n",
        "\\end{align}\n",
        "\n",
        "<font color='red'>From the above equation one can see that the gradient of the cell state is sum of four element and can be computed as follows:\n",
        " \\begin{aligned} \\frac{\\partial c_{t}}{\\partial c_{t-1}}=& \\sigma^{\\prime}\\left(W_{f} \\cdot\\left[h_{t-1}, x_{t}\\right]\\right) \\cdot W_{f} \\cdot o_{t-1} \\otimes \\tanh ^{\\prime}\\left(c_{t-1}\\right) \\cdot c_{t-1} \\\\ &+f_{t} \\\\ &+\\sigma^{\\prime}\\left(W_{i} \\cdot\\left[h_{t-1}, x_{t}\\right]\\right) \\cdot W_{i} \\cdot o_{t-1} \\otimes \\tanh ^{\\prime}\\left(c_{t-1}\\right) \\cdot \\tilde{c}_{t} \\\\ &+\\sigma^{\\prime}\\left(W_{c} \\cdot\\left[h_{t-1}, x_{t}\\right]\\right) \\cdot W_{c} \\cdot o_{t-1} \\otimes \\tanh ^{\\prime}\\left(c_{t-1}\\right) \\cdot i_{t} \\end{aligned}\n",
        "In LSTMs the presence of the forget gate, along with the additive property of the cell state gradients, enables the network to update the parameters so that the series of functions or the sum of gradients does not converge to zero:\n",
        "<font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0AmoAT3wA1J"
      },
      "source": [
        "## 2. Creating Vocabulary from Training Data\n",
        "Creating the vocabulary is the first step for every natural language processing model. In this section, you will use Stanford Sentiment Treebank (SST), a popular dataset for sentiment classification, to create your vocabulary.\n",
        "\n",
        "### Obtaining SST via Hugging Face\n",
        "We will use `datasets` package offered by Hugging Face, which allows us to easily download various language datasets, including Stanford Sentiment Treebank.\n",
        "\n",
        "First, install the package:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK0S_VTJxds4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c962ab41-98d8-4843-a4bb-28684778e701"
      },
      "source": [
        "!pip install datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-1.12.1-py3-none-any.whl (270 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 21.9 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████                          | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 81 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 270 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 39.3 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2021.9.0-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 49.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 40.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.8.1)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.2)\n",
            "Collecting huggingface-hub<0.1.0,>=0.0.14\n",
            "  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0,>=0.0.14->datasets) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0,>=0.0.14->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 46.8 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[K     |████████████████████████████████| 294 kB 51.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.5.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, yarl, async-timeout, fsspec, aiohttp, xxhash, huggingface-hub, datasets\n",
            "Successfully installed aiohttp-3.7.4.post0 async-timeout-3.0.1 datasets-1.12.1 fsspec-2021.9.0 huggingface-hub-0.0.17 multidict-5.1.0 xxhash-2.0.2 yarl-1.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8eWbt2yxb3H"
      },
      "source": [
        "Then download SST and print the first example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353,
          "referenced_widgets": [
            "d6147df7b8c54b3a9c0f301c2148c279",
            "ccdec5127b9a4f6c84681b441ab7e156",
            "2a9a83bfe45d4f659dad51686adaf423",
            "8027dc80b6f445b08d9f16114e91430e",
            "fcba449ccd6146d9aa3bee46dd3452ca",
            "e9c00fe6f37244009514eabc1129257c",
            "c829fcd3735347198c07621d81995217",
            "7edd3c1cd5d046dbaa0cea623f0c035b",
            "1939851c46464dbebfd307afe625ae94",
            "f3715cb85af64652b35f04d5923c91d0",
            "fce7bad3af0c4dd6bf5e3c26b06f9cee",
            "3e506e20a99e4903abd1d92695d8abd7",
            "772355f889454cb4927349449c481d99",
            "a04fad0d589045109bf2170b25642fd0",
            "14997b3558414efb84a2a20038f4627b",
            "4cb6d94b13334eb0b94f944a02ef7368",
            "12a8359f44644382aa12a7acebb8a530",
            "b845dadf859142dfbfb8f7a8c77a548d",
            "dca5aa97c6574d54afa684e51eea005a",
            "25314c7d27da4c8eb43dc08b8008b374",
            "f0ed32d3d6484e9f800f1a068146f6ab",
            "5392db62675f4448ab22c7b4948841ee",
            "35b838c5350149fb8fcd8b0e623dc897",
            "acad2c3d03ca44868181b59be4e637d0",
            "05465c7d7ddb4a828330cac3e3040e62",
            "23de16b80ed5423ab43c7cfe90453e50",
            "0119f3e02b5747c98ddce8d75974476e",
            "2d60d67cf9e944c38fb664260cad2104",
            "c9019245d109469a9f32b49b550d40af",
            "11f9e3bf79e94af38988ffef7fb709c8",
            "c9f75e0b6468430aa4a01f5b87f4d09a",
            "1002a535c62449c99a2d3ec6ed28bd34",
            "9be73cebf3314417b253ae05edca863e",
            "578d24fc876446c08b4a02942b47af39",
            "cbf94dc724964c3998dac2c631e1174a",
            "60ab1c0d01214984984cda8ba163b802",
            "2f61a0b328a245038254f4a14d6fc074",
            "5a2ab4057dd14135abce19387f16a9d1",
            "568912e89ea0457f8d68b5fcf70cfedf",
            "d884e88a4f6b46f3a0e0d2111df01179",
            "7571d935a33e4d149cb3beaeee8808c2",
            "04f8f6f470574996b6ef4b76361f2465",
            "2df56543ea24400383f9706dc75c428b",
            "c0d299ed63524685b7fc1b1de34bd3ca",
            "05a99493561549bca88bf07127be5c0f",
            "8edbb1c68a4547c59e03cfdd257fb092",
            "2ea87a6e0367432297b61c6b9a93f3a2",
            "3ac9c9d0a4344733802174ec75a1a964",
            "6a26fc3782db488c8cfccaa8807ed745",
            "bea0748076564195b77d29c5ca294461",
            "aeffd49d353c403c989d0ef8e15e1866",
            "465bca1f8a924713af1fe441287f0781",
            "acada50ce90845c982a1d04e66001c15",
            "5129bff5671e4ba5af664e1c43099f84",
            "e6d04f266a8a487d9e03a9439deba64c",
            "cf259cb5685a4765b931a4276f22ba26",
            "9760d62e16be4458b716f8629deecb83",
            "10128fb0845447d2a69d364559d8a423",
            "ac933984dbb642c490c9f6fdb247582b",
            "99479e802d4a4552b945655628dc216d",
            "224d0a77346143dca2dd4f707a07a16f",
            "e3541830ce204d0f9569a491e34f9698",
            "b3804bb1053844058f59c280d0e6d7a8",
            "05b5b66f019c417593494e54f00befd4",
            "10063088a65f4e57a6c8242505df144f",
            "1449b42aa4c546f58ac9c412490a8892",
            "a0ccb9b989d048eb953b9348d2fd516e",
            "da516bb89f3b4df2bbe7f1e982c96931",
            "b3e88b7ddc044147a60bf5c57c3a8452",
            "ab1c55fb1a26498f91d3ecddd84e6a71",
            "de6f2fc2e8644c41a42408e525c5c398",
            "9717494595ab48cd9b3c27d0033bc206",
            "22f44086502645f593454462638de632",
            "5c741b258f6141c7976d5d9e7d1d9577",
            "676d3e7e84fb45d09a9737a32b1c6126",
            "0f2a57ae8d614e1ab6383f86a5e60377",
            "a5ca10c22a0c482fb4a2cd75723b9ca5",
            "dd4056b8c69f478ca281175b9fd67fbe",
            "16d906893024425686aabb2a3c74ede9",
            "134cba1d68d840c1af1a470b6b959318",
            "8136a5bd92e642d4a162c6ec02444133",
            "09e509f9b02b4ff0a4d906206c567c58",
            "4e1cc8c0a73a486489d133c072d02dc5",
            "bb428fa22df644c7b0f822453a313665",
            "055c39afe6694bf9b3a04e9a83de6a75",
            "4d7bfd4df44c4276a9486e46fa199074",
            "13e9053c7c5a427585da9892080a0f2a",
            "7c92f2f444224213a447c204a6399ac0"
          ]
        },
        "id": "6drFIvgxxjgI",
        "outputId": "56bd3741-2025-45e6-9423-acaa6f41142d"
      },
      "source": [
        "from datasets import load_dataset\n",
        "from pprint import pprint\n",
        "\n",
        "sst_dataset = load_dataset('sst')\n",
        "# train_df=pd.DataFrame.from_dict(sst_dataset['train'])\n",
        "pprint(sst_dataset['train'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6147df7b8c54b3a9c0f301c2148c279",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.59k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e506e20a99e4903abd1d92695d8abd7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No config specified, defaulting to: sst/default\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset sst/default (download: 6.83 MiB, generated: 3.73 MiB, post-processed: Unknown size, total: 10.56 MiB) to /root/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35b838c5350149fb8fcd8b0e623dc897",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/6.37M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "578d24fc876446c08b4a02942b47af39",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/790k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05a99493561549bca88bf07127be5c0f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf259cb5685a4765b931a4276f22ba26",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0ccb9b989d048eb953b9348d2fd516e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset sst downloaded and prepared to /root/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd4056b8c69f478ca281175b9fd67fbe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': 0.6944400072097778,\n",
            " 'sentence': \"The Rock is destined to be the 21st Century 's new `` Conan '' \"\n",
            "             \"and that he 's going to make a splash even greater than Arnold \"\n",
            "             'Schwarzenegger , Jean-Claud Van Damme or Steven Segal .',\n",
            " 'tokens': \"The|Rock|is|destined|to|be|the|21st|Century|'s|new|``|Conan|''|and|that|he|'s|going|to|make|a|splash|even|greater|than|Arnold|Schwarzenegger|,|Jean-Claud|Van|Damme|or|Steven|Segal|.\",\n",
            " 'tree': '70|70|68|67|63|62|61|60|58|58|57|56|56|64|65|55|54|53|52|51|49|47|47|46|46|45|40|40|41|39|38|38|43|37|37|69|44|39|42|41|42|43|44|45|50|48|48|49|50|51|52|53|54|55|66|57|59|59|60|61|62|63|64|65|66|67|68|69|71|71|0'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByKkQ2n8N3-T",
        "outputId": "509e6453-5352-4ae6-866c-cc67aa1bd17f"
      },
      "source": [
        "sst_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'label', 'tokens', 'tree'],\n",
              "        num_rows: 8544\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence', 'label', 'tokens', 'tree'],\n",
              "        num_rows: 1101\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence', 'label', 'tokens', 'tree'],\n",
              "        num_rows: 2210\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAVQyYWkxib6"
      },
      "source": [
        "Note that each `label` is a score between 0 and 1. You will round it to either 0 or 1 for binary classification (positive for 1, negative for 0).\n",
        "In this first example, the label is rounded to 1, meaning that the sentence is a positive review.\n",
        "You will only use `sentence` as the input; please ignore other values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MuQDUUkhODmB",
        "outputId": "8181aa89-aa04-400b-f6de-24ddb5628022"
      },
      "source": [
        "train_df=pd.DataFrame.from_dict(sst_dataset['train'])\n",
        "train_df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>tokens</th>\n",
              "      <th>tree</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "      <td>0.69444</td>\n",
              "      <td>The|Rock|is|destined|to|be|the|21st|Century|'s...</td>\n",
              "      <td>70|70|68|67|63|62|61|60|58|58|57|56|56|64|65|5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "      <td>0.83333</td>\n",
              "      <td>The|gorgeously|elaborate|continuation|of|``|Th...</td>\n",
              "      <td>71|70|69|69|67|67|66|64|63|62|62|61|61|58|57|5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Singer\\/composer Bryan Adams contributes a sle...</td>\n",
              "      <td>0.62500</td>\n",
              "      <td>Singer\\/composer|Bryan|Adams|contributes|a|sle...</td>\n",
              "      <td>72|71|71|70|68|68|67|67|66|63|62|62|60|60|58|5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>You 'd think by now America would have had eno...</td>\n",
              "      <td>0.50000</td>\n",
              "      <td>You|'d|think|by|now|America|would|have|had|eno...</td>\n",
              "      <td>36|35|34|33|33|32|30|29|27|26|25|24|23|23|22|2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Yet the act is still charming here .</td>\n",
              "      <td>0.72222</td>\n",
              "      <td>Yet|the|act|is|still|charming|here|.</td>\n",
              "      <td>15|13|13|10|9|9|11|12|10|11|12|14|14|15|0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  ...                                               tree\n",
              "0  The Rock is destined to be the 21st Century 's...  ...  70|70|68|67|63|62|61|60|58|58|57|56|56|64|65|5...\n",
              "1  The gorgeously elaborate continuation of `` Th...  ...  71|70|69|69|67|67|66|64|63|62|62|61|61|58|57|5...\n",
              "2  Singer\\/composer Bryan Adams contributes a sle...  ...  72|71|71|70|68|68|67|67|66|63|62|62|60|60|58|5...\n",
              "3  You 'd think by now America would have had eno...  ...  36|35|34|33|33|32|30|29|27|26|25|24|23|23|22|2...\n",
              "4               Yet the act is still charming here .  ...          15|13|13|10|9|9|11|12|10|11|12|14|14|15|0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSlOIcABODv4",
        "outputId": "1f6d440e-40c8-441e-e2c5-40a8d99fb1d3"
      },
      "source": [
        "train_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8544, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sNVZKYh8OMTW",
        "outputId": "4f46edf2-ee9b-4826-9297-3468841197b0"
      },
      "source": [
        "train_df['label'] = train_df['label'].apply(lambda x: round(x))\n",
        "train_df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>tokens</th>\n",
              "      <th>tree</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "      <td>1</td>\n",
              "      <td>The|Rock|is|destined|to|be|the|21st|Century|'s...</td>\n",
              "      <td>70|70|68|67|63|62|61|60|58|58|57|56|56|64|65|5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "      <td>1</td>\n",
              "      <td>The|gorgeously|elaborate|continuation|of|``|Th...</td>\n",
              "      <td>71|70|69|69|67|67|66|64|63|62|62|61|61|58|57|5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Singer\\/composer Bryan Adams contributes a sle...</td>\n",
              "      <td>1</td>\n",
              "      <td>Singer\\/composer|Bryan|Adams|contributes|a|sle...</td>\n",
              "      <td>72|71|71|70|68|68|67|67|66|63|62|62|60|60|58|5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>You 'd think by now America would have had eno...</td>\n",
              "      <td>0</td>\n",
              "      <td>You|'d|think|by|now|America|would|have|had|eno...</td>\n",
              "      <td>36|35|34|33|33|32|30|29|27|26|25|24|23|23|22|2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Yet the act is still charming here .</td>\n",
              "      <td>1</td>\n",
              "      <td>Yet|the|act|is|still|charming|here|.</td>\n",
              "      <td>15|13|13|10|9|9|11|12|10|11|12|14|14|15|0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  ...                                               tree\n",
              "0  The Rock is destined to be the 21st Century 's...  ...  70|70|68|67|63|62|61|60|58|58|57|56|56|64|65|5...\n",
              "1  The gorgeously elaborate continuation of `` Th...  ...  71|70|69|69|67|67|66|64|63|62|62|61|61|58|57|5...\n",
              "2  Singer\\/composer Bryan Adams contributes a sle...  ...  72|71|71|70|68|68|67|67|66|63|62|62|60|60|58|5...\n",
              "3  You 'd think by now America would have had eno...  ...  36|35|34|33|33|32|30|29|27|26|25|24|23|23|22|2...\n",
              "4               Yet the act is still charming here .  ...          15|13|13|10|9|9|11|12|10|11|12|14|14|15|0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "678lds8QOMal"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s0T6qk6x78s"
      },
      "source": [
        "> **Problem 2.1** *(2 points)* Using space tokenizer, create the vocabulary for the training data and report the vocabulary size here. Make sure that you add an `UNK` token to the vocabulary to account for words (during inference time) that you haven't seen. See below for an example with a short text.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOsxkEpyxTW1",
        "outputId": "ff1e7bb8-b865-40b3-dfbb-3c70d572b373"
      },
      "source": [
        "# Space tokenization\n",
        "text = \"Hello world!\"\n",
        "tokens = text.split(' ')\n",
        "print(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'world!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iCTn95_pK7i",
        "outputId": "fb3a798d-24aa-421c-f6c9-40da36a2e796"
      },
      "source": [
        "# Constructing vocabulary with `UNK`\n",
        "vocab = ['PAD', 'UNK'] + list(set(text.split(' ')))\n",
        "word2id = {word: id_ for id_, word in enumerate(vocab)}\n",
        "print(vocab)\n",
        "print(word2id['Hello'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PAD', 'UNK', 'world!', 'Hello']\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3ZODXMPXq2n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMM9P4ILOhDi"
      },
      "source": [
        "# alltokens=[]\n",
        "# for i in range(len(train_df)):\n",
        "#     alltokens+=list(list(filter(('').__ne__,train_df.tokens.iloc[i].split(\"|\"))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VFsckFTOhIA"
      },
      "source": [
        "corpus =\" \"\n",
        "texts = list(train_df.sentence)\n",
        "for line in texts:\n",
        "    corpus+= line.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlcgcUwsXQFl"
      },
      "source": [
        "# corpus=''\n",
        "# for i in range(len(df)):\n",
        "#     corpus+=df.sentence.iloc[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv0lzmcNkS71"
      },
      "source": [
        "#### $\\color{red}{\\text{Solution 2.1}}$\n",
        "<font color='red'> **Solution** The below cells showed how the vocabular is created using  the space split tokenizer. The vocabulary size is **18466** words</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1g2k8HcXVet"
      },
      "source": [
        "# Constructing vocabulary with `UNK`\n",
        "vocab = ['PAD', 'UNK'] + list(set(filter(('').__ne__, corpus.split(' '))))\n",
        "word2id = {word: id_ for id_, word in enumerate(vocab)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrjK4JE5XQO8",
        "outputId": "122d2426-22f5-49b5-9e7b-b7e24eab8d5e"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18466"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXjeD_71O5AF",
        "outputId": "5fec0cdd-58f9-4e6d-eaf6-1291afed3e58"
      },
      "source": [
        "vocab[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PAD',\n",
              " 'UNK',\n",
              " 'operates',\n",
              " 'noyce',\n",
              " 'catching',\n",
              " 'pen',\n",
              " 'reward',\n",
              " 'barrel',\n",
              " \"''is\",\n",
              " 'horrified']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqVv57zy1OZ0"
      },
      "source": [
        "> **Problem 2.2** *(1 point)* Using all words in the training data will make the vocabulary very big. Reduce its size by only including words that occur at least 2 times. How does the size of the vocabulary change?\n",
        "#### $\\color{red}{\\text{Solution 2.2}}$\n",
        "<font color='red'> **Solution:** In the below cells we created the vocabulary from only words that appears at least twice in the corpus. The vocabulary length we got is: 8572 which is more than 2 times the previous vocabulary size.  About 9894 words have been removed. </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29mzFFUtXQSV"
      },
      "source": [
        "corpus=\" \"\n",
        "for i in range(len(train_df)):\n",
        "    corpus+=train_df.sentence.iloc[i].lower()\n",
        "texts= list(list(filter(('').__ne__, corpus.split(\" \"))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMVpzgRLPPXS"
      },
      "source": [
        "# texts[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NTzYHafXjDn"
      },
      "source": [
        "import collections"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSa3PHT6XvvW"
      },
      "source": [
        "occurrences = collections.Counter(texts)\n",
        "tokens={i:occurrences[i] for i in occurrences if occurrences[i]>=2}\n",
        "# Constructing vocabulary with `UNK`\n",
        "vocab = ['PAD', 'UNK'] + list(set(tokens))\n",
        "word2id = {word: id_ for id_, word in enumerate(vocab)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TREm3ReaYHA9",
        "outputId": "35a48152-9554-4c73-a5ee-609e7e2a3ea4"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8572"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12KuL2etPau-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDQbmM3W2Im3"
      },
      "source": [
        "## 3. Text Classification with Multi-Layer Perceptron and Recurrent Neural Network\n",
        "\n",
        "You can now use the vocabulary constructed from the training data to create an embedding matrix. You will use the embedding matrix to map each input sequence of tokens to a list of embedding vectors. One of the simplest baseline is to fix the input length (with truncation or padding), flatten the word embeddings, apply a linear transformation followed by an activation, and finally classify the output into the two classes: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFIAvGS5pQXC"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "# length = 8\n",
        "# input_ = \"hi world!\"\n",
        "# input_tokens = input_.split(' ')\n",
        "# input_ids = [word2id[word] if word in word2id else 1 for word in input_tokens] # UNK if word not found\n",
        "# if len(input_ids) < length:\n",
        "#   input_ids = input_ids + [0] * (length - len(input_ids)) # PAD tokens at the end\n",
        "# else:\n",
        "#   input_ids = input_ids[:length]\n",
        "\n",
        "# input_tensor = torch.LongTensor([input_ids]) # the first dimension is minibatch size\n",
        "# print(input_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AicaAaA2S3HD"
      },
      "source": [
        "# input_tensor.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vUmITCFqMit"
      },
      "source": [
        "# Two-layer MLP classification\n",
        "class Baseline(nn.Module):\n",
        "\n",
        "    def __init__(self, d, length=32):\n",
        "        super(Baseline, self).__init__()\n",
        "        self.embedding = nn.Embedding(len(vocab), d)\n",
        "        self.layer = nn.Linear(d * length, d, bias=True)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.class_layer = nn.Linear(d, 2, bias=True)\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        emb = self.embedding(input_tensor) # [batch_size, length, d]\n",
        "        emb_flat = emb.view(emb.size(0), -1) # [batch_size, length*d]\n",
        "        hidden = self.relu(self.layer(emb_flat))\n",
        "        logits = self.class_layer(hidden)\n",
        "        return logits\n",
        "\n",
        "# d = 3 # usually bigger, e.g. 128\n",
        "# baseline = Baseline(d, length)\n",
        "# logits = baseline(input_tensor)\n",
        "# softmax = nn.Softmax(1)\n",
        "# print(softmax(logits)) # probability for each class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9UuMWCG9YNs"
      },
      "source": [
        "Now we will compute the loss, which is the negative log probability of the input text's label being the target label (`1`), which in fact turns out to be equivalent to the cross entropy (https://en.wikipedia.org/wiki/Cross_entropy) between the probability distribution and a one-hot distribution of the target label (note that we use `logits` instead of `softmax(logits)` as the input to the cross entropy, which allow us to avoid numerical instability). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nxgYNzQqaPJ"
      },
      "source": [
        "# cel = nn.CrossEntropyLoss()\n",
        "# label = torch.LongTensor([1]) # The ground truth label for \"hi world!\" is positive.\n",
        "# loss = cel(logits, label) # Loss, a.k.a L\n",
        "# print(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKR99jZ2-wZW"
      },
      "source": [
        "Once we have the loss defined, only one step remains! We compute the gradients of parameters with respective to the loss and update. Fortunately, PyTorch does this for us in a very convenient way. Note that we used only one example to update the model, which is basically a Stochastic Gradient Descent (SGD) with minibatch size of 1. A recommended minibatch size in this exercise is at least 16. It is also recommended that you reuse your training data at least 10 times (i.e. 10 *epochs*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8JjhgQ071d6"
      },
      "source": [
        "# optimizer = torch.optim.SGD(baseline.parameters(), lr=0.1)\n",
        "# optimizer.zero_grad() # reset process\n",
        "# loss.backward() # compute gradients\n",
        "# optimizer.step() # update parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8M0fhFf_LbG"
      },
      "source": [
        "Once you have done this, all weight parameters will have `grad` attributes that contain their gradients with respect to the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpwOavsD8mpn"
      },
      "source": [
        "# print(baseline.layer.weight.grad) # dL/dw of weights in the linear layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V1qNPalYrAe"
      },
      "source": [
        "def get_tokens_ids(word2id, df, length=32):\n",
        "    token_ids=[]\n",
        "    labels=[]\n",
        "    # corpus= list(df.sentence)\n",
        "    targets = list(df.label)\n",
        "    max_len=52\n",
        "\n",
        "#     sent_tokens_= []\n",
        "    for i in range(len(df)):\n",
        "        \n",
        "        \n",
        "        sentence=df.sentence.iloc[i].lower()\n",
        "        input_tokens = list(list(filter(('').__ne__, sentence.split(\" \"))))\n",
        "        if max_len> len(input_tokens):\n",
        "            max_len= len(input_tokens)\n",
        "        #        sent_tokens.append(input_tokens)\n",
        "        input_ids=[word2id[word] if word in word2id else 1 for word in input_tokens]\n",
        "\n",
        "        if len(input_ids) < length:\n",
        "            input_ids = input_ids + [0] * (length - len(input_ids)) # PAD tokens at the end\n",
        "        else:\n",
        "            input_ids = input_ids[:length]\n",
        "\n",
        "        token_ids.append(input_ids)\n",
        "        labels.append(targets[i])\n",
        "    token_ids =torch.LongTensor(token_ids)\n",
        "    labels = torch.LongTensor(labels)\n",
        "    return max_len, token_ids, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-O9D26U_aEB"
      },
      "source": [
        "> **Problem 3.1** *(2 points)* Properly train a MLP baseline model on SST and report the model's accuracy on the dev data.\n",
        "\n",
        "> **Problem 3.2** *(2 points)* Implement a recurrent neural network (without using PyTorch's RNN module) with `tanh` activation, and use the output of the RNN at the final time step for the classification. Report the model's accuracy on the dev data.\n",
        "\n",
        "> **Problem 3.3** *(2 points)* Show that the cross entropy computed above is equivalent to the negative log likelihood of the probability distribution.\n",
        "\n",
        "> **Problem 3.4 (bonus)** *(1 points)* Why is it numerically unstable if you compute log on top of softmax?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXkT83nORbss"
      },
      "source": [
        "\n",
        "from pprint import pprint\n",
        "\n",
        "# sst_dataset = load_dataset('sst')\n",
        "# train_df=pd.DataFrame.from_dict(sst_dataset['train'])\n",
        "# train_df['label'] = train_df['label'].apply(lambda x: round(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kys4feujxUb_"
      },
      "source": [
        "\n",
        "# result_path = 'checkpoint/'\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "def train(model, train_loader, val_loader, num_epochs = 12, file = None):    \n",
        "    if (file != None):\n",
        "        best_file = file#os.path.join(result_path, file)\n",
        "\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "    best_acc = 0\n",
        "    best_acc_epoch = 0\n",
        "    \n",
        "  \n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        train_acc =0\n",
        "        total = 0\n",
        "        epoch_acc = 0\n",
        "        avg_loss=0\n",
        "        labels =[]\n",
        "        for batch in tqdm(train_loader):\n",
        "\n",
        "            data, target = batch\n",
        "            labels.extend(target)\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total += len(target)\n",
        "            avg_loss += loss.item()\n",
        "            _, preds = torch.max(output.data, 1)\n",
        "\n",
        "            train_acc += (preds == target).sum().item()\n",
        "            \n",
        "            # pred = output.data.max(1, keepdim=True)[1]\n",
        "            # train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "        epoch_acc = (100 * train_acc / total)\n",
        "        epoch_loss = avg_loss/total\n",
        "\n",
        "\n",
        "        val_loss,val_acc= validate(epoch, model, val_loader)\n",
        "        print(\"epoch {}: Training_Loss- {:.3f}, Val_Loss- {:.3f}, Training_Acc- {:.2f}, Val_Acc- {:.2f}\".format(epoch, epoch_loss, val_loss, epoch_acc, val_acc))\n",
        "\n",
        "        if (val_acc > best_acc):\n",
        "            best_acc = val_acc\n",
        "            best_epoch = epoch\n",
        "            if (file!=None):\n",
        "                torch.save(model.state_dict(), best_file)         \n",
        "        if (epoch == num_epochs-1):\n",
        "            print(\"Best accuracy at epoch: {}\".format(best_epoch))\n",
        "\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RchSfdEUhkh4"
      },
      "source": [
        "def validate(epoch, model, valid_loader):\n",
        "    \n",
        "    with torch.no_grad():\n",
        "\n",
        "        model.eval()\n",
        "        epoch_loss = 0\n",
        "        val_total = 0\n",
        "        val_correct = 0\n",
        "        epoch_val_acc = 0\n",
        "        val_loss =0\n",
        "        val_labels =[]\n",
        "        for val_batch in tqdm(valid_loader):\n",
        "            \n",
        "            val_data, val_target =  val_batch\n",
        "            val_labels.extend(val_target) \n",
        "            val_data, val_target = val_data.cuda(), val_target.cuda()\n",
        "            val_output = model(val_data)\n",
        "            val_loss += criterion(val_output, val_target).item()\n",
        "            _, preds = torch.max(val_output.data, 1)\n",
        "            val_correct += (preds == val_target).sum().item()\n",
        "\n",
        "            # val_pred = val_output.data.max(1, keepdim=True)[1]\n",
        "            # val_correct += val_pred.eq(val_target.data.view_as(val_pred)).cpu().sum()\n",
        "            val_total+= len(val_target)\n",
        "\n",
        "        epoch_loss=val_loss / len(val_labels)\n",
        "        epoch_val_acc = (100 * val_correct / val_total)\n",
        "\n",
        "    return epoch_loss, epoch_val_acc\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "611vK8alml2C"
      },
      "source": [
        "\n",
        "def test(model, test_loader, file=None):\n",
        "    \n",
        "    if (file!=None):\n",
        "        best_file = file #os.path.join(result_path, file)\n",
        "        model.load_state_dict(torch.load(best_file))\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for batch in tqdm(test_loader):\n",
        "        data, target = batch\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "        output = model(data)\n",
        "        test_loss += criterion(output, target).item()\n",
        "        _, preds = torch.max(output.data, 1)\n",
        "\n",
        "        correct += (preds == target).sum().item()\n",
        "\n",
        "        # pred = output.data.max(1, keepdim=True)[1]\n",
        "        # correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(test_loss, correct,\n",
        "                                                                                len(test_loader.dataset),\n",
        "                                                                                100. * correct / len(\n",
        "                                                                                    test_loader.dataset)))\n",
        "    # return correct / float(len(test_loader.dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "762c5543e56f40e3bbd39dc576069cec",
            "180fd0aaaddd4f3c974f752c5c64cc38",
            "3c711a549bd541438a374a71ece88158",
            "b2c58741b3ac407bb23642a6cee00100",
            "62c1473f2ba647808e51c7b095d6f216",
            "524f30a5d0ce42e1b8d3cb78599606c1",
            "c6b657a4548e48988b685939816759f0",
            "684ac74a543649b4a9db7e1763bb83f0",
            "29dc6609ddbd4731bb02b9230c7e3c37",
            "b03436550ccf4a9c9b0f97800ff76df6",
            "92505e40939f48dd93857144cdd1e8f1"
          ]
        },
        "id": "lQVnWUj7qLLU",
        "outputId": "d61a4b75-8764-4a31-da6f-cd6701ddaeaa"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "sst_dataset = load_dataset('sst')\n",
        "\n",
        "\n",
        "train_df=pd.DataFrame.from_dict(sst_dataset['train'])\n",
        "train_df['label'] = train_df['label'].apply(lambda x: round(x))\n",
        "\n",
        "val_df=pd.DataFrame.from_dict(sst_dataset['validation'])\n",
        "val_df['label'] = val_df['label'].apply(lambda x: round(x))\n",
        "\n",
        "test_df=pd.DataFrame.from_dict(sst_dataset['test'])\n",
        "test_df['label'] = test_df['label'].apply(lambda x: round(x))\n",
        "\n",
        "max_len, data, labels =get_tokens_ids(word2id, train_df, 16)\n",
        "val_max_len, val_data, val_labels =get_tokens_ids(word2id, val_df, 16)\n",
        "test_max_len, test_data, test_labels =get_tokens_ids(word2id, test_df, 16)\n",
        "# print(test_data.shape)\n",
        "# print(test_labels.shape)\n",
        "# print(test_max_len)\n",
        "# print(data.shape)\n",
        "# print(labels.shape)\n",
        "print(max_len)\n",
        "\n",
        "\n",
        "train_set = TensorDataset(data, labels)\n",
        "valid_set = TensorDataset(val_data, val_labels)\n",
        "test_set = TensorDataset(test_data, test_labels)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_set, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_set, shuffle=False, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No config specified, defaulting to: sst/default\n",
            "Reusing dataset sst (/root/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "762c5543e56f40e3bbd39dc576069cec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4Jav9pGbaGx"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv2HfJun2TRm"
      },
      "source": [
        "input_dim = 100 # word-embedding dimension\n",
        "num_epochs = 50\n",
        "model = Baseline(d=100,length=52).cuda()\n",
        "train(model, train_loader, valid_loader, num_epochs, 'base_best_model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5OGM9Z6pnPE"
      },
      "source": [
        "test(model, test_loader, file = 'base_best_model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im2tBGF4uzQ7"
      },
      "source": [
        "test(model, valid_loader, file = 'base_best_model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heBQJK1ku7b1"
      },
      "source": [
        "# L=52 vac =56.49 tac=54.52 epco =43\n",
        "# L=40 vac =57.40 tac=55.57 epco =41\n",
        "# L=32 vac =57.22 tac=56.06 epco =10\n",
        "# L=16 vac =57.77 tac=57.51 epco =17\n",
        "# L=8 vac =59.49 tac=55.57 epco =4\n",
        "# L=45 vac =56.58 tac=55.70 epco =38"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjOh7eelrloW"
      },
      "source": [
        "#### $\\color{red}{\\text{Solution 3.1}}$\n",
        "<font color='red'> The Baseline model trained for 50 epochs achieved its best performance in 2 epochs whith sequence length 16. We believe that the model overfit the data and does not generalized. The model may have started with good initialization but does not not improve the performance while the training accuracy was around 99%. Below we report the experiment results for three sequence lengths.<font>\n",
        "\n",
        "Sequence length=52 validation accuracy =56.49 test accuracy=54.52 best epoch =43\n",
        "    \n",
        "Sequence length=40 validation accuracy =57.40 test accuracy=55.57 best epoch =41\n",
        "    \n",
        "Sequence length=32 validation accuracy =57.22 test accuracy=56.06 best epoch =10\n",
        "    \n",
        "Sequence length=16 validation accuracy=57.77 test accuracy=57.51 best epoch =17\n",
        "    \n",
        "Sequences length=8 validation accuracy =59.49 test accuracy=55.57  best epoch =4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGIWXHU8SuY0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdJlp3W3iyw0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxZODO6jXCIR"
      },
      "source": [
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, hidden_dim, output_dim=2):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_dim= input_dim\n",
        "        self.hidden_dim= hidden_dim\n",
        "        self.output_dim=output_dim\n",
        "        self.embedding = nn.Embedding(len(vocab), self.input_dim)\n",
        "        self.fc_x2h = nn.Linear(in_features=self.input_dim, out_features=self.hidden_dim)\n",
        "        self.fc_h2h = nn.Linear(in_features=self.hidden_dim, out_features=self.hidden_dim)\n",
        "        self.fc_h2y = nn.Linear(in_features=self.hidden_dim, out_features=self.output_dim)\n",
        "\n",
        "    def forward(self, input):\n",
        "        emb = self.embedding(input)\n",
        "\n",
        "        h = Variable(torch.zeros(input.size(0), self.hidden_dim)).to(input.device)\n",
        "        # h = Variable(input.new_zeros(input.size(0), self.fc_h2y.weight.size(1)))\n",
        "        for t in range(emb.size(1)):\n",
        "            h = torch.tanh(self.fc_x2h(emb[:,t,:])+self.fc_h2h(h))\n",
        "        return self.fc_h2y(h)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "138336a4a3954b4da1c89174f61b2387",
            "bd92fe9ab32e45ad873522c8d3009aa7",
            "c5b3f7c9155c43d6a7fd677902269524",
            "11963c590cb04622aaf95f96a5729bd2",
            "445288e609da4a81ae57beead2050433",
            "bd528ae35f054690846520154e21fe59",
            "9fda14b143574334baca91e28c1979e4",
            "a891dfad1c9b486aa91478540a15c80d",
            "78bed69b9299479686530ca4c85d5617",
            "b3da00daef95433f9d43090cfa093367",
            "0d63708a742b4b349f86010e03f836f1"
          ]
        },
        "id": "ab7mDCKoyG0p",
        "outputId": "6247f44b-8e90-4408-e79a-464617960a6c"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "sst_dataset = load_dataset('sst')\n",
        "\n",
        "\n",
        "train_df=pd.DataFrame.from_dict(sst_dataset['train'])\n",
        "train_df['label'] = train_df['label'].apply(lambda x: round(x))\n",
        "\n",
        "val_df=pd.DataFrame.from_dict(sst_dataset['validation'])\n",
        "val_df['label'] = val_df['label'].apply(lambda x: round(x))\n",
        "\n",
        "test_df=pd.DataFrame.from_dict(sst_dataset['test'])\n",
        "test_df['label'] = test_df['label'].apply(lambda x: round(x))\n",
        "\n",
        "max_len, data, labels =get_tokens_ids(word2id, train_df, 32)\n",
        "val_max_len, val_data, val_labels =get_tokens_ids(word2id, val_df, 32)\n",
        "test_max_len, test_data, test_labels =get_tokens_ids(word2id, test_df, 32)\n",
        "# print(test_data.shape)\n",
        "# print(test_labels.shape)\n",
        "# print(test_max_len)\n",
        "# print(data.shape)\n",
        "# print(labels.shape)\n",
        "print(max_len)\n",
        "\n",
        "\n",
        "train_set = TensorDataset(data, labels)\n",
        "valid_set = TensorDataset(val_data, val_labels)\n",
        "test_set = TensorDataset(test_data, test_labels)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_set, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_set, shuffle=False, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No config specified, defaulting to: sst/default\n",
            "Reusing dataset sst (/root/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "138336a4a3954b4da1c89174f61b2387",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrzlxoyVXCMu",
        "outputId": "ba34cd08-3eed-4bf3-d2ce-20a135af6a97"
      },
      "source": [
        "# nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "num_epochs = 50\n",
        "model = RNN(input_dim=100, hidden_dim=100).cuda()\n",
        "train(model, train_loader, valid_loader, num_epochs, 'rnn_best_model.pth')\n",
        "# train(model, train_loader, valid_loader, num_epochs, None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 58.92it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 207.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 49.88, Val_Acc- 50.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.69it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 196.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.34, Val_Acc- 50.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.52it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 131.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.21, Val_Acc- 48.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.92it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 209.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.76, Val_Acc- 48.05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.26it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 190.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.66, Val_Acc- 51.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 60.01it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 192.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.85, Val_Acc- 50.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 58.88it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 207.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.59, Val_Acc- 52.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.58it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 195.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 52.67, Val_Acc- 50.95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.33it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 208.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8: Training_Loss- 0.021, Val_Loss- 0.023, Training_Acc- 53.55, Val_Acc- 48.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.91it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 207.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 53.60, Val_Acc- 51.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 60.30it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 192.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10: Training_Loss- 0.021, Val_Loss- 0.023, Training_Acc- 54.58, Val_Acc- 49.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 58.97it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 205.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 11: Training_Loss- 0.021, Val_Loss- 0.023, Training_Acc- 53.87, Val_Acc- 50.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.54it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 213.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 12: Training_Loss- 0.021, Val_Loss- 0.023, Training_Acc- 55.33, Val_Acc- 51.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 60.10it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 207.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 13: Training_Loss- 0.021, Val_Loss- 0.023, Training_Acc- 55.79, Val_Acc- 48.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 60.03it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 200.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 14: Training_Loss- 0.021, Val_Loss- 0.023, Training_Acc- 57.10, Val_Acc- 50.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 58.47it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 200.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 15: Training_Loss- 0.021, Val_Loss- 0.024, Training_Acc- 57.30, Val_Acc- 49.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.96it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 213.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 16: Training_Loss- 0.020, Val_Loss- 0.024, Training_Acc- 56.98, Val_Acc- 48.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.43it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 198.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 17: Training_Loss- 0.020, Val_Loss- 0.025, Training_Acc- 57.98, Val_Acc- 48.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.68it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 216.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 18: Training_Loss- 0.020, Val_Loss- 0.025, Training_Acc- 59.13, Val_Acc- 49.05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 57.98it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 201.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 19: Training_Loss- 0.020, Val_Loss- 0.025, Training_Acc- 59.42, Val_Acc- 49.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 60.01it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 208.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 20: Training_Loss- 0.020, Val_Loss- 0.027, Training_Acc- 58.88, Val_Acc- 51.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.61it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 189.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 21: Training_Loss- 0.020, Val_Loss- 0.026, Training_Acc- 60.88, Val_Acc- 48.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.07it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 204.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 22: Training_Loss- 0.019, Val_Loss- 0.025, Training_Acc- 60.93, Val_Acc- 47.96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.98it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 193.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 23: Training_Loss- 0.019, Val_Loss- 0.027, Training_Acc- 62.31, Val_Acc- 52.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.05it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 199.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 24: Training_Loss- 0.019, Val_Loss- 0.026, Training_Acc- 61.83, Val_Acc- 49.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 60.13it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 207.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 25: Training_Loss- 0.019, Val_Loss- 0.027, Training_Acc- 63.01, Val_Acc- 52.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 60.11it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 206.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 26: Training_Loss- 0.018, Val_Loss- 0.028, Training_Acc- 63.83, Val_Acc- 49.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.11it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 136.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 27: Training_Loss- 0.019, Val_Loss- 0.027, Training_Acc- 61.54, Val_Acc- 51.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 60.10it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 190.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 28: Training_Loss- 0.019, Val_Loss- 0.028, Training_Acc- 62.75, Val_Acc- 51.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.51it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 199.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 29: Training_Loss- 0.018, Val_Loss- 0.032, Training_Acc- 63.73, Val_Acc- 51.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.33it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 203.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 30: Training_Loss- 0.018, Val_Loss- 0.032, Training_Acc- 65.87, Val_Acc- 50.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 58.18it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 189.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 31: Training_Loss- 0.019, Val_Loss- 0.035, Training_Acc- 63.26, Val_Acc- 51.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 58.87it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 185.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 32: Training_Loss- 0.018, Val_Loss- 0.028, Training_Acc- 65.54, Val_Acc- 48.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.29it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 201.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 33: Training_Loss- 0.018, Val_Loss- 0.030, Training_Acc- 65.16, Val_Acc- 53.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.47it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 198.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 34: Training_Loss- 0.017, Val_Loss- 0.034, Training_Acc- 66.30, Val_Acc- 52.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.91it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 133.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 35: Training_Loss- 0.017, Val_Loss- 0.035, Training_Acc- 67.22, Val_Acc- 51.95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.02it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 212.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 36: Training_Loss- 0.020, Val_Loss- 0.031, Training_Acc- 63.17, Val_Acc- 49.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.61it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 200.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 37: Training_Loss- 0.018, Val_Loss- 0.031, Training_Acc- 65.57, Val_Acc- 51.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.05it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 205.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 38: Training_Loss- 0.017, Val_Loss- 0.030, Training_Acc- 67.40, Val_Acc- 52.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.74it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 199.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 39: Training_Loss- 0.017, Val_Loss- 0.029, Training_Acc- 67.80, Val_Acc- 52.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.14it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 196.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 40: Training_Loss- 0.017, Val_Loss- 0.032, Training_Acc- 67.78, Val_Acc- 49.05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 58.98it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 205.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 41: Training_Loss- 0.017, Val_Loss- 0.035, Training_Acc- 67.04, Val_Acc- 49.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.55it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 194.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 42: Training_Loss- 0.016, Val_Loss- 0.034, Training_Acc- 68.83, Val_Acc- 49.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 58.77it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 193.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 43: Training_Loss- 0.017, Val_Loss- 0.031, Training_Acc- 67.56, Val_Acc- 51.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 58.88it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 179.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 44: Training_Loss- 0.017, Val_Loss- 0.034, Training_Acc- 67.73, Val_Acc- 52.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.76it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 189.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 45: Training_Loss- 0.016, Val_Loss- 0.036, Training_Acc- 68.91, Val_Acc- 49.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.72it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 203.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 46: Training_Loss- 0.016, Val_Loss- 0.033, Training_Acc- 68.48, Val_Acc- 48.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.66it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 191.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 47: Training_Loss- 0.018, Val_Loss- 0.036, Training_Acc- 66.05, Val_Acc- 51.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 59.89it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 211.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 48: Training_Loss- 0.017, Val_Loss- 0.036, Training_Acc- 68.87, Val_Acc- 48.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:04<00:00, 58.76it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 208.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 49: Training_Loss- 0.016, Val_Loss- 0.034, Training_Acc- 69.83, Val_Acc- 48.68\n",
            "Best accuracy at epoch: 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRquPb0cXCRE",
        "outputId": "22d5ff39-bb21-4498-d709-4ad20425e09e"
      },
      "source": [
        "test(model, test_loader, file = 'rnn_best_model.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [00:00<00:00, 170.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0296, Accuracy: 1112/2210 (50.32%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0IvUNgVH2IF",
        "outputId": "ce5040c1-754d-4b07-e77e-e1e223e4eb18"
      },
      "source": [
        "test(model, valid_loader, file = 'rnn_best_model.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:00<00:00, 159.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0296, Accuracy: 586/1101 (53.22%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxS1n-NwYPGa"
      },
      "source": [
        "# L=52 vac =50.68 tac=51.72 epco =2\n",
        "# L=40 vac =52.13 tac=51.22 epco =16\n",
        "# L=32 vac =54.41 tac=51.27 epco =17  training slowly learning\n",
        "# L=16 vac =57.86 tac=57.24 epco =15 training accuracy  up90\n",
        "# L=8 vac =60.94 tac=56.56 epco =19 overfitting\n",
        "# L=24 vac =53.13 tac=52.08 epco =8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgAHX5yMr99I"
      },
      "source": [
        "#### $\\color{red}{\\text{Solution 3.2}}$\n",
        "<font color='red'>The RNN model is trained for 50 epochs.The model fails to learn for larger sequence length and overfits for smaller sequence length. The best performance is obtained with sequence length set to 8. the validation and test accuracies are respectively 60.94& and 56.56% The model achieve better performance than the baseline <font>\n",
        "\n",
        "Sequence length=52 validation accuracy =50.68 test accuracy=51.72 best epoch =2\n",
        "    \n",
        "Sequence length=40 validation accuracy =53.68 test accuracy=50.45 best epoch =17\n",
        "    \n",
        "Sequence length=32 validation accuracy =54.41 test accuracy=51.27 best epoch =18\n",
        "    \n",
        "Sequence length=16 validation accuracy=57.86 test accuracy=57.24 best epoch =15\n",
        "    \n",
        "Sequences length=8 validation accuracy =60.94 test accuracy=56.56  best epoch =19"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eWMg7zhsI0v"
      },
      "source": [
        "#### $\\color{red}{\\text{Solution 3.3}}$\n",
        "**Theoretically**\n",
        "\n",
        "<font color='red'> The cross-entropy of the distribution ${\\displaystyle q}$ relative to a distribution ${\\displaystyle p}$  over a given set is defined as follows: \n",
        "$$H(p,q) = - \\sum_{i} {\\displaystyle p_i} \\log {\\displaystyle q_i}$$,\n",
        "where $q_{i}$ is the estimated probability of outcome $i$ and $p_{i}$ is the empirical probability of outcome $i$ in the training set. <font>\n",
        "\n",
        "<font color='red'> **Relation to log-likelihood**\n",
        "\n",
        "<font color='red'> Let the estimated probability of outcome $i$ be $q_{\\theta }(x=i)= q_i$ and let the frequency (empirical probability) of outcome $i$ in the training set be $p(x=i)= p_i$\n",
        "\n",
        "<font color='red'> Given N conditionally independent samples in the training set, then the **likelihood** is given by:\n",
        "$$\\text{likelihood} = \\prod_{i} q_{i}^{Np_{i}} $$\n",
        "\n",
        "Taking the **logarithm of likelihood** followed by dividing it by N, we get\n",
        "$$\\frac{1}{N} \\log \\prod_{i} q_{i}^{Np_{i}}  = \\sum_{i} p_{i} \\log q_{i} = - H(p,q) $$\n",
        "</font>\n",
        "<font color='red'>  so that maximizing the likelihood with respect to the parameters ${\\displaystyle \\theta }$ is the same as minimizing the cross-entropy.<font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY7XLztrcAWz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj-jcSXpsTxD"
      },
      "source": [
        "#### $\\color{red}{\\text{Solution 3.4}}$\n",
        "\n",
        "<font color='red'>  If some input values are very large compared to the others, the smaller will have  value zero as softmax output. And computing the logarithm on top of this result will lead to undeflow or undefine isssue which arises when one tries to compute log(0). Example: $x = [5.0, 1.0, 10.0, 1000.0]$ we have $ softmax(x) = [0., 0., 0., 1.]$ and taking log we get $log(softmax(x))=[-inf, -inf, -inf, 0.]$.\n",
        "Therefore, **computing log on top of softmax is numerically unstable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Vax6ImqZS8G",
        "outputId": "119cb551-74ab-472b-aff6-e396538e398d"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "x =torch.tensor([5, 1, 10.0, 500])\n",
        "x= x.reshape((1,-1))\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  5.,   1.,  10., 500.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-gpqwo9ZYAG",
        "outputId": "ca18da39-16b1-4eb6-d64b-4e8417178f9f"
      },
      "source": [
        "m=nn.Softmax(dim=1)\n",
        "m(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySJhQWYfZcoG",
        "outputId": "14bc35a7-d557-427a-d486-a2919647f5df"
      },
      "source": [
        "torch.log(m(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-inf, -inf, -inf, 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBLmpKJRAd1h"
      },
      "source": [
        "## 4. Text Classification with LSTM and Dropout\n",
        "\n",
        "Replace your RNN module with an LSTM module. See Lecture slides 05 and 06 for the formal definition of LSTMs. \n",
        "\n",
        "You will also use Dropout, which randomly makes each dimension zero with the probability of `p` and scale it by `1/(1-p)` if it is not zero during training. Put it either at the input or the output of the LSTM to prevent it from overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8H0F-csCCk0",
        "outputId": "b9639721-dc91-48dd-b82c-3b179bf04742"
      },
      "source": [
        "a = torch.FloatTensor([0.1, 0.3, 0.5, 0.7, 0.9])\n",
        "dropout = nn.Dropout(0.5) # p=0.5\n",
        "print(dropout(a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.2000, 0.6000, 0.0000, 0.0000, 0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcHdg9Ori_5n"
      },
      "source": [
        "> **Problem 4.1** *(3 points)* Implement and use LSTM (without using PyTorch's LSTM module) instead of vanilla RNN. Report the accuracy on the dev data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDKxr2IyXCU9"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "class LSTMCell(nn.Module):\n",
        "    def __init__(self, vocab, input_size, hidden_size, output_size=2, bias=True, drop = 0):\n",
        "        super(LSTMCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bias = bias\n",
        "        self.drop =drop\n",
        "        self.output_size =output_size\n",
        "\n",
        "        self.fc_x2h = nn.Linear(input_size, hidden_size * 4, bias=bias)\n",
        "        self.fc_h2h = nn.Linear(hidden_size, hidden_size * 4, bias=bias)\n",
        "        self.embedding = nn.Embedding(len(vocab), self.input_size)\n",
        "        self.dropout = nn.Dropout(drop)\n",
        "        self.classifier = nn.Linear(self.hidden_size, self.output_size, bias=True) \n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        std = 1.0 / np.sqrt(self.hidden_size)\n",
        "        for w in self.parameters():\n",
        "            w.data.uniform_(-std, std)\n",
        "\n",
        "    def forward(self, input, hx=None):\n",
        "\n",
        "  \n",
        "        emb =self.embedding(input)\n",
        "\n",
        "        if hx is None:\n",
        "          #get initial values\n",
        "            batch_size = emb.shape[0]\n",
        "\n",
        "        hx, cx = (torch.zeros(batch_size, self.hidden_size).to(emb.device), \n",
        "                        torch.zeros(batch_size, self.hidden_size).to(emb.device))\n",
        "\n",
        "        # hx, cx = hx\n",
        "        for t in range(emb.shape[1]):\n",
        "            emb_t = emb[:, t, :]\n",
        "\n",
        "            gates = self.fc_x2h(emb_t) + self.fc_h2h(hx)\n",
        "            # Get gates (i_t, f_t, g_t, o_t)\n",
        "            input_gate, forget_gate, cell_gate, output_gate = gates.chunk(4, 1)\n",
        "\n",
        "            i_t = torch.sigmoid(input_gate)\n",
        "            f_t = torch.sigmoid(forget_gate)\n",
        "            g_t = torch.tanh(cell_gate)\n",
        "            o_t = torch.sigmoid(output_gate)\n",
        "\n",
        "            cy = cx * f_t + i_t * g_t\n",
        "\n",
        "            hy = o_t * torch.tanh(cy)\n",
        "\n",
        "\n",
        "        if (self.drop != 0):\n",
        "            h_t = self.dropout(hy)\n",
        "            out = self.linear(h_t)\n",
        "        else:\n",
        "            out = self.classifier(hy)\n",
        "\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9Gq503FYPGd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "17c1527582dd4716b9fad7ed7a4474e4",
            "e99fcc27e3f54c55a66b70fd5d5a270b",
            "e4e30c51be97429b817f20e8f5704e0e",
            "a2ffeb6e121f4fcfb8dc8e119cdec2f9",
            "ee4cff9d698147a7970b7d4e2c4854b9",
            "5906c4ea645049d88e5dd6069ff288e3",
            "4fdf152c5e3a41f1990c8c30c231036d",
            "2029126ef59f4e9e816398f789c2db5a",
            "ce461a946af24591a701475774bfe1bb",
            "a71837a02b454912a5ae47f2635da3a5",
            "15b7e82f57ad47aa93a6dc0587e2b6c8"
          ]
        },
        "outputId": "25454ece-9141-44c8-c0e8-a959863c432b"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "sst_dataset = load_dataset('sst')\n",
        "\n",
        "\n",
        "train_df=pd.DataFrame.from_dict(sst_dataset['train'])\n",
        "train_df['label'] = train_df['label'].apply(lambda x: round(x))\n",
        "\n",
        "val_df=pd.DataFrame.from_dict(sst_dataset['validation'])\n",
        "val_df['label'] = val_df['label'].apply(lambda x: round(x))\n",
        "\n",
        "test_df=pd.DataFrame.from_dict(sst_dataset['test'])\n",
        "test_df['label'] = test_df['label'].apply(lambda x: round(x))\n",
        "\n",
        "max_len, data, labels =get_tokens_ids(word2id, train_df, 16)\n",
        "val_max_len, val_data, val_labels =get_tokens_ids(word2id, val_df, 16)\n",
        "test_max_len, test_data, test_labels =get_tokens_ids(word2id, test_df, 16)\n",
        "# print(test_data.shape)\n",
        "# print(test_labels.shape)\n",
        "# print(test_max_len)\n",
        "# print(data.shape)\n",
        "# print(labels.shape)\n",
        "print(max_len)\n",
        "\n",
        "\n",
        "train_set = TensorDataset(data, labels)\n",
        "valid_set = TensorDataset(val_data, val_labels)\n",
        "test_set = TensorDataset(test_data, test_labels)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_set, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_set, shuffle=False, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No config specified, defaulting to: sst/default\n",
            "Reusing dataset sst (/root/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17c1527582dd4716b9fad7ed7a4474e4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmEiLf7Pj22i",
        "outputId": "ee1fe748-0bf9-459d-f8bc-7f262513e360"
      },
      "source": [
        "d = 100 # size of word-embedding\n",
        "num_epochs = 50\n",
        "model = LSTMCell(vocab, input_size=100, hidden_size=100).cuda()\n",
        "train(model, train_loader, valid_loader, num_epochs, 'lstm1_best_model.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 116.30it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 179.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 49.81, Val_Acc- 49.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 117.39it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 184.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 49.95, Val_Acc- 50.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 120.99it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 169.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 49.11, Val_Acc- 49.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 118.74it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 182.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 49.12, Val_Acc- 49.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 122.88it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 183.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.30, Val_Acc- 49.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 121.43it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 178.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 49.22, Val_Acc- 50.05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 122.39it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 171.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.50, Val_Acc- 52.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 122.24it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 171.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.69, Val_Acc- 50.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 118.68it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 140.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.54, Val_Acc- 53.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 122.36it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 178.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.26, Val_Acc- 49.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 118.18it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 171.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.15, Val_Acc- 50.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 121.54it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 179.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 11: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 49.95, Val_Acc- 51.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 118.60it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 155.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 12: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.19, Val_Acc- 49.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 120.80it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 156.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 13: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.02, Val_Acc- 50.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 118.01it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 179.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 14: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.00, Val_Acc- 48.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 120.25it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 179.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 15: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.51, Val_Acc- 52.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 119.15it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 168.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 16: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.43, Val_Acc- 49.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 113.09it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 163.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 17: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.69, Val_Acc- 49.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 118.41it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 172.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 18: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.19, Val_Acc- 50.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 119.38it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 160.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 19: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.19, Val_Acc- 52.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 117.70it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 167.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 20: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.56, Val_Acc- 49.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 115.39it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 160.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 21: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.57, Val_Acc- 49.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 117.17it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 175.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 22: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.69, Val_Acc- 49.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 120.21it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 173.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 23: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.73, Val_Acc- 48.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 119.27it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 181.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 24: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.24, Val_Acc- 51.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 116.53it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 172.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 25: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.19, Val_Acc- 52.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 118.14it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 173.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 26: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.85, Val_Acc- 51.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 119.01it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 186.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 27: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.44, Val_Acc- 50.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 123.07it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 158.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 28: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 52.61, Val_Acc- 48.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 117.49it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 185.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 29: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.83, Val_Acc- 51.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 118.45it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 180.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 30: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 53.35, Val_Acc- 48.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 122.00it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 172.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 31: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 52.48, Val_Acc- 52.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 118.90it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 178.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 32: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 53.99, Val_Acc- 51.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 114.46it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 136.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 33: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 52.55, Val_Acc- 49.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 121.53it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 185.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 34: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 53.62, Val_Acc- 48.96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 118.96it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 175.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 35: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 53.55, Val_Acc- 49.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 119.34it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 175.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 36: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 54.15, Val_Acc- 49.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 121.40it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 177.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 37: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 54.34, Val_Acc- 49.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 117.48it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 186.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 38: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 54.30, Val_Acc- 51.95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 119.90it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 179.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 39: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 55.40, Val_Acc- 51.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 121.68it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 158.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 40: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 55.03, Val_Acc- 52.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 118.08it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 123.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 41: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 56.58, Val_Acc- 51.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 117.76it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 170.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 42: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 56.30, Val_Acc- 48.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 117.59it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 177.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 43: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 56.04, Val_Acc- 52.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 114.67it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 152.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 44: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 56.46, Val_Acc- 48.96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 117.70it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 181.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 45: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 57.58, Val_Acc- 49.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 121.12it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 180.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 46: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 57.08, Val_Acc- 52.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 115.99it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 166.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 47: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 58.02, Val_Acc- 52.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 117.55it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 185.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 48: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 57.78, Val_Acc- 52.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 116.41it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 180.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 49: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 59.12, Val_Acc- 49.68\n",
            "Best accuracy at epoch: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dBBjT9AjBr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c02d12d-dd7c-4a83-8b98-4924a6f4ec30"
      },
      "source": [
        "test(model, test_loader, file = 'lstm1_best_model.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [00:00<00:00, 138.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0220, Accuracy: 1121/2210 (50.72%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY21ttVcYPGf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3603044b-f4d7-4151-b532-839addabbf49"
      },
      "source": [
        "test(model, valid_loader, file = 'lstm1_best_model.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:00<00:00, 141.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0220, Accuracy: 584/1101 (53.04%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exgqhHNVYPGf"
      },
      "source": [
        "# L=52 vac =50.68 tac=51.72 epco =2\n",
        "# L=40 vac =50.58 tac=51.72 epco =9\n",
        "# L=32 vac =50.95 tac=51.40 epco =6  training slowly learning\n",
        "# L=16 vac =53.86.86 tac=52.53 epco =27 \n",
        "# L=8 vac =53.86.94 tac=54.16 epco =47 underfitting\n",
        "# L=24 vac =53.13 tac=52.08 epco =8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15wrTnsUcAXC"
      },
      "source": [
        "\n",
        "#WE build our lstm while closely studying the work on\n",
        "#https://github.com/piEsposito/pytorch-lstm-by-hand"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SfXEDiAcAfk"
      },
      "source": [
        "import math\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, d, dropout = None):\n",
        "     \n",
        "        super(LSTM, self).__init__()\n",
        "        self.input_size = d\n",
        "        self.hidden_size = d\n",
        "        self.output_size = 2\n",
        "        self.drop = dropout\n",
        "        self.embedding = nn.Embedding(len(vocab), self.input_size)\n",
        "        # i_t, c_t, f_t, o_t\n",
        "        self.W = nn.Parameter(torch.Tensor(self.input_size, self.hidden_size * 4))\n",
        "        self.U = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size * 4))\n",
        "        self.b = nn.Parameter(torch.Tensor(self.hidden_size * 4))\n",
        "\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.linear = nn.Linear(self.hidden_size, self.output_size, bias=True) \n",
        "\n",
        "        self.init_weights()\n",
        "                \n",
        "    def init_weights(self):\n",
        "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for weight in self.parameters():\n",
        "            weight.data.uniform_(-stdv, stdv)\n",
        "         \n",
        "    def forward(self, x):\n",
        "\n",
        "        emb = self.embedding(x)\n",
        "        batch_size = emb.shape[0]\n",
        "\n",
        "        h_t, c_t = (torch.zeros(batch_size, self.hidden_size).to(emb.device), \n",
        "                        torch.zeros(batch_size, self.hidden_size).to(emb.device))\n",
        "          \n",
        "        ds = self.hidden_size\n",
        "        for t in range(emb.shape[1]):\n",
        "            emb_t = emb[:, t, :]\n",
        "            gate = emb_t @ self.W + h_t @ self.U + self.b\n",
        "            i_t, f_t, g_t, o_t = (\n",
        "                torch.sigmoid(gate[:, :ds]), \n",
        "                torch.sigmoid(gate[:, ds:ds*2]),  \n",
        "                torch.tanh(gate[:, ds*2:ds*3]),\n",
        "                torch.sigmoid(gate[:, ds*3:]), \n",
        "            )\n",
        "            c_t = f_t * c_t + i_t * g_t\n",
        "            h_t = o_t * torch.tanh(c_t)\n",
        "\n",
        "        if (self.drop != None):\n",
        "          h_t = self.dropout(h_t)\n",
        "          out = self.linear(h_t)\n",
        "        else:\n",
        "          out = self.linear(h_t)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1kcNXEgMsOa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WViByftN3h-8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "ff0f0422b49f4aa9b0632a0573d30b2e",
            "5471e625cda04393bc4bfbb9f904eb5d",
            "3c8f00b706c743a89b2dab5b2851d4b2",
            "b6434c2ded094f8f84ee2ee495bcd4a8",
            "ebe4053d9b2c4971918ef75a0251c2ff",
            "401e1dd788914e61be8942864c72e90f",
            "965d8a17c0b646cbad7d290ad5b654d3",
            "61ab58a234114f459aec31ad33094f61",
            "19ea265e8f6247f1bf2912d9abab1d15",
            "d09769c62a8b4cf5a8c565ec5ab7e263",
            "9f2cc3ccd387455796011c91b6a594e6"
          ]
        },
        "outputId": "34acfa2e-1a30-4985-b9c4-755ad28cd90e"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "sst_dataset = load_dataset('sst')\n",
        "\n",
        "\n",
        "train_df=pd.DataFrame.from_dict(sst_dataset['train'])\n",
        "train_df['label'] = train_df['label'].apply(lambda x: round(x))\n",
        "\n",
        "val_df=pd.DataFrame.from_dict(sst_dataset['validation'])\n",
        "val_df['label'] = val_df['label'].apply(lambda x: round(x))\n",
        "\n",
        "test_df=pd.DataFrame.from_dict(sst_dataset['test'])\n",
        "test_df['label'] = test_df['label'].apply(lambda x: round(x))\n",
        "\n",
        "max_len, data, labels =get_tokens_ids(word2id, train_df, 16)\n",
        "val_max_len, val_data, val_labels =get_tokens_ids(word2id, val_df, 16)\n",
        "test_max_len, test_data, test_labels =get_tokens_ids(word2id, test_df, 16)\n",
        "# print(test_data.shape)\n",
        "# print(test_labels.shape)\n",
        "# print(test_max_len)\n",
        "# print(data.shape)\n",
        "# print(labels.shape)\n",
        "print(max_len)\n",
        "\n",
        "\n",
        "train_set = TensorDataset(data, labels)\n",
        "valid_set = TensorDataset(val_data, val_labels)\n",
        "test_set = TensorDataset(test_data, test_labels)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_set, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_set, shuffle=False, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No config specified, defaulting to: sst/default\n",
            "Reusing dataset sst (/root/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff0f0422b49f4aa9b0632a0573d30b2e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RJJ8v2gcAi5",
        "outputId": "af8b1032-024c-477c-b493-dd87d22f376b"
      },
      "source": [
        "d = 100 # size of word-embedding\n",
        "num_epochs = 50\n",
        "model = LSTM(d=100).cuda()\n",
        "\n",
        "train(model, train_loader, valid_loader, num_epochs, 'lstm20_best_model.pth')\n",
        "# train_loss, train_acc, val_loss, val_acc = train(model, train_loader, valid_loader, num_epochs, 'lstm2_best_model.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.53it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 193.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 49.40, Val_Acc- 49.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.35it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 194.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.33, Val_Acc- 49.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.96it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 181.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.88, Val_Acc- 49.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.41it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 205.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 49.73, Val_Acc- 50.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.30it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 201.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.63, Val_Acc- 50.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.13it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 193.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.23, Val_Acc- 49.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.21it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 197.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 49.71, Val_Acc- 50.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.63it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 186.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.05, Val_Acc- 51.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.90it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 168.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.82, Val_Acc- 49.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.03it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 190.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.74, Val_Acc- 49.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.28it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 197.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.64, Val_Acc- 52.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.41it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 174.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 11: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.07, Val_Acc- 53.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 52.04it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 186.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 12: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.90, Val_Acc- 50.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.38it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 188.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 13: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.65, Val_Acc- 53.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.23it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 184.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 14: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.73, Val_Acc- 51.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.91it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 184.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 15: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.72, Val_Acc- 49.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 52.04it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 203.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 16: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 52.31, Val_Acc- 53.95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.68it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 183.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 17: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 52.28, Val_Acc- 50.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 49.88it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 193.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 18: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.91, Val_Acc- 54.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.03it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 196.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 19: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 53.00, Val_Acc- 51.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.95it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 193.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 20: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 53.50, Val_Acc- 50.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.25it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 194.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 21: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 54.42, Val_Acc- 52.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.62it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 183.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 22: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 54.85, Val_Acc- 56.58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.47it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 192.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 23: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 55.49, Val_Acc- 58.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.46it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 196.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 24: Training_Loss- 0.021, Val_Loss- 0.021, Training_Acc- 57.49, Val_Acc- 59.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.48it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 203.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 25: Training_Loss- 0.021, Val_Loss- 0.021, Training_Acc- 57.87, Val_Acc- 56.58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 52.03it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 185.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 26: Training_Loss- 0.021, Val_Loss- 0.021, Training_Acc- 59.01, Val_Acc- 59.40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.45it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 190.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 27: Training_Loss- 0.021, Val_Loss- 0.021, Training_Acc- 61.00, Val_Acc- 59.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 52.31it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 201.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 28: Training_Loss- 0.020, Val_Loss- 0.022, Training_Acc- 62.87, Val_Acc- 57.95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.94it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 189.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 29: Training_Loss- 0.020, Val_Loss- 0.020, Training_Acc- 64.20, Val_Acc- 63.40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.63it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 191.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 30: Training_Loss- 0.019, Val_Loss- 0.020, Training_Acc- 66.12, Val_Acc- 64.31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.78it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 191.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 31: Training_Loss- 0.019, Val_Loss- 0.023, Training_Acc- 67.38, Val_Acc- 58.31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.97it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 188.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 32: Training_Loss- 0.019, Val_Loss- 0.019, Training_Acc- 68.55, Val_Acc- 69.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.42it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 204.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 33: Training_Loss- 0.018, Val_Loss- 0.020, Training_Acc- 70.51, Val_Acc- 64.85\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.95it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 188.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 34: Training_Loss- 0.017, Val_Loss- 0.021, Training_Acc- 72.23, Val_Acc- 64.49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 49.98it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 201.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 35: Training_Loss- 0.017, Val_Loss- 0.019, Training_Acc- 73.36, Val_Acc- 66.94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.57it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 189.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 36: Training_Loss- 0.017, Val_Loss- 0.019, Training_Acc- 74.25, Val_Acc- 68.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.82it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 188.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 37: Training_Loss- 0.016, Val_Loss- 0.018, Training_Acc- 75.37, Val_Acc- 69.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.24it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 187.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 38: Training_Loss- 0.016, Val_Loss- 0.019, Training_Acc- 76.98, Val_Acc- 69.03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.42it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 198.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 39: Training_Loss- 0.015, Val_Loss- 0.020, Training_Acc- 77.19, Val_Acc- 67.03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.11it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 192.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 40: Training_Loss- 0.015, Val_Loss- 0.020, Training_Acc- 77.90, Val_Acc- 67.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.14it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 172.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 41: Training_Loss- 0.015, Val_Loss- 0.020, Training_Acc- 79.10, Val_Acc- 70.03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.99it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 193.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 42: Training_Loss- 0.014, Val_Loss- 0.019, Training_Acc- 79.89, Val_Acc- 70.03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.39it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 184.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 43: Training_Loss- 0.014, Val_Loss- 0.020, Training_Acc- 80.75, Val_Acc- 70.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 49.43it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 197.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 44: Training_Loss- 0.013, Val_Loss- 0.020, Training_Acc- 81.41, Val_Acc- 70.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.02it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 197.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 45: Training_Loss- 0.013, Val_Loss- 0.024, Training_Acc- 81.79, Val_Acc- 65.21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.00it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 163.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 46: Training_Loss- 0.013, Val_Loss- 0.020, Training_Acc- 82.07, Val_Acc- 69.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.58it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 177.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 47: Training_Loss- 0.012, Val_Loss- 0.020, Training_Acc- 83.19, Val_Acc- 71.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.98it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 176.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 48: Training_Loss- 0.012, Val_Loss- 0.019, Training_Acc- 84.29, Val_Acc- 69.94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.27it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 192.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 49: Training_Loss- 0.011, Val_Loss- 0.020, Training_Acc- 85.45, Val_Acc- 71.57\n",
            "Best accuracy at epoch: 49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Is-56J1tSdMQ",
        "outputId": "63208d0d-75a5-44de-c6ca-08f931aabaf7"
      },
      "source": [
        "test(model, test_loader, file = 'lstm20_best_model.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [00:00<00:00, 148.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0184, Accuracy: 1587/2210 (71.81%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iYWaFPQYPGh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99b70ec4-3977-4188-a4c6-a8321b76fa16"
      },
      "source": [
        "test(model, valid_loader, file = 'lstm20_best_model.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:00<00:00, 151.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0197, Accuracy: 788/1101 (71.57%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4ZAi14PZnKa"
      },
      "source": [
        "#### $\\color{red}{\\text{Solution 4.1}}$\n",
        "<font color='red'> We trained the model for 50 epochs and the validation and test accuracy are respectively. We trained two lstm the first using the linear layer from pytorch and the second based on nn.parameter from pytorch library. Both model achieve similar result but the nn.parameter based model achieve the best result with sequence length set to 16 and 8. The experiment on local machine demonstrated that the model fails to properly learn for larger sequence length as showed below. In our experiment the LSTM is the better than the previous methods.\n",
        ".<font>\n",
        "\n",
        "Sequences length=52 validation accuracy =50.68 test accuracy=51.72 best epoch =1\n",
        "    \n",
        "Sequences length=40 validation accuracy =50.68 test accuracy=51.72 best epoch =3\n",
        "    \n",
        "Sequences length=32 validation accuracy =52.59 test accuracy=51.49 best epoch =45\n",
        "    \n",
        "Sequences length=16 validation accuracy=72.12 test accuracy=72.35 best epoch =47\n",
        "    \n",
        "Sequences length=8 validation accuracy =67.39 test accuracy=67.19  best epoch =37"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6boSxKjC4Mw"
      },
      "source": [
        "\n",
        "\n",
        "> **Problem 4.2** *(2 points)* Use Dropout on LSTM (either at input or output). Report the accuracy on the dev data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SugKeRzm4iqO",
        "outputId": "70dfd365-97db-4b4e-a990-b00f82e579f5"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "sst_dataset = load_dataset('sst')\n",
        "\n",
        "\n",
        "train_df=pd.DataFrame.from_dict(sst_dataset['train'])\n",
        "train_df['label'] = train_df['label'].apply(lambda x: round(x))\n",
        "\n",
        "val_df=pd.DataFrame.from_dict(sst_dataset['validation'])\n",
        "val_df['label'] = val_df['label'].apply(lambda x: round(x))\n",
        "\n",
        "test_df=pd.DataFrame.from_dict(sst_dataset['test'])\n",
        "test_df['label'] = test_df['label'].apply(lambda x: round(x))\n",
        "\n",
        "max_len, data, labels =get_tokens_ids(word2id, train_df, 16)\n",
        "val_max_len, val_data, val_labels =get_tokens_ids(word2id, val_df, 16)\n",
        "test_max_len, test_data, test_labels =get_tokens_ids(word2id, test_df, 16)\n",
        "# print(test_data.shape)\n",
        "# print(test_labels.shape)\n",
        "# print(test_max_len)\n",
        "# print(data.shape)\n",
        "# print(labels.shape)\n",
        "print(max_len)\n",
        "\n",
        "\n",
        "train_set = TensorDataset(data, labels)\n",
        "valid_set = TensorDataset(val_data, val_labels)\n",
        "test_set = TensorDataset(test_data, test_labels)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_set, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_set, shuffle=False, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No config specified, defaulting to: sst/default\n",
            "Reusing dataset sst (/home/soro/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSfiMREjYWWj",
        "outputId": "2dfa5008-5cfa-4191-98b6-0fbf650c26d1"
      },
      "source": [
        "d = 100 # size of word-embedding\n",
        "num_epochs = 50\n",
        "model = LSTM(d,'dropout').cuda()\n",
        "train(model, train_loader, valid_loader, num_epochs, 'lstm_drop_best_model.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.01it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 193.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.15, Val_Acc- 50.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.25it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 182.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.12, Val_Acc- 50.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.50it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 168.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.26, Val_Acc- 50.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.65it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 191.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.61, Val_Acc- 49.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.04it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 198.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.13, Val_Acc- 51.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.33it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 184.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.08, Val_Acc- 50.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.90it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 184.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 49.95, Val_Acc- 50.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.43it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 203.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.33, Val_Acc- 52.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.77it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 185.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 49.81, Val_Acc- 49.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.16it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 178.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.37, Val_Acc- 49.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.36it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 196.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.59, Val_Acc- 52.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 52.41it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 197.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 11: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.08, Val_Acc- 51.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.32it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 202.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 12: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.33, Val_Acc- 53.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.96it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 202.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 13: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.67, Val_Acc- 49.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.27it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 193.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 14: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.80, Val_Acc- 51.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.32it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 196.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 15: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.43, Val_Acc- 52.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.65it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 188.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 16: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.80, Val_Acc- 49.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.82it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 192.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 17: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.95, Val_Acc- 48.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.17it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 199.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 18: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.91, Val_Acc- 55.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.87it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 204.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 19: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 52.36, Val_Acc- 54.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.71it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 176.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 20: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 52.89, Val_Acc- 49.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.64it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 171.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 21: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 52.89, Val_Acc- 54.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.14it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 207.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 22: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 53.36, Val_Acc- 54.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.23it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 176.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 23: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 54.56, Val_Acc- 52.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 52.04it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 174.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 24: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 55.63, Val_Acc- 57.58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 52.33it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 191.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 25: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 56.51, Val_Acc- 56.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.00it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 195.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 26: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 57.32, Val_Acc- 57.40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 52.22it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 199.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 27: Training_Loss- 0.021, Val_Loss- 0.021, Training_Acc- 58.75, Val_Acc- 59.58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 52.56it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 184.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 28: Training_Loss- 0.021, Val_Loss- 0.021, Training_Acc- 59.87, Val_Acc- 58.95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.87it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 185.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 29: Training_Loss- 0.020, Val_Loss- 0.021, Training_Acc- 61.58, Val_Acc- 62.76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.20it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 204.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 30: Training_Loss- 0.020, Val_Loss- 0.021, Training_Acc- 63.27, Val_Acc- 58.76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.47it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 190.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 31: Training_Loss- 0.020, Val_Loss- 0.020, Training_Acc- 65.27, Val_Acc- 66.67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 52.11it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 206.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 32: Training_Loss- 0.019, Val_Loss- 0.019, Training_Acc- 67.26, Val_Acc- 67.85\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.79it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 199.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 33: Training_Loss- 0.019, Val_Loss- 0.019, Training_Acc- 67.84, Val_Acc- 69.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 52.71it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 170.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 34: Training_Loss- 0.018, Val_Loss- 0.021, Training_Acc- 70.42, Val_Acc- 64.03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 52.08it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 198.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 35: Training_Loss- 0.018, Val_Loss- 0.019, Training_Acc- 71.25, Val_Acc- 68.39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.78it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 195.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 36: Training_Loss- 0.017, Val_Loss- 0.019, Training_Acc- 73.05, Val_Acc- 67.94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.00it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 174.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 37: Training_Loss- 0.017, Val_Loss- 0.020, Training_Acc- 74.09, Val_Acc- 68.39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.52it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 183.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 38: Training_Loss- 0.017, Val_Loss- 0.019, Training_Acc- 74.24, Val_Acc- 69.66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.77it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 182.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 39: Training_Loss- 0.016, Val_Loss- 0.020, Training_Acc- 76.22, Val_Acc- 67.67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.27it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 176.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 40: Training_Loss- 0.016, Val_Loss- 0.019, Training_Acc- 76.56, Val_Acc- 69.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.40it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 195.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 41: Training_Loss- 0.015, Val_Loss- 0.019, Training_Acc- 78.08, Val_Acc- 69.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.19it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 183.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 42: Training_Loss- 0.015, Val_Loss- 0.019, Training_Acc- 79.18, Val_Acc- 68.39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.86it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 190.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 43: Training_Loss- 0.015, Val_Loss- 0.019, Training_Acc- 78.86, Val_Acc- 69.94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 52.38it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 196.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 44: Training_Loss- 0.014, Val_Loss- 0.023, Training_Acc- 80.21, Val_Acc- 64.31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.19it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 184.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 45: Training_Loss- 0.014, Val_Loss- 0.019, Training_Acc- 80.78, Val_Acc- 71.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.75it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 173.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 46: Training_Loss- 0.014, Val_Loss- 0.021, Training_Acc- 81.00, Val_Acc- 69.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 50.27it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 195.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 47: Training_Loss- 0.013, Val_Loss- 0.020, Training_Acc- 82.20, Val_Acc- 68.76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.26it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 197.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 48: Training_Loss- 0.012, Val_Loss- 0.020, Training_Acc- 83.73, Val_Acc- 68.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:05<00:00, 51.33it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 184.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 49: Training_Loss- 0.012, Val_Loss- 0.021, Training_Acc- 84.00, Val_Acc- 69.85\n",
            "Best accuracy at epoch: 45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeQGNcn9cxDw",
        "outputId": "b2851a87-e419-4e47-ac13-730471bb93d9"
      },
      "source": [
        "test(model, test_loader, file = 'lstm_drop_best_model.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [00:00<00:00, 161.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0178, Accuracy: 1597/2210 (72.26%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMVRFnzdYPGi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee3ff2d8-9992-49c3-f9a5-a7cb5b60cabf"
      },
      "source": [
        "test(model, valid_loader, file = 'lstm_drop_best_model.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:00<00:00, 155.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0187, Accuracy: 790/1101 (71.75%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD0211CFZvy1"
      },
      "source": [
        "#### $\\color{red}{\\text{Solution 4.2}}$\n",
        "<font color='red'> The drop out is inserted on the last hidden state before feeding to the ouput linear layer. The below results obatined on local machine with RTX2018 GPU show that the model learn too slowly for smaller sequence lengths and does not not learn for larger sequence length. and for large sequence size the model fails to learn similar to the LSTM and method. The drop out operation has not improve the performance significantly. That could be due to the fact that the model is underfitting.</font>\n",
        "\n",
        "Sequences length=52 validation accuracy =50.68 test accuracy=51.72 best epoch =1\n",
        "    \n",
        "Sequences length=40 validation accuracy =50.68 test accuracy=51.72 best epoch =3\n",
        "    \n",
        "Sequences length=32 validation accuracy =50.96 test accuracy=51.40 best epoch =45\n",
        "    \n",
        "Sequences length=16 validation accuracy=71.75 test accuracy=72.26 best epoch =46\n",
        "    \n",
        "Sequences length=8 validation accuracy =55.04 test accuracy=52.71 best epoch =30\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4ZBOzVSk31j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SVdtWzMk34V"
      },
      "source": [
        "# class CustomLSTM(nn.Module):\n",
        "#     def __init__(self, input_sz, hidden_sz):\n",
        "#         super().__init__()\n",
        "#         self.input_sz = input_sz\n",
        "#         self.hidden_size = hidden_sz\n",
        "#         self.W = nn.Parameter(torch.Tensor(input_sz, hidden_sz * 4))\n",
        "#         self.U = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz * 4))\n",
        "#         self.bias = nn.Parameter(torch.Tensor(hidden_sz * 4))\n",
        "#         self.init_weights()\n",
        "                \n",
        "#     def init_weights(self):\n",
        "#         stdv = 1.0 / math.sqrt(self.hidden_size)\n",
        "#         for weight in self.parameters():\n",
        "#             weight.data.uniform_(-stdv, stdv)\n",
        "         \n",
        "#     def forward(self, x, \n",
        "#                 init_states=None):\n",
        "\n",
        "#         bs, seq_sz, _ = x.size()\n",
        "#         hidden_seq = []\n",
        "#         if init_states is None:\n",
        "#             h_t, c_t = (torch.zeros(bs, self.hidden_size).to(x.device), \n",
        "#                         torch.zeros(bs, self.hidden_size).to(x.device))\n",
        "#         else:\n",
        "#             h_t, c_t = init_states\n",
        "         \n",
        "#         HS = self.hidden_size\n",
        "#         for t in range(seq_sz):\n",
        "#             x_t = x[:, t, :]\n",
        "#             # batch the computations into a single matrix multiplication\n",
        "#             gates = x_t @ self.W + h_t @ self.U + self.bias\n",
        "#             i_t, f_t, g_t, o_t = (\n",
        "#                 torch.sigmoid(gates[:, :HS]), # input\n",
        "#                 torch.sigmoid(gates[:, HS:HS*2]), # forget\n",
        "#                 torch.tanh(gates[:, HS*2:HS*3]),\n",
        "#                 torch.sigmoid(gates[:, HS*3:]), # output\n",
        "#             )\n",
        "#             c_t = f_t * c_t + i_t * g_t\n",
        "#             h_t = o_t * torch.tanh(c_t)\n",
        "#             hidden_seq.append(h_t.unsqueeze(0))\n",
        "#         hidden_seq = torch.cat(hidden_seq, dim=0)\n",
        "#         # reshape from shape (sequence, batch, feature) to (batch, sequence, feature)\n",
        "#         hidden_seq = hidden_seq.transpose(0, 1).contiguous()\n",
        "#         return hidden_seq, (h_t, c_t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyVz4jy-ZV8v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXSPm7QCjinq"
      },
      "source": [
        "> **Problem 4.3 (bonus)** *(2 points)* Consider implementing bidirectional LSTM and two layers of LSTM. Concatenate the forward direction output at the final time step and the backward direction output at the first time step for the final classificaiton. Report your accuracy on dev data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYBKAd4IcxGr"
      },
      "source": [
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, d, dropout = None):\n",
        "\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.input_size = d\n",
        "        self.hidden_size = d\n",
        "        self.output_size = 2\n",
        "\n",
        "        self.embedding = nn.Embedding(len(vocab), self.input_size)\n",
        "        # forward lstm parameters\n",
        "        self.forward_W = nn.Parameter(torch.Tensor(self.input_size, self.hidden_size * 4))\n",
        "        self.forward_U = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size * 4))\n",
        "        self.forward_b = nn.Parameter(torch.Tensor(self.hidden_size * 4))\n",
        "      #backward lstm parameters\n",
        "        self.backward_W = nn.Parameter(torch.Tensor(self.input_size, self.hidden_size * 4))\n",
        "        self.backward_U = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size * 4))\n",
        "        self.backward_b = nn.Parameter(torch.Tensor(self.hidden_size * 4))\n",
        "\n",
        "        self.linear = nn.Linear(self.hidden_size*2, self.output_size, bias=True) \n",
        "\n",
        "        self.init_weights()\n",
        "                \n",
        "    def init_weights(self):\n",
        "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for weight in self.parameters():\n",
        "            weight.data.uniform_(-stdv, stdv)\n",
        "         \n",
        "    def forward(self, input):\n",
        "        \"\"\"Assumes x is of shape (batch, sequence, feature)\"\"\"\n",
        "       \n",
        "        emb = self.embedding(input)\n",
        "        batch_size = emb.shape[0]\n",
        "\n",
        "        forward_pass = []\n",
        "        backward_pass = []\n",
        "        h_t_forward, c_t_forward = (torch.zeros(batch_size, self.hidden_size).to(emb.device), \n",
        "                        torch.zeros(batch_size, self.hidden_size).to(emb.device))\n",
        "        h_t_backward, c_t_backward = (torch.zeros(batch_size, self.hidden_size).to(emb.device), \n",
        "                        torch.zeros(batch_size, self.hidden_size).to(emb.device))\n",
        "          \n",
        "        ds = self.hidden_size \n",
        "        for t in range(emb.shape[1]):\n",
        "            emb_t = emb[:, t, :]\n",
        "            gate = emb_t @ self.forward_W + h_t_forward @ self.forward_U + self.forward_b\n",
        "            i_t, f_t, g_t, o_t = (\n",
        "                torch.sigmoid(gate[:, :ds]), \n",
        "                torch.sigmoid(gate[:, ds:ds*2]),  \n",
        "                torch.tanh(gate[:, ds*2:ds*3]),\n",
        "                torch.sigmoid(gate[:, ds*3:]), \n",
        "            )\n",
        "            c_t_forward = f_t * c_t_forward + i_t * g_t\n",
        "            h_t_forward = o_t * torch.tanh(c_t_forward)\n",
        "            forward_pass.append(h_t_forward)\n",
        "\n",
        "        for t in reversed(range(emb.shape[1])):\n",
        "            emb_t = emb[:, t, :]\n",
        "            gate = emb_t @ self.backward_W + h_t_backward @ self.backward_U + self.backward_b\n",
        "            i_t, f_t, g_t, o_t = (\n",
        "                torch.sigmoid(gate[:, :ds]), \n",
        "                torch.sigmoid(gate[:, ds:ds*2]),  \n",
        "                torch.tanh(gate[:, ds*2:ds*3]),\n",
        "                torch.sigmoid(gate[:, ds*3:]), \n",
        "            )\n",
        "            c_t_backward = f_t * c_t_backward + i_t * g_t\n",
        "            h_t_backward = o_t * torch.tanh(c_t_backward)\n",
        "            backward_pass.append(h_t_backward)\n",
        "\n",
        "        h_final= torch.cat((h_t_forward, h_t_backward), 1)\n",
        "        out = self.linear(h_final)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giXyHV5nYPGl",
        "outputId": "33d00553-a5c6-45ce-d8cb-40043154614f"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "sst_dataset = load_dataset('sst')\n",
        "\n",
        "\n",
        "train_df=pd.DataFrame.from_dict(sst_dataset['train'])\n",
        "train_df['label'] = train_df['label'].apply(lambda x: round(x))\n",
        "\n",
        "val_df=pd.DataFrame.from_dict(sst_dataset['validation'])\n",
        "val_df['label'] = val_df['label'].apply(lambda x: round(x))\n",
        "\n",
        "test_df=pd.DataFrame.from_dict(sst_dataset['test'])\n",
        "test_df['label'] = test_df['label'].apply(lambda x: round(x))\n",
        "\n",
        "max_len, data, labels =get_tokens_ids(word2id, train_df, 8)\n",
        "val_max_len, val_data, val_labels =get_tokens_ids(word2id, val_df, 8)\n",
        "test_max_len, test_data, test_labels =get_tokens_ids(word2id, test_df, 8)\n",
        "# print(test_data.shape)\n",
        "# print(test_labels.shape)\n",
        "# print(test_max_len)\n",
        "# print(data.shape)\n",
        "# print(labels.shape)\n",
        "print(max_len)\n",
        "\n",
        "\n",
        "train_set = TensorDataset(data, labels)\n",
        "valid_set = TensorDataset(val_data, val_labels)\n",
        "test_set = TensorDataset(test_data, test_labels)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_set, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_set, shuffle=False, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No config specified, defaulting to: sst/default\n",
            "Reusing dataset sst (/home/soro/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0Nh6zJCYPUj",
        "outputId": "f7aad5c9-70a0-4efc-d357-00af3ab4cc43"
      },
      "source": [
        "d = 100\n",
        "num_epochs = 50\n",
        "model = BiLSTM(d).cuda()\n",
        "train(model, train_loader, valid_loader, num_epochs, 'bilstm_best_model.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 113.48it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 462.20it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 114.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.99, Val_Acc- 49.32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 111.45it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 452.27it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 112.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.98, Val_Acc- 50.68\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 111.81it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 452.69it/s]\n",
            "  4%|▍         | 11/267 [00:00<00:02, 107.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 51.74, Val_Acc- 53.04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 111.21it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 453.80it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 110.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 52.98, Val_Acc- 57.67\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 112.90it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 439.10it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 113.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 53.45, Val_Acc- 56.68\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 113.25it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 431.77it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 114.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 54.62, Val_Acc- 57.86\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 114.75it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 465.17it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 115.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 6: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 54.65, Val_Acc- 56.68\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 115.11it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 458.31it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 111.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 7: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 55.62, Val_Acc- 53.68\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 115.34it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 436.43it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 116.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 8: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 56.51, Val_Acc- 58.04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 114.57it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 446.54it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 115.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 9: Training_Loss- 0.021, Val_Loss- 0.021, Training_Acc- 56.91, Val_Acc- 58.67\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 116.28it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 450.40it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 114.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 10: Training_Loss- 0.021, Val_Loss- 0.021, Training_Acc- 57.60, Val_Acc- 58.58\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 116.10it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 446.30it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 115.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 11: Training_Loss- 0.021, Val_Loss- 0.021, Training_Acc- 57.24, Val_Acc- 58.04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 115.40it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 448.53it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 112.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 12: Training_Loss- 0.021, Val_Loss- 0.021, Training_Acc- 58.80, Val_Acc- 58.76\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 113.68it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 449.20it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 112.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 13: Training_Loss- 0.021, Val_Loss- 0.021, Training_Acc- 60.23, Val_Acc- 59.67\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 112.95it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 445.36it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 111.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 14: Training_Loss- 0.021, Val_Loss- 0.021, Training_Acc- 60.84, Val_Acc- 60.49\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 112.01it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 446.88it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 111.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 15: Training_Loss- 0.020, Val_Loss- 0.020, Training_Acc- 62.49, Val_Acc- 61.85\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 112.01it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 451.72it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 111.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 16: Training_Loss- 0.020, Val_Loss- 0.020, Training_Acc- 63.83, Val_Acc- 60.85\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 110.87it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 448.52it/s]\n",
            "  4%|▍         | 11/267 [00:00<00:02, 109.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 17: Training_Loss- 0.019, Val_Loss- 0.021, Training_Acc- 66.25, Val_Acc- 58.76\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 112.59it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 439.21it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 113.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 18: Training_Loss- 0.019, Val_Loss- 0.020, Training_Acc- 67.64, Val_Acc- 63.22\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 112.57it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 458.65it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 114.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 19: Training_Loss- 0.018, Val_Loss- 0.019, Training_Acc- 70.19, Val_Acc- 65.03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 113.94it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 463.58it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 111.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 20: Training_Loss- 0.017, Val_Loss- 0.020, Training_Acc- 71.36, Val_Acc- 64.85\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 112.23it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 465.75it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 115.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 21: Training_Loss- 0.017, Val_Loss- 0.019, Training_Acc- 72.98, Val_Acc- 66.12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 113.60it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 449.27it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 113.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 22: Training_Loss- 0.016, Val_Loss- 0.020, Training_Acc- 74.39, Val_Acc- 65.49\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 113.20it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 449.11it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 112.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 23: Training_Loss- 0.016, Val_Loss- 0.019, Training_Acc- 75.95, Val_Acc- 66.58\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 113.70it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 463.87it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 113.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 24: Training_Loss- 0.015, Val_Loss- 0.021, Training_Acc- 76.98, Val_Acc- 64.12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 113.79it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 323.55it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 113.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 25: Training_Loss- 0.014, Val_Loss- 0.021, Training_Acc- 78.58, Val_Acc- 66.12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 112.61it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 452.79it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 112.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 26: Training_Loss- 0.014, Val_Loss- 0.021, Training_Acc- 79.13, Val_Acc- 65.40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 112.08it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 437.36it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 113.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 27: Training_Loss- 0.013, Val_Loss- 0.024, Training_Acc- 79.95, Val_Acc- 63.67\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 113.59it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 449.86it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 112.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 28: Training_Loss- 0.013, Val_Loss- 0.021, Training_Acc- 81.14, Val_Acc- 68.21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 113.19it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 430.07it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 111.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 29: Training_Loss- 0.013, Val_Loss- 0.022, Training_Acc- 82.08, Val_Acc- 66.49\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 114.05it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 442.56it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 110.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 30: Training_Loss- 0.012, Val_Loss- 0.022, Training_Acc- 82.37, Val_Acc- 66.94\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 110.73it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 465.87it/s]\n",
            "  4%|▍         | 11/267 [00:00<00:02, 109.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 31: Training_Loss- 0.012, Val_Loss- 0.025, Training_Acc- 83.27, Val_Acc- 64.49\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 110.21it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 429.15it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 114.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 32: Training_Loss- 0.011, Val_Loss- 0.023, Training_Acc- 83.73, Val_Acc- 63.94\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 117.13it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 320.18it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 117.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 33: Training_Loss- 0.011, Val_Loss- 0.028, Training_Acc- 85.15, Val_Acc- 63.58\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 109.14it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 429.24it/s]\n",
            "  4%|▍         | 11/267 [00:00<00:02, 108.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 34: Training_Loss- 0.011, Val_Loss- 0.024, Training_Acc- 85.48, Val_Acc- 66.58\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 110.53it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 419.86it/s]\n",
            "  4%|▍         | 11/267 [00:00<00:02, 105.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 35: Training_Loss- 0.010, Val_Loss- 0.024, Training_Acc- 85.83, Val_Acc- 65.76\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 113.85it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 468.29it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 119.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 36: Training_Loss- 0.010, Val_Loss- 0.026, Training_Acc- 86.10, Val_Acc- 64.85\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 114.78it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 473.83it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 119.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 37: Training_Loss- 0.010, Val_Loss- 0.025, Training_Acc- 86.79, Val_Acc- 66.03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 118.03it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 468.12it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 118.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 38: Training_Loss- 0.009, Val_Loss- 0.026, Training_Acc- 87.58, Val_Acc- 65.12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 117.03it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 475.47it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 116.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 39: Training_Loss- 0.009, Val_Loss- 0.026, Training_Acc- 87.34, Val_Acc- 66.12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 116.77it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 468.02it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 113.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 40: Training_Loss- 0.009, Val_Loss- 0.030, Training_Acc- 88.69, Val_Acc- 64.12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 116.52it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 476.45it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 119.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 41: Training_Loss- 0.008, Val_Loss- 0.030, Training_Acc- 88.99, Val_Acc- 65.21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 115.96it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 474.87it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 117.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 42: Training_Loss- 0.008, Val_Loss- 0.029, Training_Acc- 89.34, Val_Acc- 66.12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 117.23it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 450.96it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 114.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 43: Training_Loss- 0.008, Val_Loss- 0.034, Training_Acc- 89.41, Val_Acc- 61.94\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 116.87it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 467.40it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 117.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 44: Training_Loss- 0.008, Val_Loss- 0.030, Training_Acc- 89.90, Val_Acc- 63.31\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 115.69it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 469.37it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 113.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 45: Training_Loss- 0.007, Val_Loss- 0.032, Training_Acc- 90.93, Val_Acc- 63.31\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 112.36it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 451.94it/s]\n",
            "  4%|▎         | 10/267 [00:00<00:02, 96.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 46: Training_Loss- 0.007, Val_Loss- 0.034, Training_Acc- 90.84, Val_Acc- 65.21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 111.49it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 447.57it/s]\n",
            "  4%|▍         | 12/267 [00:00<00:02, 116.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 47: Training_Loss- 0.007, Val_Loss- 0.034, Training_Acc- 91.14, Val_Acc- 64.85\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 113.69it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 443.59it/s]\n",
            "  4%|▎         | 10/267 [00:00<00:02, 94.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 48: Training_Loss- 0.007, Val_Loss- 0.033, Training_Acc- 91.25, Val_Acc- 66.94\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:02<00:00, 114.08it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 467.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 49: Training_Loss- 0.007, Val_Loss- 0.037, Training_Acc- 91.94, Val_Acc- 63.67\n",
            "Best accuracy at epoch: 28\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAz2A_5yYPGl",
        "outputId": "1f9615fc-788d-441f-9d93-e25a99badcfb"
      },
      "source": [
        "test(model, test_loader, file = 'bilstm_best_model.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70/70 [00:00<00:00, 351.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0201, Accuracy: 1513/2210 (68.46%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oig7EKJ1YPGm",
        "outputId": "a57fa41e-aa71-41dc-b019-eb63400802c5"
      },
      "source": [
        "test(model, valid_loader, file = 'bilstm_best_model.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:00<00:00, 351.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0205, Accuracy: 751/1101 (68.21%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kP43B_XYPGm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-ojaGKBuY2Z"
      },
      "source": [
        "#### $\\color{red}{\\text{Solution 4.3}}$\n",
        "\n",
        "<font color='red'> We trained the model for 50 epochs with different sequence length on local machine. The bidirectionnal LSTM outperformed all the previous methods tested in this study for the different sequence length. the best performance is achieve with sequence length set 40 which is 73.48% and 73.30 for the validation and test set respectively.<font>\n",
        "\n",
        "Sequences length=52 validation accuracy =72.39 test accuracy=72.26 best epoch =45\n",
        "    \n",
        "Sequences length=40 validation accuracy =73.48 test accuracy=73.30 best epoch =33\n",
        "    \n",
        "Sequences length=32 validation accuracy =72.66 test accuracy=71.76 best epoch =37\n",
        "    \n",
        "Sequences length=16 validation accuracy=71.03 test accuracy=71.76 best epoch =47\n",
        "    \n",
        "Sequences length=8 validation accuracy =68.21 test accuracy=68.30 best epoch =34 \n",
        "    \n",
        "Sequences length=24 validation accuracy =73.02 test accuracy=73.12 best epoch =42"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axYapdsxc6FO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "855DrT78DXps"
      },
      "source": [
        "## 5. Pretrained Word Vectors\n",
        "The last step is to use pretrained vocabulary and word vectors. The prebuilt vocabulary will replace the vocabulary you built with SST training data, and the word vectors will replace the embedding vectors. You will observe the power of leveraging self-supservised pretrained models.\n",
        "\n",
        "> **Problem 5.1 (bonus)** *(2 points)* Go to https://nlp.stanford.edu/projects/glove/ and download `glove.6B.zip`. Use these pretrained word vectors to replace word embeddings in your model from 4.2. Report the model's accuracy on the dev data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJapnKsUaSIL",
        "outputId": "f932b7c4-00a2-491e-9f88-00b11aa93721"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-26 09:06:29--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-09-26 09:06:29--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-09-26 09:06:29--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.11MB/s    in 2m 40s  \n",
            "\n",
            "2021-09-26 09:09:09 (5.14 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GO_L6mkkkeP"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHfBAGWhgZTj"
      },
      "source": [
        "glove = pd.read_csv('glove.6B.100d.txt', sep=\" \", quoting=3, header=None, index_col=0)\n",
        "glove_embedding = {key: val.values for key, val in glove.T.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWaVOhJ9pZT5",
        "outputId": "68a62cb1-7cf2-4e60-cfeb-58b57503e55f"
      },
      "source": [
        "glove_embedding['bedtime']\n",
        "# word2id.items()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.038901 ,  0.14695  , -0.062946 ,  0.0076634, -1.4591   ,\n",
              "        1.2302   ,  0.045659 ,  0.41254  , -0.074825 , -0.30942  ,\n",
              "        0.69898  ,  0.38158  , -0.18333  ,  0.21672  ,  0.84012  ,\n",
              "       -0.17574  , -0.028191 , -0.15103  ,  0.22295  , -0.18099  ,\n",
              "        0.22464  , -0.6649   , -0.038821 ,  0.31431  ,  0.43477  ,\n",
              "        0.54241  , -0.46119  ,  0.068432 , -1.0356   ,  0.48924  ,\n",
              "       -0.09531  , -0.61189  ,  0.13242  , -0.36736  , -0.66299  ,\n",
              "        0.55532  , -0.58866  , -0.83158  , -0.025662 , -0.31443  ,\n",
              "        0.043428 ,  0.98309  , -0.48474  ,  0.042313 , -0.5515   ,\n",
              "       -0.087464 , -0.77318  , -0.46762  , -0.03519  , -0.70757  ,\n",
              "        0.35963  ,  0.11543  , -0.065643 ,  0.66271  , -0.34811  ,\n",
              "       -0.67678  ,  0.38171  ,  0.36789  , -0.030991 , -0.075245 ,\n",
              "       -0.26004  ,  0.45867  , -0.19097  , -0.82811  ,  0.18871  ,\n",
              "       -0.5021   ,  0.031506 , -0.51581  , -0.030224 , -0.33641  ,\n",
              "       -0.41555  , -0.23367  ,  1.0551   ,  0.49484  , -0.56004  ,\n",
              "        0.5095   , -0.44207  , -0.51873  ,  0.19986  , -0.75091  ,\n",
              "       -1.2188   ,  0.35203  ,  0.21421  , -0.067837 , -0.85289  ,\n",
              "        0.095032 , -0.24771  , -0.064864 , -0.47289  ,  0.35125  ,\n",
              "        0.47591  ,  0.86828  ,  0.85594  , -0.0062488, -1.0084   ,\n",
              "       -0.62948  ,  0.76544  , -0.6497   , -0.54344  ,  0.81965  ])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fCILLc7r_nI",
        "outputId": "16fd24c8-b17a-4d99-c71f-be9d9ae8ec12"
      },
      "source": [
        "glove_embedding['bedtime'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWzXHZI-ruog",
        "outputId": "015fec1a-dde3-459d-9076-ec4e868be095"
      },
      "source": [
        "word2id.items()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('PAD', 0), ('UNK', 1), ('captures', 2), ('disingenuous', 3), ('arguments', 4), ('.murderous', 5), ('girls', 6), ('threatens', 7), ('rifkin', 8), ('immensely', 9), ('exaggerated', 10), ('loses', 11), ('secrets', 12), ('unappealing', 13), ('stooping', 14), ('personality', 15), ('producers', 16), ('psychological', 17), ('.maybe', 18), ('fool', 19), ('.meyjes', 20), ('decade', 21), ('sickeningly', 22), ('greatness', 23), ('.blessed', 24), ('.hey', 25), ('assault', 26), ('proposal', 27), ('frustratingly', 28), ('impressed', 29), ('swallow', 30), ('reality', 31), ('illusion', 32), ('laughable', 33), ('ghost', 34), ('shrugging', 35), ('possess', 36), ('1915', 37), ('authentically', 38), ('humans', 39), ('tastelessness', 40), ('studio', 41), ('leave', 42), ('brief', 43), ('kumble', 44), ('cheated', 45), ('gags', 46), ('allen', 47), ('graham', 48), ('period', 49), (\"'re\", 50), ('communicates', 51), ('charmless', 52), ('goofy', 53), ('waking', 54), ('real', 55), ('him', 56), ('life', 57), ('locales', 58), ('lifts', 59), ('holm', 60), ('sucker', 61), ('liar', 62), ('libertine', 63), ('energy', 64), ('wrenching', 65), ('.parker', 66), ('potency', 67), ('skinny', 68), ('.cho', 69), ('stops', 70), ('predictability', 71), ('obviously', 72), ('gaza', 73), ('imaginable', 74), ('pellington', 75), ('clicks', 76), ('pathology', 77), ('results', 78), ('limit', 79), ('weighs', 80), ('pearl', 81), ('bodily', 82), ('script', 83), ('poorly', 84), ('duration', 85), ('paper', 86), ('kouyate', 87), ('greenlight', 88), ('turf', 89), ('signpost', 90), ('madonna', 91), ('.k-19', 92), ('familiar', 93), ('archival', 94), ('elsewhere', 95), ('jia', 96), ('shout', 97), ('provide', 98), ('pilot', 99), ('knew', 100), ('-', 101), ('imaginative', 102), ('climate', 103), ('rumination', 104), ('refuse', 105), ('angle', 106), ('unfunny', 107), ('indulgence', 108), ('gloss', 109), ('steals', 110), ('deserves', 111), ('antidote', 112), ('sensitivity', 113), ('blue', 114), ('.were', 115), ('shtick', 116), ('sociology', 117), ('feature-length', 118), ('monster', 119), ('reflect', 120), ('major', 121), ('chekhov', 122), ('certain', 123), ('bisset', 124), ('moves', 125), ('applies', 126), ('religion', 127), ('going', 128), ('simply', 129), ('truly', 130), ('boom', 131), ('.me', 132), ('social', 133), ('thousand', 134), ('.some', 135), ('dependent', 136), ('characteristically', 137), ('forcefully', 138), ('...the', 139), ('.return', 140), ('.beautiful', 141), ('tolerance', 142), ('peace', 143), ('kline', 144), ('40', 145), ('markets', 146), ('clause', 147), ('muster', 148), ('exact', 149), ('.ritchie', 150), ('sell', 151), ('tagline', 152), ('rose-colored', 153), ('tiresome', 154), ('jaw-droppingly', 155), ('cup', 156), ('startling', 157), ('tradition', 158), ('yet', 159), ('called', 160), ('bear', 161), ('hands', 162), ('punk', 163), ('craftsmanship', 164), ('cleaner', 165), ('setup', 166), ('grant', 167), ('rolling', 168), ('would-be', 169), ('guaranteed', 170), ('vastly', 171), ('strained', 172), ('voices', 173), ('enemy', 174), ('.nothing', 175), ('pervasive', 176), ('insider', 177), ('bears', 178), ('piano', 179), ('region', 180), ('investigate', 181), ('left', 182), ('explosions', 183), ('increasingly', 184), ('under-inspired', 185), ('preemptive', 186), ('import', 187), ('echoes', 188), ('intellectual', 189), ('technological', 190), ('?a', 191), ('refusal', 192), ('loneliness', 193), ('spookiness', 194), ('adding', 195), ('macdowell', 196), ('wednesday', 197), ('unsuspecting', 198), ('over-the-top', 199), ('israel', 200), ('window', 201), ('anything', 202), ('wrestling', 203), ('chance', 204), ('spectacle', 205), ('high-octane', 206), ('self-reflection', 207), ('unremarkable', 208), ('.upper', 209), ('deceptions', 210), ('tragedies', 211), ('audiences', 212), ('hits', 213), ('stinks', 214), ('cooper', 215), ('sustains', 216), ('vincent', 217), ('blanks', 218), ('henry', 219), ('iq', 220), ('wave', 221), ('deliver', 222), ('wish', 223), ('plan', 224), ('.go', 225), ('ok', 226), ('fear', 227), ('.waydowntown', 228), ('pumpkin', 229), ('theatrical', 230), ('fatal', 231), ('dedication', 232), ('resorts', 233), ('elevate', 234), ('none', 235), ('expects', 236), ('eats', 237), ('beauty', 238), ('billy', 239), ('hate', 240), ('qualities', 241), ('male', 242), ('george', 243), ('travel', 244), ('alas', 245), ('abundant', 246), ('.then', 247), ('veneer', 248), ('extended', 249), ('down', 250), ('concocted', 251), ('rooting', 252), ('opts', 253), ('cinematography', 254), ('satisfied', 255), ('romantic', 256), ('matter', 257), ('visual', 258), ('academy', 259), ('12-year-old', 260), ('humanism', 261), ('toward', 262), ('die', 263), ('topless', 264), ('twisted', 265), ('friday', 266), ('weave', 267), ('primitive', 268), ('sources', 269), ('.perhaps', 270), ('sight', 271), ('gracefully', 272), ('contrivances', 273), ('kosashvili', 274), ('demands', 275), ('savvy', 276), ('charming', 277), ('twice', 278), ('scripts', 279), ('.colorful', 280), ('.parents', 281), ('sham', 282), ('singing', 283), ('asphalt', 284), ('shimmering', 285), ('ham-fisted', 286), ('aesthetic', 287), ('b', 288), ('third', 289), ('premise', 290), ('sitting', 291), ('disposable', 292), ('artistic', 293), ('lower', 294), ('!in', 295), ('somebody', 296), ('hopeless', 297), ('.britney', 298), ('pitch-perfect', 299), ('screenings', 300), ('office', 301), ('reaches', 302), ('conspiracies', 303), ('bleak', 304), ('rustic', 305), ('mediocrity', 306), ('dozens', 307), ('traffic', 308), ('anger', 309), ('nose', 310), ('chabrol', 311), ('creepiness', 312), ('artistry', 313), ('marred', 314), ('inescapable', 315), ('convincing', 316), ('challenges', 317), ('publishing', 318), ('care', 319), ('sometimes', 320), ('lilia', 321), ('inspiring', 322), ('usually', 323), ('ha', 324), ('.silly', 325), ('calibrated', 326), ('faced', 327), ('clear-eyed', 328), ('city', 329), ('wholly', 330), ('cannes', 331), ('sympathetic', 332), ('private', 333), ('preview', 334), ('dealing', 335), ('.aside', 336), ('digest', 337), ('winds', 338), ('grieving', 339), ('styles', 340), ('fiery', 341), ('family', 342), ('contemplative', 343), ('.enough', 344), ('shainberg', 345), ('bouncy', 346), ('pantheon', 347), ('mush', 348), ('turd', 349), ('embarrassed', 350), ('greatest', 351), ('academic', 352), ('reverence', 353), ('tootsie', 354), ('sober', 355), ('encourage', 356), ('.even', 357), ('awkwardness', 358), ('be', 359), ('friggin', 360), ('groove', 361), ('portrayal', 362), ('post', 363), ('quiet', 364), ('joie', 365), ('vast', 366), ('sprinkled', 367), ('crash', 368), ('achieve', 369), ('downfall', 370), ('awards', 371), ('older', 372), ('birthday', 373), ('.renner', 374), ('across', 375), ('ichi', 376), ('view', 377), ('.kaufman', 378), ('described', 379), ('parker', 380), ('wedding', 381), ('downbeat', 382), ('amid', 383), ('our', 384), ('wallace', 385), ('inner-city', 386), ('.uneven', 387), ('austerity', 388), ('dustin', 389), ('.lawrence', 390), ('blown', 391), ('bug-eyed', 392), ('mixes', 393), ('!', 394), ('set-up', 395), ('cyber', 396), ('sequel', 397), ('nerve', 398), ('turgid', 399), ('dope', 400), ('numerous', 401), ('that', 402), ('cube', 403), ('tops', 404), ('knows', 405), ('.schnitzler', 406), ('review', 407), ('actresses', 408), ('force', 409), ('shelf', 410), ('natural', 411), ('saturday', 412), ('sleeve', 413), ('lovers', 414), ('got', 415), ('.such', 416), ('.resident', 417), ('painted', 418), ('hindered', 419), ('.low', 420), ('sisterhood', 421), ('gained', 422), ('current', 423), ('.little', 424), ('derivative', 425), ('routines', 426), ('machine', 427), ('fulfill', 428), ('sorority', 429), ('represented', 430), ('......', 431), ('working-class', 432), ('unoriginal', 433), ('in-depth', 434), ('.barney', 435), ('yes', 436), ('painterly', 437), ('leash', 438), ('enthralling', 439), ('departure', 440), ('hanks', 441), ('boasting', 442), ('excesses', 443), ('despite', 444), ('stuck', 445), ('ages', 446), ('imagine', 447), ('reflective', 448), ('counter-cultural', 449), ('tolerate', 450), ('vapid', 451), ('dish', 452), ('lanes', 453), ('childhood', 454), ('schmaltz', 455), ('domestic', 456), ('convinced', 457), ('label', 458), ('cars', 459), ('bartlett', 460), ('yi', 461), ('muse', 462), ('one-sided', 463), ('definition', 464), ('rugrats', 465), ('relate', 466), ('temptation', 467), ('succumbing', 468), ('editing', 469), ('flickering', 470), ('ringing', 471), ('shadowy', 472), ('predisposed', 473), ('such', 474), ('immediately', 475), ('.watching', 476), ('showcase', 477), ('running', 478), ('nifty', 479), ('.one', 480), ('squandering', 481), ('second', 482), ('dutiful', 483), ('conscience', 484), ('inevitably', 485), ('consigned', 486), ('shrek', 487), ('reading', 488), ('ensues', 489), ('cocktail', 490), ('blended', 491), ('associated', 492), ('unlikely', 493), ('while', 494), ('goals', 495), ('lets', 496), ('twohy', 497), ('.any', 498), ('.starts', 499), ('salma', 500), ('.plays', 501), ('available', 502), ('sets', 503), ('peek', 504), ('nicest', 505), ('weekend', 506), ('untalented', 507), ('ming-liang', 508), ('sardonic', 509), ('has', 510), ('sweetly', 511), ('mesmerizing', 512), ('views', 513), ('glumly', 514), ('offers', 515), ('utter', 516), ('date', 517), ('updated', 518), ('embrace', 519), ('mature', 520), ('female', 521), ('paranoia', 522), ('.eric', 523), ('wry', 524), ('cherish', 525), ('ambrose', 526), ('ringu', 527), ('3', 528), ('would', 529), ('speculation', 530), ('measure', 531), ('.i', 532), ('lower-class', 533), ('demand', 534), ('lunacy', 535), ('banderas', 536), ('faces', 537), ('argue', 538), ('clothing', 539), ('enthusiastic', 540), ('swear', 541), ('jell', 542), ('parking', 543), ('highest', 544), ('committed', 545), ('celebrates', 546), ('pulpy', 547), ('childlike', 548), ('hopes', 549), ('conundrum', 550), ('xerox', 551), ('dumped', 552), ('endlessly', 553), ('latin', 554), ('o', 555), ('contradiction', 556), ('deadpan', 557), ('avant-garde', 558), ('awfully', 559), ('lessen', 560), ('experimentation', 561), ('theatre', 562), ('taste', 563), ('harder', 564), ('50-year-old', 565), ('lark', 566), ('carefully', 567), ('wertmuller', 568), ('horrifying', 569), ('.better', 570), ('reflection', 571), ('bothers', 572), ('overblown', 573), ('immaculate', 574), ('serious', 575), ('inexperienced', 576), ('.films', 577), ('erotic', 578), ('unholy', 579), ('scrutiny', 580), ('handed', 581), ('wearing', 582), ('comes', 583), ('thirteen', 584), ('compels', 585), ('jackson', 586), ('implausibility', 587), ('mishmash', 588), ('unpersuasive', 589), ('dopey', 590), ('duty', 591), ('next', 592), ('whitaker', 593), ('merges', 594), ('vardalos', 595), ('25', 596), ('evocation', 597), ('stoked', 598), ('cows', 599), ('emotional', 600), ('tapping', 601), ('fair', 602), ('levels', 603), ('underdog', 604), ('.dense', 605), ('bag', 606), ('unsentimental', 607), ('boasts', 608), ('shining', 609), ('.takes', 610), ('ambiguous', 611), ('hybrid', 612), ('tool', 613), ('astounding', 614), ('rage', 615), ('york', 616), ('probe', 617), ('sexually', 618), ('.insomnia', 619), ('451', 620), ('sporadic', 621), ('screwed-up', 622), ('.and', 623), ('sandler', 624), ('strands', 625), ('joy', 626), ('madness', 627), ('macabre', 628), ('ruins', 629), ('unbelievable', 630), ('remind', 631), ('spirit', 632), ('bought', 633), ('blaxploitation', 634), ('?there', 635), ('burkina', 636), ('authentic', 637), ('includes', 638), ('absorbing', 639), ('lying', 640), ('.not', 641), ('vein', 642), ('employment', 643), ('spring', 644), ('debt', 645), ('catching', 646), ('fast-moving', 647), ('bound', 648), ('friendly', 649), ('swooning', 650), ('.allen', 651), ('allow', 652), ('revelations', 653), ('comment', 654), ('mounted', 655), ('self-destructive', 656), ('schools', 657), ('filmgoers', 658), ('desire', 659), ('impulse', 660), ('eric', 661), ('ghetto', 662), ('australia', 663), ('adults', 664), ('fiercely', 665), ('bygone', 666), ('unashamedly', 667), ('1960s', 668), ('centers', 669), ('penance', 670), ('.peralta', 671), ('newfangled', 672), ('prevent', 673), ('oedekerk', 674), ('spine', 675), ('stitched', 676), ('leon', 677), ('nimble', 678), ('hell', 679), ('doofus', 680), ('vague', 681), ('scrapbook', 682), ('makes', 683), ('ignored', 684), ('durable', 685), ('rodrigues', 686), ('benefited', 687), ('question', 688), ('cause', 689), ('subversive', 690), ('thomas', 691), ('intermittently', 692), ('.do', 693), ('transparent', 694), ('relationship', 695), ('delivering', 696), ('leaden', 697), ('rough', 698), ('objective', 699), ('issue', 700), ('indictment', 701), ('logic', 702), ('unconvincing', 703), ('dinner', 704), ('screams', 705), ('modestly', 706), ('swings', 707), ('wonders', 708), ('heavy-handed', 709), ('ice-t', 710), ('earnhart', 711), ('deeper', 712), ('tried', 713), ('relic', 714), ('sparkles', 715), ('balancing', 716), ('...even', 717), ('discomfort', 718), ('glory', 719), ('slap', 720), ('ash', 721), ('injuries', 722), ('kick', 723), ('encounters', 724), ('midst', 725), ('boils', 726), ('?this', 727), ('nemesis', 728), ('please', 729), ('mayhem', 730), ('teenagers', 731), ('sustained', 732), ('paintings', 733), ('under', 734), ('visit', 735), ('villeneuve', 736), ('dangerous', 737), ('invasion', 738), ('moore', 739), ('unfortunately', 740), ('moments', 741), ('law', 742), ('license', 743), ('derived', 744), ('conjures', 745), ('shake', 746), ('ham', 747), ('apparent', 748), ('moral', 749), ('solidly', 750), ('paint', 751), ('par', 752), ('obsessions', 753), ('shenanigans', 754), ('blast', 755), ('schumacher', 756), ('revolutionary', 757), ('and\\\\/or', 758), ('surreal', 759), ('demented', 760), ('reminder', 761), ('dogs', 762), ('situation', 763), ('interests', 764), ('standards', 765), ('middle', 766), ('benefit', 767), ('they', 768), ('masculine', 769), ('skateboard', 770), ('suspend', 771), ('parts', 772), ('crisp', 773), ('old-school', 774), ('placed', 775), ('sheets', 776), ('cinematographer', 777), ('satire', 778), ('chuckle', 779), ('.certainly', 780), ('.slow', 781), ('.since', 782), ('listen', 783), ('footnote', 784), ('january', 785), ('me', 786), ('intensity', 787), ('multiplex', 788), ('peak', 789), ('levity', 790), ('whether', 791), ('basically', 792), ('produced', 793), ('subtlety', 794), ('sides', 795), ('kwan', 796), ('flat-out', 797), ('fleeting', 798), ('crime', 799), ('trite', 800), ('been-there', 801), ('secondhand', 802), ('maintain', 803), ('arrangements', 804), ('happening', 805), ('shots', 806), ('balm', 807), ('intended', 808), ('obnoxious', 809), ('gratuitous', 810), ('futile', 811), ('infinitely', 812), ('weep', 813), ('table', 814), ('myers', 815), ('beginning', 816), ('discerned', 817), ('visions', 818), ('aristocracy', 819), ('presents', 820), ('awkwardly', 821), ('dumas', 822), ('pompeo', 823), ('english-language', 824), ('accepting', 825), ('parental', 826), ('comedy-drama', 827), ('conversation', 828), ('born', 829), ('shaped', 830), ('reserved', 831), ('tucked', 832), ('annals', 833), ('advice', 834), ('.most', 835), ('gem', 836), ('6-year-old', 837), ('dead', 838), ('kidlets', 839), ('screaming', 840), ('importance', 841), ('engage', 842), ('crashing', 843), ('quietly', 844), ('although', 845), ('poster', 846), ('horrors', 847), ('plus', 848), ('starting', 849), ('reminding', 850), ('traditional', 851), ('circles', 852), ('classy', 853), ('flaw', 854), ('baroque', 855), ('mamá', 856), ('series', 857), ('broomfield', 858), ('creation', 859), ('self-parody', 860), ('paradiso', 861), ('special', 862), ('whole', 863), ('authority', 864), ('schlocky', 865), ('interview', 866), ('off', 867), ('devastating', 868), ('.bigelow', 869), ('courageous', 870), ('capable', 871), ('kicks', 872), ('afraid', 873), ('smaller', 874), ('prey', 875), ('.surprisingly', 876), ('piccoli', 877), ('personalities', 878), ('sheerly', 879), ('caring', 880), ('nebrida', 881), ('grotesque', 882), ('self-congratulation', 883), ('teens', 884), ('resemble', 885), ('trash', 886), ('letting', 887), ('flashy', 888), ('investment', 889), ('narrow', 890), ('nonetheless', 891), ('end', 892), ('stew', 893), ('filled', 894), ('perpetual', 895), ('honorable', 896), ('team', 897), ('compare', 898), ('biting', 899), ('emerges', 900), ('dick', 901), ('.full', 902), ('cardboard', 903), ('ballistic', 904), ('.ms.', 905), ('slippery', 906), ('menace', 907), ('stand', 908), ('reminds', 909), ('scene', 910), ('teachers', 911), ('successfully', 912), ('limits', 913), ('gently', 914), ('modern-day', 915), ('transports', 916), ('entirely', 917), ('heard', 918), ('genteel', 919), ('ed', 920), ('earn', 921), ('laudable', 922), ('?not', 923), ('mention', 924), ('protect', 925), ('linking', 926), ('book', 927), ('convenient', 928), ('gear', 929), ('seasoned', 930), ('structure', 931), ('grow', 932), ('sixth', 933), ('photography', 934), ('bunch', 935), ('passable', 936), ('saves', 937), ('indecipherable', 938), ('sever', 939), ('fresh', 940), ('forcefulness', 941), ('dimension', 942), ('artificial', 943), ('hears', 944), ('recipe', 945), ('challenged', 946), ('mildly', 947), ('winter', 948), ('melodramatic', 949), ('voice', 950), ('.try', 951), ('worries', 952), ('feisty', 953), ('whatsoever', 954), ('overview', 955), ('.steers', 956), ('fleshed-out', 957), ('science-fiction', 958), ('meditation', 959), ('begin', 960), ('pronounce', 961), ('raise', 962), ('brutal', 963), ('kaos', 964), ('project', 965), ('recreates', 966), ('exotic', 967), ('task', 968), ('pore', 969), ('distinction', 970), ('service', 971), ('unbearably', 972), ('terminally', 973), ('hours', 974), ('trademark', 975), ('emerge', 976), ('cristo', 977), ('frailty', 978), ('club', 979), (\"'it\", 980), ('delivery', 981), ('everyman', 982), ('thrills', 983), ('feel', 984), ('wear', 985), ('surfeit', 986), ('profession', 987), ('irresponsible', 988), ('movie-going', 989), ('spotlight', 990), ('remotely', 991), ('paid', 992), ('sub', 993), ('sinister', 994), ('k-19', 995), ('shockingly', 996), ('slight', 997), ('only', 998), ('philosophical', 999), ('deepest', 1000), ('bike', 1001), ('far', 1002), ('pulchritude', 1003), ('pathetically', 1004), ('.first-time', 1005), ('term', 1006), ('album', 1007), ('months', 1008), ('captured', 1009), ('wendigo', 1010), ('weirdly', 1011), ('maintains', 1012), ('lore', 1013), ('caricatures', 1014), ('disintegrating', 1015), ('buoyant', 1016), ('pinnacle', 1017), ('.schrader', 1018), ('pacing', 1019), ('thought-provoking', 1020), ('now', 1021), ('.throughout', 1022), ('tinseltown', 1023), ('crossed', 1024), ('thank', 1025), ('undercut', 1026), ('nevertheless', 1027), ('dysfunctional', 1028), ('empowerment', 1029), ('realities', 1030), ('lean', 1031), ('juxtaposition', 1032), ('wicked', 1033), ('job', 1034), ('.who', 1035), ('crap', 1036), ('2\\xa01\\\\/2', 1037), ('heritage', 1038), ('resolutions', 1039), ('colored', 1040), ('auto', 1041), ('banality', 1042), ('gun', 1043), ('.as', 1044), ('wollter', 1045), ('chill', 1046), ('jolly', 1047), ('.has', 1048), ('delightful', 1049), ('assuredly', 1050), ('earned', 1051), ('lohman', 1052), ('getting', 1053), ('.together', 1054), ('useless', 1055), ('type', 1056), ('affecting', 1057), ('rude', 1058), ('county', 1059), ('.uplifting', 1060), ('lil', 1061), ('many', 1062), ('literal', 1063), ('midlife', 1064), ('frankly', 1065), ('rah-rah', 1066), ('suffered', 1067), ('brogue', 1068), ('terrible', 1069), ('eloquent', 1070), ('credited', 1071), ('fantasies', 1072), ('cutting', 1073), ('much', 1074), ('triumphant', 1075), ('its', 1076), ('caustic', 1077), ('size', 1078), ('.whereas', 1079), ('.see', 1080), ('del', 1081), ('damned', 1082), ('relationships', 1083), ('carmen', 1084), ('pretentious', 1085), ('run-of-the-mill', 1086), ('legged', 1087), ('unexpected', 1088), ('payne', 1089), ('hallucinatory', 1090), ('top-notch', 1091), ('storylines', 1092), ('including', 1093), ('involving', 1094), ('creek', 1095), ('acquired', 1096), ('102-minute', 1097), (\"'50s\", 1098), ('automatically', 1099), ('grind', 1100), ('overproduced', 1101), ('convince', 1102), ('.muddled', 1103), ('cheesiest', 1104), ('bigger', 1105), ('ambiguity', 1106), ('1970s', 1107), ('.woody', 1108), ('blind', 1109), ('creature', 1110), ('burger', 1111), ('unmentionable', 1112), ('quarter', 1113), ('scruffy', 1114), ('previous', 1115), ('weightless', 1116), ('harmon', 1117), ('evokes', 1118), ('\\\\*', 1119), ('maintained', 1120), ('brave', 1121), ('concern', 1122), ('different', 1123), ('crazy', 1124), ('cad', 1125), ('country', 1126), ('.those', 1127), ('king', 1128), ('immigrant', 1129), ('resonant', 1130), ('straightforward', 1131), ('serrault', 1132), ('intriguing', 1133), ('sensitive', 1134), ('weighty', 1135), ('fringes', 1136), ('kitsch', 1137), ('showtime', 1138), ('inner', 1139), ('youngsters', 1140), ('swimfan', 1141), ('hearts', 1142), ('loves', 1143), ('flashbacks', 1144), ('guitar', 1145), ('transformed', 1146), ('slide', 1147), ('after', 1148), ('parallel', 1149), ('basic', 1150), ('climax', 1151), ('abuse', 1152), ('griffiths', 1153), ('big', 1154), ('asks', 1155), ('virtuosity', 1156), ('outdated', 1157), ('dozen', 1158), ('brutally', 1159), ('old-hat', 1160), ('vanity', 1161), ('bracing', 1162), ('.secretary', 1163), ('lips', 1164), ('dullest', 1165), ('.demonstrates', 1166), ('squander', 1167), ('.mike', 1168), ('founders', 1169), ('books', 1170), ('casts', 1171), ('slice', 1172), ('tax', 1173), ('darkness', 1174), ('dreamed', 1175), ('motivations', 1176), ('effectiveness', 1177), ('rally', 1178), ('stevenson', 1179), ('impression', 1180), ('scientist', 1181), ('astonishing', 1182), ('treats', 1183), ('slack', 1184), ('.despite', 1185), ('cobbled', 1186), ('everlasting', 1187), ('waste', 1188), ('morph', 1189), ('expense', 1190), ('.boy', 1191), ('pleased', 1192), ('was', 1193), ('lifetime', 1194), ('square', 1195), ('surf', 1196), ('.stands', 1197), ('intacto', 1198), ('vistas', 1199), ('extraordinarily', 1200), ('terrorist', 1201), ('should', 1202), ('doubt', 1203), ('chilling', 1204), ('could', 1205), ('guy', 1206), ('smart-aleck', 1207), ('longtime', 1208), ('unchecked', 1209), ('clubs', 1210), ('subtlest', 1211), ('messing', 1212), ('interplay', 1213), ('brits', 1214), ('creaky', 1215), ('losers', 1216), ('irish', 1217), ('hokum', 1218), ('ferrera', 1219), ('enough', 1220), ('vaudeville', 1221), ('achingly', 1222), ('strives', 1223), ('rerun', 1224), ('watches', 1225), ('.sandra', 1226), ('seller', 1227), ('off-putting', 1228), ('joseph', 1229), ('interesting', 1230), ('argentine', 1231), ('dialogue', 1232), ('orgasm', 1233), ('.where', 1234), ('surprise', 1235), ('lucia', 1236), ('hop', 1237), ('improvised', 1238), ('moviegoer', 1239), ('.diaz', 1240), ('century', 1241), ('meant', 1242), ('referred', 1243), ('biggest', 1244), ('breaking', 1245), ('tap', 1246), ('bob', 1247), ('.when', 1248), ('strictly', 1249), ('anguished', 1250), ('runs', 1251), ('.writer', 1252), ('naked', 1253), ('sag', 1254), ('messiness', 1255), ('inconsistencies', 1256), ('remembered', 1257), ('tosca', 1258), ('tucker', 1259), ('insanity', 1260), ('litmus', 1261), ('falls', 1262), ('restraint', 1263), ('substitutes', 1264), ('improvement', 1265), ('substitute', 1266), ('alabama', 1267), ('curmudgeon', 1268), ('incapable', 1269), ('breaks', 1270), ('ingenious', 1271), ('jump', 1272), ('chelsea', 1273), ('playwright', 1274), ('shut', 1275), ('batch', 1276), ('bring', 1277), ('intelligent', 1278), ('connections', 1279), ('laughed', 1280), ('oh', 1281), ('centre', 1282), ('dog', 1283), ('numbing', 1284), ('considerably', 1285), ('fused', 1286), ('curious', 1287), ('beach', 1288), ('ignorant', 1289), ('e.t.', 1290), ('poetic', 1291), ('sensibility', 1292), ('replaced', 1293), ('.about', 1294), ('addressing', 1295), ('?in', 1296), ('manages', 1297), ('infuriating', 1298), ('waves', 1299), ('distracting', 1300), ('repellent', 1301), ('leap', 1302), ('murk', 1303), ('coal', 1304), ('examination', 1305), ('side', 1306), ('practice', 1307), ('.director', 1308), ('aim', 1309), ('ivans', 1310), ('violent', 1311), ('spot', 1312), ('?an', 1313), ('.meandering', 1314), ('search', 1315), ('occur', 1316), ('defines', 1317), ('negligible', 1318), ('corners', 1319), ('marginal', 1320), ('nails', 1321), ('simone', 1322), ('compressed', 1323), ('tales', 1324), ('connect', 1325), ('unrelenting', 1326), ('boundaries', 1327), ('underdogs', 1328), ('shocks', 1329), ('things', 1330), ('killing', 1331), ('reel', 1332), ('concentrates', 1333), ('obvious', 1334), ('antwone', 1335), ('express', 1336), ('overlook', 1337), ('nonjudgmental', 1338), ('german', 1339), ('irresistible', 1340), ('element', 1341), ('haunting', 1342), ('surrender', 1343), ('respectable', 1344), ('highway', 1345), ('instance', 1346), ('mick', 1347), ('daniel', 1348), ('system', 1349), ('.mostly', 1350), ('foolish', 1351), ('anti-semitism', 1352), ('wins', 1353), ('pack', 1354), ('napoleon', 1355), ('psyche', 1356), ('winning', 1357), ('society', 1358), ('diesel', 1359), ('forgive', 1360), ('lectures', 1361), ('introducing', 1362), ('forgets', 1363), ('tougher', 1364), ('places', 1365), ('hallmark', 1366), ('understated', 1367), ('sympathies', 1368), ('devices', 1369), ('spiked', 1370), ('bright', 1371), ('exalted', 1372), ('delusions', 1373), ('grace', 1374), ('flatulence', 1375), ('weaves', 1376), ('bette', 1377), ('pastiche', 1378), ('examine', 1379), ('sister', 1380), ('danang', 1381), ('catherine', 1382), ('hoping', 1383), ('separate', 1384), ('generic', 1385), ('appearance', 1386), ('expertly', 1387), ('might', 1388), ('coke', 1389), ('legal', 1390), ('begging', 1391), ('anyone', 1392), ('weak', 1393), ('quick', 1394), ('com', 1395), ('transition', 1396), ('generations', 1397), ('diverse', 1398), ('golf', 1399), ('moviemaking', 1400), ('suit', 1401), ('soulless', 1402), ('.all', 1403), ('pat', 1404), ('sound', 1405), ('niche', 1406), ('overcooked', 1407), ('seemed', 1408), ('.god', 1409), ('brain', 1410), ('ugliness', 1411), ('manic', 1412), ('had', 1413), ('worrying', 1414), ('bruckheimer', 1415), ('distasteful', 1416), ('meow', 1417), ('erratic', 1418), ('strikes', 1419), ('territory', 1420), ('devils', 1421), ('everyone', 1422), ('primal', 1423), ('minimalist', 1424), ('commerce', 1425), ('housing', 1426), ('storyline', 1427), ('insultingly', 1428), ('digs', 1429), ('journey', 1430), ('disarmingly', 1431), ('tribute', 1432), ('brilliant', 1433), ('horribly', 1434), ('lilo', 1435), ('moronic', 1436), ('scenic', 1437), ('considerable', 1438), ('stunningly', 1439), ('cumbersome', 1440), ('klein', 1441), ('demanding', 1442), ('challenging', 1443), ('compassionate', 1444), ('tavernier', 1445), ('tortured', 1446), ('dominant', 1447), ('mom', 1448), ('experimental', 1449), ('stevens', 1450), ('collapses', 1451), ('it', 1452), ('forever', 1453), ('hackneyed', 1454), ('fence', 1455), ('graceful', 1456), ('goyer', 1457), ('.few', 1458), ('surrenders', 1459), ('reactionary', 1460), ('9', 1461), ('states', 1462), ('schemes', 1463), ('evoking', 1464), ('sadly', 1465), ('take', 1466), ('punches', 1467), ('splendid', 1468), ('crackle', 1469), ('.', 1470), ('.grant', 1471), ('confection', 1472), ('fondly', 1473), ('luckiest', 1474), ('becoming', 1475), ('resistance', 1476), ('impulsive', 1477), ('mixed-up', 1478), ('maybe', 1479), ('bite', 1480), ('unimpressive', 1481), ('puzzling', 1482), ('aging', 1483), ('huge', 1484), ('operas', 1485), ('.real', 1486), ('demonstrating', 1487), ('former', 1488), ('quentin', 1489), ('liberal', 1490), ('explode', 1491), ('daughters', 1492), ('arresting', 1493), ('must-see', 1494), ('tons', 1495), ('sweet', 1496), ('whatever', 1497), ('.boasts', 1498), ('matches', 1499), ('chops', 1500), ('brilliance', 1501), ('avary', 1502), ('contemporaries', 1503), ('goodwill', 1504), ('distanced', 1505), ('wide', 1506), ('.unfolds', 1507), ('composed', 1508), ('letdown', 1509), ('failing', 1510), ('jonah', 1511), ('excursion', 1512), ('yorkers', 1513), ('plotting', 1514), ('everyday', 1515), ('moderately', 1516), ('threshold', 1517), ('watchable', 1518), ('backstage', 1519), ('recovery', 1520), ('conceit', 1521), ('exit', 1522), ('american', 1523), ('overkill', 1524), ('john', 1525), ('con', 1526), ('paul', 1527), ('.mr.', 1528), ('clear', 1529), ('martha', 1530), ('faithful', 1531), ('arguing', 1532), ('tediously', 1533), ('successful', 1534), ('stands', 1535), ('outstanding', 1536), ('jewish', 1537), ('heist', 1538), ('realism', 1539), ('horror', 1540), ('feel-good', 1541), ('letter', 1542), ('.far', 1543), ('postmodern', 1544), ('dong', 1545), ('destined', 1546), ('circa', 1547), ('meaningful', 1548), ('theater', 1549), ('gayton', 1550), ('bonds', 1551), ('aimed', 1552), ('zany', 1553), ('maximum', 1554), ('court', 1555), ('unrewarding', 1556), ('french', 1557), ('nuances', 1558), ('milieu', 1559), ('discord', 1560), ('come', 1561), ('sap', 1562), ('confrontations', 1563), ('wanes', 1564), ('l.a.', 1565), ('fright', 1566), ('merchant', 1567), ('...what', 1568), ('e', 1569), ('just', 1570), ('.time', 1571), ('ponder', 1572), ('southern', 1573), ('pushing', 1574), ('pretends', 1575), ('civic', 1576), ('birot', 1577), ('mere', 1578), ('ayurveda', 1579), ('directed', 1580), ('prince', 1581), ('trap', 1582), ('.ramsay', 1583), ('briefly', 1584), ('cuts', 1585), ('resembles', 1586), ('.reign', 1587), ('americans', 1588), ('bowling', 1589), ('he', 1590), ('alfred', 1591), ('shakespearean', 1592), ('cutesy', 1593), ('co-written', 1594), ('float', 1595), ('reassuring', 1596), ('sword', 1597), ('detailed', 1598), ('heights', 1599), ('self-deprecating', 1600), ('lucky', 1601), ('lack', 1602), ('within', 1603), ('like', 1604), ('inertia', 1605), ('physical', 1606), ('frustrating', 1607), ('.pretty', 1608), ('dough', 1609), ('wilco', 1610), ('difficult', 1611), ('overcomes', 1612), ('heroes', 1613), ('hall', 1614), ('means', 1615), ('grain', 1616), ('radical', 1617), ('suffer', 1618), ('capitalize', 1619), ('displays', 1620), ('generated', 1621), ('hunter', 1622), ('documentarians', 1623), ('really', 1624), ('dreadful', 1625), ('questions', 1626), ('done', 1627), ('payoff', 1628), ('planet', 1629), ('ralph', 1630), ('.tries', 1631), ('godfrey', 1632), ('deserved', 1633), ('proving', 1634), ('denying', 1635), ('route', 1636), ('landmark', 1637), ('luster', 1638), ('appreciation', 1639), ('decided', 1640), ('escapist', 1641), ('...', 1642), ('expands', 1643), ('craven', 1644), ('acknowledges', 1645), ('polanski', 1646), ('silence', 1647), ('handling', 1648), ('punch-drunk', 1649), ('beautiful', 1650), ('lofty', 1651), ('uneventful', 1652), ('frequently', 1653), ('pow', 1654), ('.evokes', 1655), ('karen', 1656), ('forcing', 1657), ('pokemon', 1658), ('cumulative', 1659), ('charles', 1660), ('replete', 1661), ('widget', 1662), ('lear', 1663), ('child', 1664), ('rolls', 1665), ('jesse', 1666), ('awful', 1667), ('incomprehensible', 1668), ('lovely', 1669), ('modern', 1670), ('surfing', 1671), ('.seemingly', 1672), ('notable', 1673), ('yiddish', 1674), ('costumes', 1675), ('backyard', 1676), ('complicated', 1677), ('cho', 1678), ('.contrived', 1679), ('treat', 1680), ('doomed', 1681), ('cool', 1682), ('drop', 1683), ('so-so', 1684), ('undeniable', 1685), ('camouflage', 1686), ('co-writer', 1687), ('derive', 1688), ('reaching', 1689), ('entertained', 1690), ('kitten', 1691), ('.cox', 1692), ('consolation', 1693), ('camps', 1694), ('.wait', 1695), ('ivan', 1696), ('rather', 1697), ('agenda', 1698), ('pitifully', 1699), ('rice', 1700), ('overstated', 1701), ('straight-ahead', 1702), ('hipness', 1703), ('genre', 1704), ('contemporary', 1705), ('anonymous', 1706), ('confirms', 1707), ('innovation', 1708), ('fairy', 1709), ('partners', 1710), ('seams', 1711), ('recount', 1712), ('abandoned', 1713), ('movements', 1714), ('gay', 1715), ('fade', 1716), ('emotion', 1717), ('amazingly', 1718), ('.amazingly', 1719), ('legacy', 1720), ('albeit', 1721), ('telling', 1722), ('chaos', 1723), ('lit', 1724), ('translate', 1725), ('gifts', 1726), ('.combines', 1727), ('rhetoric', 1728), ('range', 1729), ('shorter', 1730), ('building', 1731), ('queasy', 1732), ('lasting', 1733), ('we', 1734), ('some', 1735), ('illuminating', 1736), ('.taken', 1737), ('due', 1738), ('atlantic', 1739), ('tambor', 1740), ('pale', 1741), ('simultaneously', 1742), ('fundamentals', 1743), ('nine', 1744), ('.seems', 1745), ('sexist', 1746), ('refreshing', 1747), ('full', 1748), ('cinematically', 1749), ('nice', 1750), ('issues', 1751), ('evolves', 1752), ('jumble', 1753), ('squanders', 1754), ('pleasing', 1755), ('shifting', 1756), ('rejected', 1757), ('mugs', 1758), ('stolid', 1759), ('nation', 1760), ('inevitable', 1761), ('terrifying', 1762), ('snappy', 1763), ('miller', 1764), ('freshly', 1765), ('surviving', 1766), ('maker', 1767), ('stitch', 1768), ('eventually', 1769), ('progression', 1770), ('3d', 1771), ('rings', 1772), ('favors', 1773), ('ii', 1774), ('cohesive', 1775), ('.brown', 1776), ('disturbed', 1777), ('establishes', 1778), ('belgium', 1779), ('.writer-director', 1780), ('timid', 1781), ('strokes', 1782), ('no.', 1783), ('public', 1784), ('astray', 1785), ('aspects', 1786), ('undemanding', 1787), ('losing', 1788), ('busy', 1789), ('solemnity', 1790), ('dominate', 1791), ('endure', 1792), ('grenade', 1793), ('properly', 1794), ('sickening', 1795), ('tuck', 1796), ('.got', 1797), ('discourse', 1798), ('muccino', 1799), ('whimsy', 1800), ('conviction', 1801), ('hoot', 1802), ('appear', 1803), ('allegory', 1804), ('portuguese', 1805), ('demonstrates', 1806), ('tadpole', 1807), ('.being', 1808), ('growing', 1809), ('xtc', 1810), ('.with', 1811), ('focused', 1812), ('barry', 1813), ('flop', 1814), ('via', 1815), ('stepped', 1816), ('pleasures', 1817), ('awkward', 1818), ('sticky', 1819), ('admire', 1820), ('regardless', 1821), ('today', 1822), ('survive', 1823), ('brooms', 1824), ('edge', 1825), ('action-comedy', 1826), ('appointed', 1827), ('reviews', 1828), ('nerves', 1829), ('classified', 1830), ('dentist', 1831), ('suddenly', 1832), ('blurry', 1833), ('.using', 1834), ('kind', 1835), ('aged', 1836), ('beard', 1837), ('hard-bitten', 1838), ('wannabe', 1839), ('patch', 1840), ('videos', 1841), ('.directed', 1842), ('release', 1843), ('complexities', 1844), ('own', 1845), ('tragedy', 1846), ('backgrounds', 1847), ('disappointing', 1848), ('apollo', 1849), ('preordained', 1850), ('ten', 1851), ('vulnerable', 1852), ('thought', 1853), ('.cinematic', 1854), ('reunion', 1855), ('fellow', 1856), ('denouement', 1857), ('.norton', 1858), ('punching', 1859), ('venture', 1860), ('metal', 1861), ('puzzle', 1862), ('hewitt', 1863), ('style', 1864), ('rules', 1865), ('happen', 1866), ('poses', 1867), ('contriving', 1868), ('leads', 1869), ('ravishing', 1870), ('pick', 1871), ('laid-back', 1872), ('uses', 1873), ('park', 1874), ('directions', 1875), ('home', 1876), ('adventure', 1877), ('well-crafted', 1878), ('rewards', 1879), ('crocodile', 1880), ('slovenly', 1881), ('romp', 1882), ('profound', 1883), ('ardently', 1884), ('praises', 1885), ('hypocritical', 1886), ('intentionally', 1887), ('scariest', 1888), ('ripping', 1889), ('dim-witted', 1890), ('mostly', 1891), ('lulls', 1892), ('ethos', 1893), ('shaggy', 1894), ('promised', 1895), ('true', 1896), ('road', 1897), ('discover', 1898), ('succumbs', 1899), ('bands', 1900), ('sum', 1901), ('saw', 1902), ('gore', 1903), ('assayas', 1904), ('thanks', 1905), ('classics', 1906), ('salton', 1907), ('dishonest', 1908), ('pauline', 1909), ('rebellion', 1910), ('.provides', 1911), ('20', 1912), ('.carrying', 1913), ('exploiting', 1914), ('connection', 1915), ('acted', 1916), ('or', 1917), ('realize', 1918), ('joins', 1919), ('figure', 1920), ('struck', 1921), ('traveler', 1922), ('warfare', 1923), ('.performances', 1924), ('retread', 1925), ('hidden', 1926), ('iconoclastic', 1927), ('nearly', 1928), ('allusions', 1929), ('clearly', 1930), ('advantage', 1931), ('juvenile', 1932), ('adolescence', 1933), ('especially', 1934), ('slow-moving', 1935), ('change', 1936), ('connect-the-dots', 1937), ('network', 1938), ('raunchy', 1939), ('dynamics', 1940), ('above-average', 1941), ('amélie', 1942), ('well', 1943), ('implausible', 1944), ('lesson', 1945), ('muddy', 1946), ('ode', 1947), ('grown', 1948), ('putrid', 1949), ('lows', 1950), ('metaphor', 1951), ('revenge', 1952), ('details', 1953), ('illustrated', 1954), ('staggeringly', 1955), ('healthy', 1956), ('impressive', 1957), ('cox', 1958), ('dazzling', 1959), ('notorious', 1960), ('diminishing', 1961), ('.becomes', 1962), ('harangues', 1963), ('strain', 1964), ('marriage', 1965), ('oleander', 1966), ('among', 1967), ('opening', 1968), ('battlefield', 1969), ('delusional', 1970), ('davies', 1971), ('effective', 1972), ('admitted', 1973), ('sits', 1974), ('kim', 1975), ('oppressively', 1976), ('loving', 1977), ('dime', 1978), ('builds', 1979), ('low-grade', 1980), ('loose', 1981), ('probing', 1982), ('translation', 1983), ('forced', 1984), ('.everything', 1985), ('daughter', 1986), ('memoir', 1987), ('grew', 1988), ('denial', 1989), ('cope', 1990), ('war-torn', 1991), ('alternative', 1992), ('august', 1993), ('opportunities', 1994), ('chest', 1995), ('internet', 1996), ('era', 1997), ('partly', 1998), ('half-baked', 1999), ('uncle', 2000), ('heavily', 2001), ('depression', 2002), ('.scherfig', 2003), ('baffled', 2004), ('introduces', 2005), ('cinderella', 2006), ('wall', 2007), ('classical', 2008), ('live-action', 2009), ('funeral', 2010), ('silver', 2011), ('moaning', 2012), ('spider', 2013), ('50', 2014), ('stupidity', 2015), ('land', 2016), ('particular', 2017), ('fearlessness', 2018), ('idealistic', 2019), ('deals', 2020), ('bursts', 2021), ('photos', 2022), ('ardent', 2023), ('minimum', 2024), ('masterful', 2025), ('smooth', 2026), ('tear', 2027), ('remembrance', 2028), ('attack', 2029), ('outline', 2030), ('denis', 2031), ('presenting', 2032), ('sent', 2033), ('handsomely', 2034), ('stamina', 2035), ('serving', 2036), ('popcorn', 2037), ('complete', 2038), ('kenneth', 2039), ('self-indulgent', 2040), ('.frankly', 2041), ('cartoon', 2042), ('ballast', 2043), ('unfulfilling', 2044), ('hawaiian', 2045), ('evocative', 2046), ('idiocy', 2047), ('least', 2048), ('s', 2049), ('decide', 2050), ('mind', 2051), ('marvel', 2052), ('dialog', 2053), ('bathtub', 2054), ('exchange', 2055), ('soliloquies', 2056), ('ironies', 2057), ('shocked', 2058), ('supporting', 2059), ('heartwarming', 2060), ('key', 2061), ('destination', 2062), ('about', 2063), ('idealism', 2064), ('mob', 2065), ('mess', 2066), ('episode', 2067), ('slowly', 2068), ('balance', 2069), ('stumble', 2070), ('possible', 2071), ('potshots', 2072), ('columbine', 2073), ('existentialism', 2074), ('text', 2075), ('is', 2076), ('kaufman', 2077), ('tv', 2078), ('audacity', 2079), ('honestly', 2080), ('leaving', 2081), ('equals', 2082), ('stock', 2083), ('aimlessly', 2084), ('freely', 2085), ('theory', 2086), ('frantic', 2087), ('power', 2088), ('.borrows', 2089), ('.fred', 2090), ('awfulness', 2091), ('telemarketers', 2092), ('gored', 2093), ('.unless', 2094), ('brio', 2095), ('wickedly', 2096), ('.elegant', 2097), ('proud', 2098), ('stardom', 2099), ('resources', 2100), ('seeks', 2101), ('pray', 2102), ('into', 2103), ('otherworldly', 2104), ('repetition', 2105), ('looking', 2106), ('oddest', 2107), ('hurts', 2108), ('numbers', 2109), ('zero', 2110), ('favor', 2111), ('unruly', 2112), ('dismiss', 2113), ('craziness', 2114), ('abroad', 2115), ('adrenaline', 2116), ('1920', 2117), ('cameos', 2118), ('olivier', 2119), ('.somewhere', 2120), ('kiddie', 2121), ('divine', 2122), ('junk', 2123), ('fincher', 2124), ('.miyazaki', 2125), ('.forget', 2126), ('brass', 2127), ('musical', 2128), ('?`', 2129), ('inspire', 2130), ('temple', 2131), ('international', 2132), ('processed', 2133), ('turned', 2134), ('nicely', 2135), ('urge', 2136), ('irrelevant', 2137), ('takes', 2138), ('clockstoppers', 2139), ('.should', 2140), ('likely', 2141), ('branagh', 2142), ('monumental', 2143), ('sane', 2144), ('musicals', 2145), ('.robert', 2146), ('remarkable', 2147), ('requisite', 2148), ('stone', 2149), ('unpretentious', 2150), ('unblinking', 2151), ('mood', 2152), ('high-tech', 2153), ('namely', 2154), ('oscar-worthy', 2155), ('cynicism', 2156), ('amount', 2157), ('look', 2158), ('misery', 2159), ('critics', 2160), ('talented', 2161), ('poet', 2162), ('makeup', 2163), ('beside', 2164), ('fathers', 2165), ('surely', 2166), ('provided', 2167), ('mainstream', 2168), ('flavor', 2169), ('selection', 2170), ('spinning', 2171), ('crew', 2172), ('follow-up', 2173), ('pro', 2174), ('warmth', 2175), ('superficially', 2176), ('insistent', 2177), ('.first', 2178), ('begins', 2179), ('feeling', 2180), ('glossy', 2181), ('venice', 2182), ('depressing', 2183), ('color', 2184), ('chamber', 2185), ('knee-jerk', 2186), ('tragically', 2187), ('.lacks', 2188), ('questioning', 2189), ('laughably', 2190), ('crimes', 2191), ('atmospheric', 2192), ('boredom', 2193), ('storytelling', 2194), ('graceless', 2195), ('hearst', 2196), ('struggled', 2197), ('lightweight', 2198), ('whose', 2199), ('closest', 2200), ('theatres', 2201), ('cops', 2202), ('sleepless', 2203), ('efficiently', 2204), ('cry', 2205), ('sorry', 2206), ('.sometimes', 2207), ('wants', 2208), ('normally', 2209), ('well-constructed', 2210), ('music', 2211), ('morton', 2212), ('tonal', 2213), ('role', 2214), ('overbearing', 2215), ('spirited', 2216), ('bond', 2217), ('cohesion', 2218), ('rocky', 2219), ('.cherish', 2220), ('insufferable', 2221), ('subject', 2222), ('claude', 2223), ('debated', 2224), ('span', 2225), ('advance', 2226), ('glitter', 2227), ('.friday', 2228), ('clips', 2229), ('serious-minded', 2230), ('collectively', 2231), ('develops', 2232), ('mix', 2233), ('stance', 2234), ('steady', 2235), ('dip', 2236), ('thankfully', 2237), ('dime-store', 2238), ('legend', 2239), ('.fessenden', 2240), ('feature', 2241), ('judge', 2242), ('sexual', 2243), ('insightful', 2244), ('beings', 2245), ('israeli', 2246), ('.for', 2247), ('stuart', 2248), ('walking', 2249), ('noir', 2250), ('verdict', 2251), ('corruption', 2252), ('zings', 2253), ('faults', 2254), ('passions', 2255), ('borrows', 2256), ('don', 2257), ('didactic', 2258), ('filming', 2259), ('...it', 2260), ('stealing', 2261), ('worked', 2262), ('turn', 2263), ('wishing', 2264), ('163', 2265), ('brimming', 2266), ('two-hour', 2267), ('cheap', 2268), ('craig', 2269), ('understand', 2270), ('amateur', 2271), ('.is', 2272), ('transcends', 2273), ('.we', 2274), ('evening', 2275), ('garcia', 2276), ('meets', 2277), ('fashion', 2278), ('spots', 2279), ('appeal', 2280), ('charged', 2281), ('members', 2282), ('invented', 2283), ('put', 2284), ('realizing', 2285), ('symbolism', 2286), ('sadistic', 2287), ('show', 2288), ('washington', 2289), ('vivid', 2290), ('finest', 2291), ('inventiveness', 2292), ('goal', 2293), ('superhero', 2294), ('market', 2295), ('highlight', 2296), ('her', 2297), ('godard', 2298), ('odds', 2299), ('saying', 2300), ('refreshed', 2301), ('writing', 2302), ('characters', 2303), ('attractive', 2304), (\"'if\", 2305), ('ear', 2306), ('gang', 2307), ('material', 2308), ('manipulation', 2309), ('coen', 2310), ('cussing', 2311), ('shift', 2312), ('huppert', 2313), ('kong', 2314), ('stirs', 2315), ('flies', 2316), ('basketball', 2317), ('anderson', 2318), ('unexpectedly', 2319), ('bruce', 2320), ('directs', 2321), ('nostalgic', 2322), ('plenty', 2323), ('became', 2324), ('sucks', 2325), ('.last', 2326), ('silly', 2327), ('work', 2328), ('endearing', 2329), ('whiny', 2330), ('comforting', 2331), ('conditions', 2332), ('abound', 2333), ('.seagal', 2334), ('one-hour', 2335), ('ago', 2336), ('clichéd', 2337), ('surround', 2338), ('removed', 2339), ('airs', 2340), ('tongue', 2341), ('insight', 2342), ('enterprise', 2343), ('test', 2344), ('spouses', 2345), ('chillingly', 2346), ('.will', 2347), ('runteldat', 2348), ('widowmaker', 2349), ('casual', 2350), ('row', 2351), ('received', 2352), ('emperor', 2353), ('pill', 2354), (\"'em\", 2355), ('disappointment', 2356), ('almost', 2357), ('.bogdanovich', 2358), ('ominous', 2359), ('always', 2360), ('rank', 2361), ('wonderful', 2362), ('lush', 2363), ('returning', 2364), ('farce', 2365), ('black', 2366), ('weary', 2367), ('.george', 2368), ('arrives', 2369), ('massive', 2370), ('littered', 2371), ('hannibal', 2372), ('gaze', 2373), ('palma', 2374), ('demonstrate', 2375), ('crack', 2376), ('soap-opera', 2377), ('abel', 2378), ('?once', 2379), ('welcome', 2380), ('insignificance', 2381), ('play', 2382), ('infuses', 2383), ('extensive', 2384), ('back-stabbing', 2385), ('adolescent', 2386), ('zealand', 2387), ('woman', 2388), ('lighthearted', 2389), ('seductive', 2390), ('dream', 2391), ('mouth', 2392), ('plotless', 2393), ('keeping', 2394), ('innocent', 2395), ('slog', 2396), ('kingsley', 2397), ('entity', 2398), ('pic', 2399), ('executive', 2400), ('belt', 2401), ('comedy\\\\/drama', 2402), ('.jones', 2403), ('sounding', 2404), ('hampered', 2405), ('trouble', 2406), ('relevance', 2407), ('clayburgh', 2408), ('cameo', 2409), ('unsatisfied', 2410), ('weird', 2411), ('enervating', 2412), ('efforts', 2413), ('am', 2414), ('shrill', 2415), ('afford', 2416), ('.still', 2417), ('suffering', 2418), ('.michael', 2419), ('sopranos', 2420), ('.quite', 2421), ('.definitely', 2422), ('hey', 2423), ('person', 2424), ('barrel', 2425), ('document', 2426), ('disquieting', 2427), ('.been', 2428), ('kids', 2429), ('perfunctory', 2430), ('checklist', 2431), ('cautionary', 2432), ('anemic', 2433), ('confusing', 2434), ('obstacles', 2435), ('barbershop', 2436), ('wonderfully', 2437), ('volatile', 2438), ('angry', 2439), ('reason', 2440), ('fight', 2441), ('somehow', 2442), ('gratefully', 2443), ('loyalty', 2444), ('drag', 2445), ('deserve', 2446), ('most', 2447), ('excitement', 2448), ('.confessions', 2449), ('rowdy', 2450), ('suggestive', 2451), ('kennedy', 2452), ('perpetrated', 2453), ('cliche', 2454), ('friends', 2455), ('pretensions', 2456), ('depth', 2457), ('condition', 2458), ('numbingly', 2459), ('openness', 2460), ('barely', 2461), ('joel', 2462), ('skillful', 2463), ('because', 2464), ('share', 2465), ('frenzy', 2466), ('blockbusters', 2467), ('quickie', 2468), ('glover', 2469), ('insane', 2470), ('need', 2471), ('heavy', 2472), ('preachy', 2473), ('on-camera', 2474), ('directorial', 2475), ('imitating', 2476), ('schnitzler', 2477), ('experience', 2478), ('badness', 2479), ('notice', 2480), ('proves', 2481), ('considering', 2482), ('.great', 2483), ('smith', 2484), ('loud', 2485), ('obscure', 2486), ('returns', 2487), ('grin', 2488), ('stay', 2489), ('paxton', 2490), ('comedic', 2491), ('?just', 2492), ('subculture', 2493), ('.highly', 2494), ('disbelief', 2495), ('effort', 2496), ('rapt', 2497), ('eccentrics', 2498), ('ill', 2499), ('hypnotic', 2500), ('passionate', 2501), ('genius', 2502), ('rape', 2503), ('dawns', 2504), ('directors', 2505), ('anyway', 2506), ('russian', 2507), ('kicking', 2508), ('clancy', 2509), ('holiday', 2510), ('souls', 2511), ('sadism', 2512), ('sudsy', 2513), ('90-minute', 2514), ('.brings', 2515), ('undercurrent', 2516), ('answers', 2517), ('inviting', 2518), ('exhilarating', 2519), ('adapted', 2520), ('remaining', 2521), ('cat-and-mouse', 2522), ('curse', 2523), ('talent', 2524), ('ours', 2525), ('used', 2526), ('artist', 2527), ('follow', 2528), ('murderer', 2529), ('.unfortunately', 2530), ('hair', 2531), ('lake', 2532), ('c.', 2533), ('give', 2534), ('early', 2535), ('laramie', 2536), ('wilder', 2537), ('titled', 2538), ('alone', 2539), ('owe', 2540), ('kidman', 2541), ('.could', 2542), ('atmospherics', 2543), ('lock', 2544), ('everybody', 2545), ('cotton', 2546), ('prevents', 2547), ('develop', 2548), ('trying', 2549), ('miyazaki', 2550), ('jolie', 2551), ('crude', 2552), ('rigor', 2553), ('destroy', 2554), ('witty', 2555), ('sacrifice', 2556), ('mumbo', 2557), ('pile', 2558), ('unexplainable', 2559), ('unhurried', 2560), ('ethics', 2561), ('threat', 2562), ('equation', 2563), ('.did', 2564), ('hinge', 2565), ('live', 2566), ('looks', 2567), ('formal', 2568), ('artfully', 2569), ('ably', 2570), ('recycling', 2571), ('value', 2572), ('.reno', 2573), ('touched', 2574), ('intensely', 2575), ('safe', 2576), ('note', 2577), ('making', 2578), ('love', 2579), ('watts', 2580), ('blair', 2581), ('.his', 2582), ('hardy', 2583), ('dey', 2584), ('harrowing', 2585), ('.twohy', 2586), ('tendencies', 2587), ('.nicks', 2588), ('guts', 2589), ('partner', 2590), ('seemingly', 2591), ('loads', 2592), ('doa', 2593), ('possession', 2594), ('seagal', 2595), ('separation', 2596), ('workers', 2597), ('friendship', 2598), ('unpredictable', 2599), ('remakes', 2600), ('bielinsky', 2601), ('.oh', 2602), ('.eight', 2603), ('scope', 2604), ('nba', 2605), ('staying', 2606), ('better', 2607), ('clown', 2608), ('ahola', 2609), ('ending', 2610), ('influenced', 2611), ('do', 2612), ('chase', 2613), ('gheorghiu', 2614), ('uneasily', 2615), ('box', 2616), ('sentimentality', 2617), ('antonio', 2618), ('tasteless', 2619), ('push', 2620), ('foibles', 2621), ('longer', 2622), ('holes', 2623), ('passes', 2624), ('10', 2625), ('reflects', 2626), ('quest', 2627), ('weeks', 2628), ('pictures', 2629), ('morally', 2630), ('mechanical', 2631), ('sacrifices', 2632), ('stream', 2633), ('promisingly', 2634), ('writers', 2635), ('sonnenfeld', 2636), ('indoors', 2637), ('motives', 2638), ('3000', 2639), ('costume', 2640), ('significant', 2641), ('events', 2642), ('disguise', 2643), ('dated', 2644), ('gold', 2645), ('receive', 2646), ('casting', 2647), ('protagonist', 2648), ('drivel', 2649), ('cycle', 2650), ('rug', 2651), ('clash', 2652), ('killed', 2653), ('accident', 2654), ('enjoyment', 2655), ('scarier', 2656), ('deftly', 2657), ('bewildering', 2658), ('conception', 2659), ('youth', 2660), ('bow', 2661), ('hugh', 2662), ('discipline', 2663), ('outweighs', 2664), ('conveys', 2665), ('simplistic', 2666), ('overwrought', 2667), ('regalia', 2668), ('charade', 2669), ('fully', 2670), ('collide', 2671), ('anachronistic', 2672), ('families', 2673), ('.a', 2674), ('middle-aged', 2675), ('trial', 2676), ('walls', 2677), ('humane', 2678), ('misogyny', 2679), ('dread', 2680), ('crane', 2681), ('juan', 2682), ('unique', 2683), ('victims', 2684), ('hip', 2685), ('.queen', 2686), ('burr', 2687), ('discreet', 2688), ('.serving', 2689), ('incisive', 2690), (\"'60s\", 2691), ('gross-out', 2692), ('journalist', 2693), ('daydreams', 2694), ('fictional', 2695), ('continues', 2696), ('darned', 2697), ('buzz', 2698), ('enticing', 2699), ('100', 2700), ('chord', 2701), ('little-known', 2702), ('map', 2703), ('record', 2704), ('indeed', 2705), ('spectator', 2706), ('reductive', 2707), ('triangle', 2708), ('portions', 2709), ('sanctimony', 2710), ('room', 2711), ('plodding', 2712), ('sweeping', 2713), ('my', 2714), ('explanations', 2715), ('yesterday', 2716), ('fitting', 2717), ('motivation', 2718), ('rate', 2719), ('edgy', 2720), ('borderline', 2721), ('two', 2722), ('time', 2723), ('valuable', 2724), ('yard', 2725), ('?is', 2726), ('kiss', 2727), ('tropes', 2728), ('popularity', 2729), ('thin', 2730), ('pair', 2731), ('lightness', 2732), ('entertaining', 2733), ('veteran', 2734), ('address', 2735), ('suspense', 2736), ('suggests', 2737), ('unmistakable', 2738), ('tricky', 2739), ('exposes', 2740), ('suffers', 2741), ('says', 2742), ('overcome', 2743), ('all-too-familiar', 2744), ('stereotypical', 2745), ('cathartic', 2746), ('nightmarish', 2747), ('wildly', 2748), ('layered', 2749), ('survivors', 2750), ('conflicts', 2751), ('near', 2752), ('distinctly', 2753), ('pay', 2754), ('unnerving', 2755), ('chris', 2756), ('big-screen', 2757), ('.suffers', 2758), ('plotted', 2759), ('descends', 2760), ('involved', 2761), ('channeling', 2762), ('framework', 2763), ('mother\\\\/daughter', 2764), ('moods', 2765), ('.simultaneously', 2766), ('behavior', 2767), ('impact', 2768), ('shanghai', 2769), ('titles', 2770), ('suffocating', 2771), ('.pretend', 2772), ('na', 2773), ('tepid', 2774), ('static', 2775), ('pinochet', 2776), ('culture', 2777), ('stare', 2778), ('jagged', 2779), ('first-rate', 2780), ('marina', 2781), ('bourne', 2782), ('scares', 2783), ('immediate', 2784), ('broader', 2785), ('animal', 2786), ('heart', 2787), ('estranged', 2788), ('h', 2789), ('flimsy', 2790), ('ace', 2791), ('media', 2792), (\"'...\", 2793), ('.here', 2794), ('outrage', 2795), ('gravity', 2796), ('.rice', 2797), ('flick', 2798), ('contradictory', 2799), ('conclusion', 2800), ('bridget', 2801), ('spousal', 2802), ('lucy', 2803), ('knock', 2804), ('20th', 2805), ('chimps', 2806), ('savage', 2807), ('melancholy', 2808), ('convention', 2809), ('surefire', 2810), ('supposed', 2811), ('cartoonish', 2812), ('.filmmakers', 2813), ('dolls', 2814), ('bravado', 2815), ('meal', 2816), ('wake', 2817), ('telegraphed', 2818), ('downtown', 2819), ('woody', 2820), ('renowned', 2821), ('sons', 2822), ('steeped', 2823), ('satiric', 2824), ('medium', 2825), ('gag', 2826), ('dvd', 2827), ('.succeeds', 2828), ('neighbor', 2829), ('serves', 2830), ('elizabeth', 2831), ('story', 2832), ('tendency', 2833), ('attitude', 2834), ('paints', 2835), ('single', 2836), ('newcomer', 2837), ('.white', 2838), ('smug', 2839), ('molly', 2840), ('ordeal', 2841), ('critique', 2842), ('stylistic', 2843), ('``', 2844), ('scripted', 2845), ('anthony', 2846), ('approaches', 2847), ('frissons', 2848), ('diane', 2849), ('vicious', 2850), ('guns', 2851), ('piercing', 2852), ('puppet', 2853), ('c.h.o.', 2854), ('.handsome', 2855), ('incoherent', 2856), ('vividly', 2857), ('.hard', 2858), ('smoochy', 2859), ('twisting', 2860), ('funk', 2861), ('viewer', 2862), ('rhythm', 2863), ('fails', 2864), ('uncomfortably', 2865), ('leaping', 2866), ('confusion', 2867), ('rests', 2868), ('accomplished', 2869), ('code', 2870), ('chafing', 2871), ('coma', 2872), ('unabashed', 2873), ('.anemic', 2874), ('undermines', 2875), ('dearth', 2876), ('sketch', 2877), ('genuine', 2878), ('screens', 2879), ('surprises', 2880), ('.tom', 2881), ('witherspoon', 2882), ('guarantee', 2883), ('introduction', 2884), ('nuclear', 2885), ('beast', 2886), ('object', 2887), ('engineering', 2888), ('throwing', 2889), ('primarily', 2890), ('visionary', 2891), ('everything', 2892), ('sudden', 2893), ('glorious', 2894), ('astonishingly', 2895), ('rely', 2896), ('heat', 2897), ('leblanc', 2898), ('draws', 2899), ('subplots', 2900), ('agent', 2901), ('resorting', 2902), ('wade', 2903), ('fame', 2904), ('narration', 2905), ('pass', 2906), ('canvas', 2907), ('anguish', 2908), ('rendition', 2909), ('build', 2910), ('built', 2911), ('iwai', 2912), ('profoundly', 2913), ('morvern', 2914), ('.although', 2915), ('attempts', 2916), ('entertain', 2917), ('glimpses', 2918), ('carried', 2919), ('necessary', 2920), ('run', 2921), ('hard-hitting', 2922), ('vampire', 2923), ('predictably', 2924), ('recreating', 2925), ('songs', 2926), ('sentiments', 2927), ('closer', 2928), ('sung', 2929), ('queens', 2930), ('dreadfully', 2931), ('vietnam', 2932), ('.puts', 2933), ('gloriously', 2934), ('singles', 2935), ('consistently', 2936), ('devotees', 2937), ('.muccino', 2938), ('ritchie', 2939), ('eerie', 2940), ('nadia', 2941), ('19th-century', 2942), ('strike', 2943), ('r', 2944), ('.family', 2945), ('screen', 2946), ('personal', 2947), ('disaster', 2948), ('padded', 2949), ('shopping', 2950), ('?cattaneo', 2951), ('magic', 2952), ('have', 2953), ('fitfully', 2954), ('staring', 2955), ('manifesto', 2956), ('exoticism', 2957), ('marked', 2958), ('eastwood', 2959), ('manner', 2960), ('visuals', 2961), ('.let', 2962), ('filling', 2963), ('commentary', 2964), ('corn', 2965), ('discovering', 2966), ('playing', 2967), ('past', 2968), ('.really', 2969), ('watching', 2970), ('hickenlooper', 2971), ('snaps', 2972), ('mcgrath', 2973), ('understanding', 2974), ('handle', 2975), ('saccharine', 2976), ('materialthe', 2977), ('empathy', 2978), ('recycles', 2979), ('smarter', 2980), ('motion', 2981), ('soldiers', 2982), ('movies', 2983), ('jersey', 2984), ('contains', 2985), ('et', 2986), ('pretension', 2987), ('match', 2988), ('apparatus', 2989), ('intricate', 2990), ('catholic', 2991), ('antics', 2992), ('gilliam', 2993), ('sprightly', 2994), ('slightly', 2995), ('midnight', 2996), ('retaliation', 2997), ('cruel', 2998), ('caffeinated', 2999), ('foul', 3000), ('4', 3001), ('tarantula', 3002), ('darker', 3003), ('generating', 3004), ('gotten', 3005), ('dual', 3006), ('themes', 3007), ('disappointingly', 3008), ('greatly', 3009), ('laws', 3010), ('undermining', 3011), ('violence', 3012), ('soundtrack', 3013), ('car', 3014), ('two-thirds', 3015), ('reveal', 3016), ('phrase', 3017), ('86', 3018), ('aimless', 3019), ('brow', 3020), ('beautifully', 3021), ('.shows', 3022), ('misanthropic', 3023), ('grave', 3024), ('dreams', 3025), ('and', 3026), ('leonine', 3027), ('retains', 3028), ('plate', 3029), ('ticking', 3030), ('misdemeanor', 3031), ('good-hearted', 3032), ('soul', 3033), ('japan', 3034), ('journalism', 3035), ('n', 3036), (\"'but\", 3037), ('amuse', 3038), ('subtitled', 3039), ('crosses', 3040), ('seats', 3041), ('.pacino', 3042), ('binoche', 3043), ('incoherence', 3044), ('insurance', 3045), ('sexism', 3046), ('various', 3047), ('sleep', 3048), ('forgettably', 3049), ('innocuous', 3050), ('dramatized', 3051), ('ridiculousness', 3052), ('--', 3053), ('broad', 3054), ('soon', 3055), ('expresses', 3056), ('mira', 3057), ('guys', 3058), ('.disney', 3059), ('student', 3060), ('surrounding', 3061), ('squarely', 3062), ('enveloping', 3063), ('collaboration', 3064), ('danny', 3065), ('dose', 3066), ('chew', 3067), ('topical', 3068), ('fizz', 3069), ('lo', 3070), ('overwhelming', 3071), ('stranger', 3072), ('.can', 3073), ('plainly', 3074), ('presented', 3075), ('bother', 3076), ('puerile', 3077), ('seems', 3078), ('strains', 3079), ('offensive', 3080), ('momentum', 3081), ('island', 3082), ('.sadly', 3083), ('tame', 3084), ('modeled', 3085), ('robinson', 3086), ('adventures', 3087), ('uninteresting', 3088), ('1940s', 3089), ('fairy-tale', 3090), ('.nair', 3091), ('homosexuality', 3092), ('professionals', 3093), ('.tends', 3094), ('.make', 3095), ('ireland', 3096), ('geared', 3097), ('contrived', 3098), ('1975', 3099), ('principals', 3100), ('cross', 3101), ('schizophrenia', 3102), ('maternal', 3103), ('feeble', 3104), ('denzel', 3105), ('noise', 3106), ('gone', 3107), ('stephen', 3108), ('ways', 3109), ('naturalism', 3110), ('swooping', 3111), ('never', 3112), ('no', 3113), ('airless', 3114), ('scratch', 3115), ('undeniably', 3116), ('nonsensical', 3117), ('bomb', 3118), ('nash', 3119), ('scary', 3120), ('.de', 3121), ('beat', 3122), ('banal', 3123), ('i.e.', 3124), ('.more', 3125), ('master', 3126), ('lines', 3127), ('rouge', 3128), ('surprisingly', 3129), ('remembering', 3130), ('wrapped', 3131), ('thick', 3132), ('ensure', 3133), ('witnesses', 3134), ('photographer', 3135), ('forgettable', 3136), ('lunatic', 3137), ('dies', 3138), ('homage', 3139), ('hardened', 3140), ('crossroads', 3141), ('burning', 3142), ('amounts', 3143), ('moralizing', 3144), ('recklessness', 3145), ('allowed', 3146), ('tim', 3147), ('nature', 3148), ('spiritual', 3149), ('careers', 3150), ('audience', 3151), ('.cacoyannis', 3152), ('laughing', 3153), ('define', 3154), ('mundane', 3155), ('ancient', 3156), ('boss', 3157), ('.imagine', 3158), ('cult', 3159), ('juice', 3160), ('face', 3161), ('parade', 3162), ('gift', 3163), ('inquisitive', 3164), ('west', 3165), ('evaluate', 3166), ('.strictly', 3167), ('.jacquot', 3168), ('calm', 3169), ('immediacy', 3170), ('bled', 3171), ('yourself', 3172), ('blank', 3173), ('trek', 3174), ('blade', 3175), ('newcomers', 3176), ('scattered', 3177), ('sterling', 3178), ('.ends', 3179), ('amy', 3180), ('crudity', 3181), ('intelligently', 3182), ('sweetheart', 3183), ('alexandre', 3184), ('clinic', 3185), ('knack', 3186), ('motivated', 3187), ('roiling', 3188), ('.good', 3189), ('pg-13', 3190), ('tunney', 3191), ('reefs', 3192), ('lampoon', 3193), ('genial', 3194), ('someone', 3195), ('integrated', 3196), ('repulsive', 3197), ('great', 3198), ('filmmaking', 3199), ('polemical', 3200), ('sublimely', 3201), ('familiarity', 3202), ('mystical', 3203), ('ironic', 3204), ('brosnan', 3205), ('equally', 3206), ('recently', 3207), ('populated', 3208), ('.barry', 3209), ('thoroughly', 3210), ('support', 3211), ('tapestry', 3212), ('unless', 3213), ('no-frills', 3214), ('endless', 3215), ('.over', 3216), ('odyssey', 3217), ('potboiler', 3218), ('1', 3219), ('dawson', 3220), ('parallels', 3221), ('positive', 3222), ('clever', 3223), ('jay', 3224), ('trashy', 3225), ('manufactured', 3226), ('go', 3227), ('depraved', 3228), ('mud', 3229), ('magnificent', 3230), ('gimmicky', 3231), ('trick', 3232), ('man', 3233), ('heartbreakingly', 3234), ('.to', 3235), ('squad', 3236), ('stereotypes', 3237), ('outing', 3238), ('tian', 3239), ('quaid', 3240), ('kilmer', 3241), ('tykwer', 3242), ('content', 3243), ('more', 3244), (':', 3245), ('except', 3246), ('kissinger', 3247), ('.impostor', 3248), ('swill', 3249), ('effortlessly', 3250), ('curiously', 3251), ('came', 3252), ('jfk', 3253), ('ruggero', 3254), ('transporting', 3255), ('sheer', 3256), ('perfection', 3257), ('alike', 3258), ('cockettes', 3259), (\"'s\", 3260), ('excess', 3261), ('.humorous', 3262), ('lavish', 3263), ('when', 3264), ('stewart', 3265), ('visually', 3266), ('shorts', 3267), ('dispossessed', 3268), ('bargain-basement', 3269), ('well-paced', 3270), ('.goes', 3271), ('miramax', 3272), ('hardly', 3273), ('icon', 3274), ('charmer', 3275), ('.simply', 3276), ('.amid', 3277), ('hole', 3278), ('sprung', 3279), ('gleaned', 3280), ('england', 3281), ('appeared', 3282), ('decent', 3283), ('lump', 3284), ('cricket', 3285), ('.why', 3286), ('definite', 3287), ('phifer', 3288), ('testament', 3289), ('mythic', 3290), ('er', 3291), ('insulting', 3292), ('canon', 3293), ('pain', 3294), ('hudlin', 3295), ('must', 3296), ('body', 3297), ('revulsion', 3298), ('suggestion', 3299), ('stunt', 3300), ('zone', 3301), ('advised', 3302), ('from', 3303), ('happy', 3304), ('.brosnan', 3305), ('flirts', 3306), ('merits', 3307), ('son', 3308), ('successes', 3309), ('.australian', 3310), ('.bad', 3311), ('forgotten', 3312), ('amidst', 3313), ('redone', 3314), ('forth', 3315), ('song', 3316), ('historically', 3317), ('.huppert', 3318), ('clueless', 3319), ('sentence', 3320), ('pa', 3321), ('conservative', 3322), ('factory', 3323), ('kung', 3324), ('shore', 3325), ('solaris', 3326), ('rueful', 3327), ('cheer', 3328), ('happiness', 3329), ('raw', 3330), ('.rather', 3331), ('medicine', 3332), ('electric', 3333), ('von', 3334), ('low-budget', 3335), ('admission', 3336), ('combined', 3337), ('slip', 3338), ('.adaptation', 3339), ('grim', 3340), ('wherever', 3341), ('1960', 3342), ('aspirations', 3343), ('smugly', 3344), ('...(', 3345), ('cell', 3346), ('tweaked', 3347), ('attached', 3348), ('defiant', 3349), ('combine', 3350), ('odd', 3351), ('fisher', 3352), ('.terrific', 3353), ('.trapped', 3354), ('babysitter', 3355), ('scientific', 3356), ('risks', 3357), ('ideas', 3358), ('infomercial', 3359), ('thematic', 3360), ('jordan', 3361), ('insult', 3362), ('platter', 3363), ('claims', 3364), ('purposeless', 3365), ('texture', 3366), ('overwhelmed', 3367), ('sara', 3368), ('jonze', 3369), (\"'70s\", 3370), ('recite', 3371), ('emotions', 3372), ('joys', 3373), ('added', 3374), ('l.', 3375), ('collinwood', 3376), ('stylistically', 3377), ('sentimentalizing', 3378), ('traces', 3379), ('autopsy', 3380), ('waterboy', 3381), ('improve', 3382), ('carrying', 3383), ('?', 3384), ('created', 3385), ('based', 3386), ('clarity', 3387), ('adopt', 3388), ('check', 3389), ('assassin', 3390), ('stinker', 3391), ('hanussen', 3392), ('complexity', 3393), ('susan', 3394), ('thrives', 3395), ('insights', 3396), ('shafer', 3397), ('played', 3398), ('earth', 3399), ('illness', 3400), ('languid', 3401), ('nutty', 3402), ('acting', 3403), ('raises', 3404), ('relatively', 3405), ('count', 3406), ('brooklyn', 3407), ('sort', 3408), ('van', 3409), ('shepard', 3410), ('achievement', 3411), ('block', 3412), ('maelstrom', 3413), ('bad', 3414), ('underestimated', 3415), ('turns', 3416), ('pbs', 3417), ('strings', 3418), ('budget', 3419), ('therapy', 3420), ('.hugh', 3421), ('nyc', 3422), ('infusion', 3423), ('mysterious', 3424), ('tale', 3425), ('handled', 3426), ('observed', 3427), ('teeth', 3428), ('burst', 3429), ('sharing', 3430), ('nerds', 3431), ('fortune', 3432), ('firmly', 3433), ('living', 3434), ('continuation', 3435), ('cold-hearted', 3436), ('fiennes', 3437), ('bombastic', 3438), ('caruso', 3439), ('byatt', 3440), ('endurance', 3441), ('?well', 3442), ('quaint', 3443), ('attal', 3444), ('padding', 3445), ('campus', 3446), ('presence', 3447), ('father', 3448), ('finish', 3449), ('vivre', 3450), ('emphasizes', 3451), ('tract', 3452), ('scathing', 3453), ('expressive', 3454), ('worry', 3455), ('miraculous', 3456), ('goofball', 3457), ('precise', 3458), ('board', 3459), ('adam', 3460), ('.miller', 3461), ('clashing', 3462), ('flourishes', 3463), ('.loud', 3464), ('stilted', 3465), ('novel', 3466), ('.intriguing', 3467), ('screenplay', 3468), ('stirring', 3469), ('has-been', 3470), ('portrayed', 3471), ('vietnamese', 3472), ('freaks', 3473), ('.halfway', 3474), ('recording', 3475), ('steal', 3476), ('ever', 3477), ('.feels', 3478), ('48', 3479), ('.another', 3480), ('damning', 3481), ('jim', 3482), ('informative', 3483), ('producing', 3484), ('even', 3485), ('sin', 3486), ('concert', 3487), ('inconsequential', 3488), ('credits', 3489), ('alternately', 3490), ('chasing', 3491), ('rollerball', 3492), ('spent', 3493), ('stomach-turning', 3494), ('unflappable', 3495), ('creators', 3496), ('unorthodox', 3497), ('exciting', 3498), ('tongue-in-cheek', 3499), ('italian', 3500), ('rock', 3501), ('considered', 3502), ('murphy', 3503), ('approach', 3504), ('gothic', 3505), ('.snipes', 3506), ('noticeably', 3507), ('russell', 3508), ('mental', 3509), ('arriving', 3510), ('receiving', 3511), ('writer\\\\/director', 3512), ('food', 3513), ('fast', 3514), ('.moonlight', 3515), ('closing', 3516), ('forces', 3517), ('eloquently', 3518), ('well-meaning', 3519), ('afterlife', 3520), ('awareness', 3521), ('.manages', 3522), ('loveable', 3523), ('often', 3524), ('specifically', 3525), ('steaming', 3526), ('sleeper', 3527), ('redeems', 3528), ('adventurous', 3529), ('.visually', 3530), ('tightrope', 3531), ('bloodshed', 3532), ('aristocrats', 3533), ('average', 3534), ('stacked', 3535), ('.unlike', 3536), ('m.', 3537), ('thrillers', 3538), ('to', 3539), ('solid', 3540), ('sneaks', 3541), ('minus', 3542), ('shaking', 3543), ('handles', 3544), ('strict', 3545), ('eye', 3546), ('road-trip', 3547), ('scarlet', 3548), ('moviemakers', 3549), ('diversity', 3550), ('stagy', 3551), ('co-stars', 3552), ('fascinate', 3553), ('shoots', 3554), ('shekhar', 3555), ('resembling', 3556), ('fireworks', 3557), ('shell', 3558), ('wondered', 3559), ('sunday', 3560), ('insanely', 3561), ('transgressive', 3562), ('high-minded', 3563), ('drink', 3564), ('demographic', 3565), ('salt', 3566), ('tense', 3567), ('.consider', 3568), ('downright', 3569), ('thrilling', 3570), ('juicy', 3571), ('decides', 3572), ('.seeing', 3573), ('wondrously', 3574), ('servants', 3575), ('musty', 3576), ('también', 3577), ('mores', 3578), ('princess', 3579), ('scooter', 3580), ('humility', 3581), ('relegated', 3582), ('deliberately', 3583), ('convincingly', 3584), ('slo-mo', 3585), ('1999', 3586), ('neck', 3587), ('brightly', 3588), ('women', 3589), ('mournful', 3590), ('finesse', 3591), ('levy', 3592), ('represents', 3593), ('remote', 3594), ('ditsy', 3595), ('earns', 3596), ('concerned', 3597), ('popular', 3598), ('teen', 3599), ('hand', 3600), ('escaped', 3601), ('ai', 3602), ('family-friendly', 3603), ('delicate', 3604), ('sparkling', 3605), ('during', 3606), ('innuendo', 3607), ('villainous', 3608), ('underbelly', 3609), ('.thoroughly', 3610), ('controlling', 3611), ('hokey', 3612), ('insults', 3613), ('them', 3614), ('lots', 3615), ('shocker', 3616), ('intoxicating', 3617), ('.looks', 3618), ('goofiness', 3619), ('hellish', 3620), ('roll', 3621), ('incredible', 3622), ('wrote', 3623), ('success', 3624), ('neorealism', 3625), ('limited', 3626), ('marvelous', 3627), ('influence', 3628), ('earnest', 3629), ('urgency', 3630), ('verbally', 3631), ('truth', 3632), ('military', 3633), ('margin', 3634), ('tooth', 3635), ('monotonous', 3636), ('minor', 3637), ('offering', 3638), ('glamour', 3639), ('feminist', 3640), ('afternoon', 3641), ('drains', 3642), ('obsession', 3643), ('worthwhile', 3644), ('benjamins', 3645), ('silent', 3646), ('flabby', 3647), ('pressed', 3648), ('follows', 3649), ('toes', 3650), ('rain', 3651), ('.once', 3652), ('altogether', 3653), ('brusqueness', 3654), ('together', 3655), ('pleasingly', 3656), ('q', 3657), ('settled', 3658), ('extraordinary', 3659), ('goodfellas', 3660), ('enjoy', 3661), ('reasonable', 3662), ('.human', 3663), ('bank', 3664), ('fantasia', 3665), ('controversy', 3666), ('cunning', 3667), ('oozing', 3668), ('extent', 3669), ('heartbreak', 3670), ('fuzzy', 3671), ('the', 3672), ('duvall', 3673), ('revolution', 3674), ('fault', 3675), ('cuban', 3676), ('bean', 3677), ('believe', 3678), ('otherwise', 3679), ('video', 3680), ('fumbles', 3681), ('gamble', 3682), ('.gives', 3683), ('relative', 3684), ('scared', 3685), ('brooding', 3686), ('unsubtle', 3687), ('shine', 3688), ('51', 3689), ('shower', 3690), ('asylum', 3691), ('risk', 3692), ('.rifkin', 3693), ('extravaganza', 3694), ('alien', 3695), ('adorably', 3696), ('placid', 3697), ('suggesting', 3698), ('believability', 3699), ('ready', 3700), ('shadow', 3701), ('construction', 3702), ('serve', 3703), ('painful', 3704), ('.children', 3705), ('eye-catching', 3706), ('same', 3707), ('aplomb', 3708), ('spontaneous', 3709), ('potential', 3710), ('pink', 3711), ('bard', 3712), ('devolves', 3713), ('indication', 3714), ('faster', 3715), ('between', 3716), ('justify', 3717), ('arthur', 3718), ('cliched', 3719), ('broke', 3720), ('imamura', 3721), ('went', 3722), ('showgirls', 3723), ('lens', 3724), ('performer', 3725), ('elaborate', 3726), ('comfortable', 3727), ('movement', 3728), ('france', 3729), ('college', 3730), ('gritty', 3731), ('...this', 3732), ('machines', 3733), ('.captivates', 3734), ('claptrap', 3735), ('randomness', 3736), ('ilk', 3737), ('stuttering', 3738), ('theatrics', 3739), ('shadows', 3740), ('took', 3741), ('hoped', 3742), ('(', 3743), ('schaeffer', 3744), ('lurking', 3745), ('evelyn', 3746), ('burstein', 3747), ('right-wing', 3748), ('bare', 3749), ('bravery', 3750), ('larger-than-life', 3751), ('severely', 3752), ('then', 3753), ('plane', 3754), ('jokes', 3755), ('tenor', 3756), ('maguire', 3757), ('.weird', 3758), ('simple-minded', 3759), ('grinder', 3760), ('action-adventure', 3761), ('adequately', 3762), ('.roman', 3763), ('found', 3764), ('willie', 3765), ('excited', 3766), ('consider', 3767), ('pretty', 3768), ('elevated', 3769), ('choppy', 3770), ('listless', 3771), ('providing', 3772), ('feces', 3773), ('occasionally', 3774), ('boozy', 3775), ('impersonal', 3776), ('tell', 3777), ('howard', 3778), ('clothes', 3779), ('paranoid', 3780), ('purely', 3781), ('cinematic', 3782), ('!is', 3783), ('condensed', 3784), ('jazzy', 3785), ('saigon', 3786), ('introspective', 3787), ('themed', 3788), ('bland', 3789), ('realm', 3790), ('whenever', 3791), ('indifference', 3792), ('.ryan', 3793), ('plain', 3794), ('filmmakers', 3795), ('ugly', 3796), ('art-house', 3797), ('betty', 3798), ('holocaust', 3799), ('clumsily', 3800), ('younger', 3801), ('carl', 3802), ('large', 3803), ('unturned', 3804), ('splashed', 3805), ('masses', 3806), ('flee', 3807), ('tissue-thin', 3808), ('al.', 3809), ('acerbic', 3810), ('.presents', 3811), ('proven', 3812), ('expectation', 3813), ('constraints', 3814), ('eventual', 3815), ('designed', 3816), ('absurd', 3817), ('diabolical', 3818), ('orchard', 3819), ('weaknesses', 3820), ('but', 3821), ('breathe', 3822), ('adrenalin', 3823), ('rehashes', 3824), ('sophomoric', 3825), ('angst', 3826), ('heartfelt', 3827), ('complications', 3828), ('gossip', 3829), ('flash', 3830), ('malcolm', 3831), ('humanly', 3832), ('league', 3833), ('powerful', 3834), ('muddled', 3835), ('tones', 3836), ('differences', 3837), ('indians', 3838), ('victories', 3839), ('t', 3840), ('speaking', 3841), ('conned', 3842), ('uh', 3843), ('aids', 3844), ('amazing', 3845), ('interminable', 3846), ('students', 3847), ('old-fashioned', 3848), ('weaving', 3849), ('.scotland', 3850), ('.skip', 3851), ('times', 3852), ('handful', 3853), ('placement', 3854), ('thinks', 3855), ('cake', 3856), ('length', 3857), ('hopelessly', 3858), ('potter', 3859), ('lighting', 3860), ('.features', 3861), ('fights', 3862), ('waters', 3863), ('half-hearted', 3864), ('satisfyingly', 3865), ('managed', 3866), ('collapse', 3867), ('strip', 3868), ('action-packed', 3869), ('doc', 3870), ('centered', 3871), ('camp', 3872), ('taylor', 3873), ('jolts', 3874), ('unconditional', 3875), ('inhabit', 3876), ('excels', 3877), ('thoughtfulness', 3878), ('characteristic', 3879), ('.leaves', 3880), ('likable', 3881), ('entertainment', 3882), ('dramas', 3883), ('skill', 3884), ('realizes', 3885), ('arnold', 3886), ('sealed', 3887), ('grossly', 3888), ('overused', 3889), ('unlike', 3890), ('compellingly', 3891), ('hot', 3892), ('counts', 3893), ('f', 3894), ('all-star', 3895), ('leaky', 3896), ('revelation', 3897), ('elements', 3898), ('.promises', 3899), ('blues', 3900), ('accomplish', 3901), ('circumstantial', 3902), ('mushy', 3903), ('combines', 3904), ('i', 3905), ('.high', 3906), ('undistinguished', 3907), ('using', 3908), ('thanksgiving', 3909), ('harry', 3910), ('cuisine', 3911), ('imply', 3912), ('drives', 3913), ('extremely', 3914), ('why', 3915), ('engaged', 3916), ('being', 3917), ('ponderous', 3918), ('bile', 3919), ('sensibilities', 3920), ('fantasma', 3921), ('unnecessary', 3922), ('bernard', 3923), ('tug', 3924), ('scorpion', 3925), ('enchanting', 3926), ('.fans', 3927), ('.dark', 3928), ('.well-meaning', 3929), ('miserable', 3930), ('parent', 3931), ('actor', 3932), ('mask', 3933), ('mothers', 3934), ('steve', 3935), ('monsoon', 3936), ('tosses', 3937), ('engrossing', 3938), ('healing', 3939), ('inept', 3940), ('turbulent', 3941), ('hitchcockian', 3942), ('point', 3943), ('fluff', 3944), ('rarely', 3945), ('glasses', 3946), ('.stealing', 3947), ('traditions', 3948), ('richer', 3949), ('lingers', 3950), ('gangs', 3951), ('fu', 3952), ('helps', 3953), ('liked', 3954), ('nationwide', 3955), ('rocket', 3956), ('culkin', 3957), ('arduous', 3958), ('likeable', 3959), ('.offers', 3960), ('?the', 3961), ('.scott', 3962), (\"''...\", 3963), ('rowling', 3964), ('amateurishly', 3965), ('witnessed', 3966), ('sweetness', 3967), ('canny', 3968), ('doing', 3969), ('spirits', 3970), ('knowledge', 3971), ('biased', 3972), ('hoffman', 3973), ('vile', 3974), ('celebrity', 3975), ('sequences', 3976), ('surface', 3977), ('lady', 3978), ('scribe', 3979), ('reasons', 3980), ('assume', 3981), ('?do', 3982), ('drown', 3983), ('dimensions', 3984), ('matrix', 3985), ('rushed', 3986), ('celluloid', 3987), ('cheese', 3988), ('neglecting', 3989), ('outside', 3990), ('fury', 3991), ('prove', 3992), ('improved', 3993), ('summer', 3994), ('character', 3995), ('promises', 3996), ('.unexpected', 3997), ('dips', 3998), ('admit', 3999), ('reconstruction', 4000), ('foremost', 4001), ('matters', 4002), ('showdown', 4003), ('.light', 4004), ('wills', 4005), ('proper', 4006), ('unrelentingly', 4007), ('assembled', 4008), ('coffee', 4009), ('actual', 4010), ('.bears', 4011), ('street', 4012), ('endeavors', 4013), ('indicative', 4014), ('suspected', 4015), ('mehta', 4016), ('inclination', 4017), ('packed', 4018), ('overstuffed', 4019), ('bet', 4020), ('.fails', 4021), ('formed', 4022), ('imax', 4023), ('move', 4024), ('stately', 4025), ('european', 4026), ('unexceptional', 4027), ('oral', 4028), ('order', 4029), ('tangled', 4030), ('.leigh', 4031), ('quieter', 4032), ('ground', 4033), ('breathless', 4034), ('psychic', 4035), ('.sure', 4036), ('dare', 4037), ('filmed', 4038), ('ache', 4039), ('potentially', 4040), ('genres', 4041), ('summertime', 4042), ('soft', 4043), ('101', 4044), ('miscalculation', 4045), ('ridicule', 4046), ('roger', 4047), ('each', 4048), ('unforgettable', 4049), ('memories', 4050), ('carnage', 4051), ('absolutely', 4052), ('expectations', 4053), ('succeeds', 4054), ('contribution', 4055), ('lolita', 4056), ('unassuming', 4057), ('disturb', 4058), ('existed', 4059), ('wondrous', 4060), ('five', 4061), ('enlightening', 4062), ('entered', 4063), ('yu', 4064), ('eloquence', 4065), ('.my', 4066), ('named', 4067), ('stronger', 4068), ('confident', 4069), ('yearning', 4070), ('gorgeously', 4071), ('virtually', 4072), ('.nettelbeck', 4073), ('mean', 4074), ('profanity', 4075), ('cheek', 4076), ('bray', 4077), ('lousy', 4078), ('loquacious', 4079), ('girl-meets-girl', 4080), ('say', 4081), ('.if', 4082), ('epic', 4083), ('slightest', 4084), ('upbeat', 4085), ('greedy', 4086), ('boring', 4087), ('monday', 4088), ('aplenty', 4089), ('fishy', 4090), ('horses', 4091), ('comfort', 4092), ('severe', 4093), ('demons', 4094), ('ops', 4095), ('enduring', 4096), ('rescue', 4097), ('peculiar', 4098), ('crucial', 4099), ('films', 4100), ('fills', 4101), ('degraded', 4102), ('seem', 4103), ('.irwin', 4104), ('refreshingly', 4105), ('hook', 4106), ('relies', 4107), ('failed', 4108), ('initial', 4109), ('.birthday', 4110), ('fearless', 4111), ('opera-ish', 4112), ('reputation', 4113), ('message', 4114), ('thing', 4115), ('talks', 4116), ('toilet', 4117), ('patient', 4118), ('lee', 4119), ('distinct', 4120), ('schneider', 4121), (\"'m\", 4122), ('.witless', 4123), ('regarding', 4124), ('ride', 4125), ('swimming', 4126), ('developments', 4127), ('remarkably', 4128), ('delicately', 4129), ('wartime', 4130), ('rachel', 4131), ('dickensian', 4132), ('nick', 4133), ('punchy', 4134), ('hence', 4135), ('breadth', 4136), ('sentimental', 4137), ('artists', 4138), ('everywhere', 4139), ('liking', 4140), ('pride', 4141), ('thorough', 4142), ('layers', 4143), ('pull', 4144), ('romances', 4145), ('improvisation', 4146), ('shown', 4147), ('convey', 4148), ('three', 4149), ('8', 4150), ('perversity', 4151), ('unfolding', 4152), ('putting', 4153), ('pitch', 4154), ('psycho', 4155), ('psychology', 4156), ('day', 4157), ('breathtakingly', 4158), ('affair', 4159), ('vitality', 4160), ('cheering', 4161), ('commitment', 4162), ('pitched', 4163), ('logical', 4164), ('rollicking', 4165), ('fallen', 4166), ('notes', 4167), ('richly', 4168), ('?try', 4169), ('unendurable', 4170), ('tatters', 4171), ('83', 4172), ('language', 4173), ('salute', 4174), ('achieving', 4175), ('guessed', 4176), ('formula', 4177), ('restrained', 4178), ('catches', 4179), ('radiant', 4180), ('underscore', 4181), ('baffling', 4182), ('spare', 4183), ('succeeded', 4184), ('80', 4185), ('free', 4186), ('lodging', 4187), ('mexican', 4188), (\"''the\", 4189), ('martin', 4190), ('.yet', 4191), ('line', 4192), ('suspects', 4193), ('yarn', 4194), ('mechanics', 4195), ('.drumline', 4196), ('resolutely', 4197), ('callar', 4198), ('.frida', 4199), ('laissez-passer', 4200), ('pomposity', 4201), ('disdain', 4202), ('policy', 4203), ('capture', 4204), ('j.', 4205), ('hanna-barbera', 4206), ('asset', 4207), ('patience', 4208), ('terror', 4209), ('.quitting', 4210), ('facile', 4211), ('through-line', 4212), ('cage', 4213), ('twists', 4214), ('sequence', 4215), ('corny', 4216), ('doorstep', 4217), ('laughter', 4218), ('overtly', 4219), ('title', 4220), ('pedestrian', 4221), ('memory', 4222), ('.remember', 4223), ('pieces', 4224), ('highs', 4225), ('broken', 4226), ('fairly', 4227), ('moonlight', 4228), ('suitable', 4229), ('!--', 4230), ('foreign', 4231), ('sink', 4232), ('aspires', 4233), ('already', 4234), ('salle', 4235), ('costly', 4236), ('soaper', 4237), ('space', 4238), ('universe', 4239), ('stores', 4240), ('spirituality', 4241), ('actually', 4242), ('filmmaker', 4243), ('ararat', 4244), ('.wallace', 4245), ('direction', 4246), ('aspect', 4247), ('tend', 4248), ('patronizing', 4249), ('original', 4250), ('bridge', 4251), ('paris', 4252), ('repressed', 4253), ('tea', 4254), ('multi-character', 4255), ('accurate', 4256), ('immersed', 4257), ('radar', 4258), ('experiences', 4259), ('beats', 4260), ('grandiosity', 4261), ('rhythms', 4262), ('vat', 4263), ('gosling', 4264), ('homes', 4265), ('bucks', 4266), ('thrust', 4267), ('bump', 4268), ('grisly', 4269), ('killer', 4270), ('eat', 4271), ('inherent', 4272), ('admirably', 4273), ('effectively', 4274), ('spaces', 4275), ('grade', 4276), ('altar', 4277), ('comparison', 4278), ('earnestness', 4279), ('.kinnear', 4280), ('stagey', 4281), ('rohmer', 4282), ('pushes', 4283), ('.only', 4284), ('result', 4285), ('inimitable', 4286), ('arms', 4287), ('1952', 4288), ('gere', 4289), ('blunt', 4290), ('jar', 4291), ('escort', 4292), ('convoluted', 4293), ('blab', 4294), ('flows', 4295), ('calculated', 4296), ('plethora', 4297), ('ought', 4298), ('.no', 4299), ('cultural', 4300), ('profane', 4301), ('who', 4302), ('blithe', 4303), ('keeps', 4304), ('realistic', 4305), ('ends', 4306), ('fable', 4307), ('shakes', 4308), ('minimal', 4309), ('chiller', 4310), ('decidedly', 4311), ('naipaul', 4312), ('complacency', 4313), ('r.', 4314), ('scriptwriters', 4315), ('pollution', 4316), ('witless', 4317), ('.deuces', 4318), ('sit', 4319), ('corporate', 4320), ('winners', 4321), ('bigelow', 4322), (\"'occasionally\", 4323), ('splash', 4324), ('.gets', 4325), ('kooky', 4326), ('inadvertently', 4327), ('pedestal', 4328), ('orwell', 4329), ('mib', 4330), ('.reggio', 4331), ('physique', 4332), ('striking', 4333), ('pork', 4334), ('observation', 4335), ('conduct', 4336), ('.apparently', 4337), ('doses', 4338), ('miike', 4339), ('cgi', 4340), ('condescending', 4341), ('wet', 4342), ('pleaser', 4343), ('hopefully', 4344), ('stylish', 4345), ('.this', 4346), ('mann', 4347), ('raunch', 4348), ('aliens', 4349), ('sea', 4350), ('tub', 4351), ('insightfully', 4352), ('pool', 4353), ('.whatever', 4354), ('decadent', 4355), ('auteur', 4356), ('behind', 4357), ('deal', 4358), ('.pure', 4359), ('conspiracy', 4360), ('handsome', 4361), ('smart', 4362), ('crippled', 4363), ('oliver', 4364), ('myself', 4365), ('ca', 4366), ('.goldmember', 4367), ('clones', 4368), ('gives', 4369), ('psychologically', 4370), ('.think', 4371), ('.sorvino', 4372), ('.just', 4373), ('rendered', 4374), ('tasteful', 4375), ('totalitarian', 4376), ('completely', 4377), ('arthouse', 4378), ('.before', 4379), ('specific', 4380), ('pathetic', 4381), ('accompanying', 4382), ('unsuccessful', 4383), ('amiable', 4384), ('opportunity', 4385), ('hilarious', 4386), ('hint', 4387), ('.solondz', 4388), ('regret', 4389), ('ones', 4390), ('parody', 4391), ('misses', 4392), ('relating', 4393), ('words', 4394), ('wife', 4395), ('tickets', 4396), ('marching', 4397), ('matthew', 4398), ('.diane', 4399), ('proficient', 4400), ('rival', 4401), ('infectious', 4402), ('perfectly', 4403), ('wacky', 4404), ('talking', 4405), ('frames', 4406), ('woven', 4407), ('dangerously', 4408), ('.smart', 4409), ('beguiling', 4410), ('pit', 4411), ('fantasy', 4412), ('timeless', 4413), ('swedish', 4414), ('definitely', 4415), ('tiny', 4416), ('narc', 4417), ('welles', 4418), ('cleverly', 4419), ('vital', 4420), ('pairing', 4421), ('voting', 4422), ('feels', 4423), ('dramatization', 4424), ('schmaltzy', 4425), ('enigmatic', 4426), ('open-ended', 4427), ('sympathy', 4428), ('boldly', 4429), ('distinctive', 4430), ('carrey', 4431), ('refined', 4432), ('greek', 4433), ('forceful', 4434), ('.from', 4435), ('rapid-fire', 4436), ('magnolia', 4437), ('endings', 4438), ('beneath', 4439), ('criminal', 4440), ('retro', 4441), ('titular', 4442), ('daring', 4443), ('continue', 4444), ('.plodding', 4445), ('practically', 4446), ('sonny', 4447), ('timing', 4448), ('besson', 4449), ('combat', 4450), ('brit', 4451), ('hanging', 4452), ('beyond', 4453), ('depend', 4454), ('.its', 4455), ('mild-mannered', 4456), ('late-night', 4457), ('mattei', 4458), ('potent', 4459), ('yawning', 4460), ('made', 4461), ('bottom', 4462), ('shame', 4463), ('vain', 4464), ('quite', 4465), ('successor', 4466), ('soggy', 4467), ('.throwing', 4468), ('wooden', 4469), ('brisk', 4470), ('clients', 4471), ('metaphors', 4472), ('jackie', 4473), ('pity', 4474), ('seas', 4475), ('marking', 4476), ('amusing', 4477), ('uninspired', 4478), ('gallo', 4479), ('prophecies', 4480), ('speak', 4481), ('simpson', 4482), ('independent', 4483), ('preteen', 4484), ('freddy', 4485), ('.comes', 4486), ('unhappy', 4487), ('carry', 4488), ('balances', 4489), ('wal-mart', 4490), ('drunken', 4491), ('muted', 4492), ('verbal', 4493), ('proceeds', 4494), ('guide', 4495), ('eileen', 4496), ('satin', 4497), ('misguided', 4498), ('company', 4499), ('predominantly', 4500), ('carvey', 4501), ('less', 4502), ('gleefully', 4503), ('passed', 4504), ('organic', 4505), ('bailly', 4506), ('overall', 4507), ('folly', 4508), ('vin', 4509), ('delighted', 4510), ('thoughtful', 4511), ('teacher', 4512), ('party', 4513), ('option', 4514), ('others', 4515), ('auteuil', 4516), ('by-the-numbers', 4517), ('.benigni', 4518), ('enter', 4519), ('banter', 4520), ('stumbles', 4521), ('drowned', 4522), ('cowering', 4523), ('errors', 4524), ('contest', 4525), ('ladies', 4526), ('nod', 4527), ('stamp', 4528), ('caesar', 4529), ('forms', 4530), ('robert', 4531), ('fail', 4532), ('viewing', 4533), ('clunky', 4534), ('doings', 4535), ('figured', 4536), ('slyly', 4537), ('murder', 4538), ('poor', 4539), ('race', 4540), ('self-hatred', 4541), ('skewed', 4542), ('shoot', 4543), ('study', 4544), ('existential', 4545), ('opinion', 4546), ('11', 4547), ('rut', 4548), ('pointed', 4549), ('viewers', 4550), ('riot', 4551), ('merely', 4552), ('essentially', 4553), ('disguised', 4554), ('motions', 4555), ('drew', 4556), ('perform', 4557), ('exploring', 4558), ('half-hour', 4559), ('converted', 4560), ('describe', 4561), ('.ferrara', 4562), ('consistent', 4563), ('draw', 4564), ('drawings', 4565), ('barney', 4566), ('incessant', 4567), ('precisely', 4568), ('usual', 4569), ('flesh', 4570), ('kubrick', 4571), ('ron', 4572), ('mean-spirited', 4573), ('posturing', 4574), ('.piccoli', 4575), ('lively', 4576), ('department', 4577), ('.campanella', 4578), ('sledgehammer', 4579), ('repartee', 4580), ('scare', 4581), ('magnetic', 4582), ('silberling', 4583), ('21\\\\/2', 4584), ('one-dimensional', 4585), ('upper', 4586), ('dullard', 4587), ('reliable', 4588), ('hug', 4589), ('.often', 4590), ('holding', 4591), ('enters', 4592), ('disregard', 4593), ('bullets', 4594), ('hundred', 4595), ('evade', 4596), ('deadly', 4597), ('swinging', 4598), ('skillfully', 4599), ('if', 4600), ('cylinders', 4601), ('themselves', 4602), ('touching', 4603), ('superb', 4604), ('bones', 4605), ('uneasy', 4606), ('sy', 4607), ('twin', 4608), ('.strange', 4609), ('depressed', 4610), ('overwhelm', 4611), ('lost', 4612), ('beloved', 4613), ('.unfunny', 4614), ('bit', 4615), ('similar', 4616), ('one', 4617), ('unconventional', 4618), ('copycat', 4619), ('.an', 4620), ('keep', 4621), ('truthful', 4622), ('examines', 4623), ('afterthought', 4624), ('photographed', 4625), ('intent', 4626), ('humanistic', 4627), ('hairs', 4628), ('cross-country', 4629), ('dismissed', 4630), ('scale', 4631), ('crackles', 4632), ('alert', 4633), ('strength', 4634), ('cares', 4635), ('promising', 4636), ('terrifically', 4637), ('discernible', 4638), ('basis', 4639), ('resurrection', 4640), ('agony', 4641), ('lucas', 4642), ('jaglom', 4643), ('lover', 4644), ('esther', 4645), ('.works', 4646), ('an', 4647), ('hilarity', 4648), ('photo', 4649), ('prime', 4650), ('negotiate', 4651), ('awe-inspiring', 4652), ('notch', 4653), ('.deserves', 4654), ('pulp', 4655), ('mothman', 4656), ('inspirational', 4657), ('stick', 4658), ('fifth', 4659), ('fake', 4660), ('through', 4661), ('lights', 4662), ('teach', 4663), ('messages', 4664), ('brought', 4665), ('web', 4666), ('humming', 4667), ('videotape', 4668), ('detached', 4669), ('damon', 4670), ('agonizing', 4671), ('deliberate', 4672), ('bowel', 4673), ('participatory', 4674), ('emergence', 4675), ('notwithstanding', 4676), ('comprehend', 4677), ('wo', 4678), ('breezy', 4679), ('.deep', 4680), ('genuinely', 4681), ('realized', 4682), ('discarded', 4683), ('dollar', 4684), ('spanning', 4685), ('reworking', 4686), ('.godard', 4687), ('aficionados', 4688), ('smoothly', 4689), ('bits', 4690), ('explosion', 4691), ('closure', 4692), ('rapidly', 4693), ('bored', 4694), ('africa', 4695), ('effortless', 4696), ('cat', 4697), ('.heartwarming', 4698), ('essence', 4699), ('ballet', 4700), ('glaring', 4701), ('caught', 4702), ('pursuing', 4703), ('generate', 4704), ('lyne', 4705), ('melodramas', 4706), ('overwhelms', 4707), ('technical', 4708), ('.raimi', 4709), ('myth', 4710), ('roman', 4711), ('implies', 4712), ('malkovich', 4713), ('opened', 4714), ('jagger', 4715), (\"ol'\", 4716), ('unsettling', 4717), ('amused', 4718), ('chips', 4719), ('computer-generated', 4720), ('.writer\\\\/director', 4721), ('julie', 4722), ('wallop', 4723), ('coming-of-age', 4724), ('pleasant', 4725), ('snap', 4726), ('stupid', 4727), ('maid', 4728), ('ecks', 4729), ('heal', 4730), ('animé', 4731), ('taxi', 4732), ('chaplin', 4733), ('.tsai', 4734), ('chronicles', 4735), ('bearing', 4736), ('.long', 4737), ('idea', 4738), ('self-discovery', 4739), ('zingers', 4740), ('co-writers', 4741), ('auditorium', 4742), ('romance', 4743), ('manhattan', 4744), ('pratfalls', 4745), ('satisfactory', 4746), ('absorb', 4747), ('train', 4748), ('arty', 4749), ('aimlessness', 4750), ('familial', 4751), ('.stay', 4752), ('manage', 4753), ('delicious', 4754), ('genitals', 4755), ('taymor', 4756), ('crass', 4757), ('interested', 4758), ('analyze', 4759), ('pulls', 4760), ('dumbness', 4761), ('perspective', 4762), ('did', 4763), ('needed', 4764), ('skip', 4765), (\"''\", 4766), ('surroundings', 4767), ('milestones', 4768), ('crudup', 4769), ('thirty', 4770), ('kosminsky', 4771), ('sessions', 4772), ('adage', 4773), ('sensual', 4774), ('rises', 4775), ('fan', 4776), ('mawkish', 4777), ('spiral', 4778), ('edits', 4779), ('cheeky', 4780), ('gory', 4781), ('wryly', 4782), ('.showtime', 4783), ('.be', 4784), ('floating', 4785), ('asian', 4786), ('return', 4787), ('morbid', 4788), ('exposition', 4789), ('pootie', 4790), ('commercialism', 4791), ('press', 4792), ('observe', 4793), ('sports', 4794), ('ball', 4795), ('opera', 4796), ('particularly', 4797), ('on-screen', 4798), ('melodrama', 4799), ('randall', 4800), ('limitations', 4801), ('padre', 4802), ('charitable', 4803), ('fish', 4804), ('conceive', 4805), ('trembling', 4806), ('anti-catholic', 4807), ('flatter', 4808), ('communal', 4809), ('iranian', 4810), ('ward', 4811), ('switch', 4812), ('community', 4813), ('animated', 4814), ('against', 4815), ('head', 4816), ('generally', 4817), ('tumult', 4818), ('.samuel', 4819), ('circumstances', 4820), ('.hollywood', 4821), ('.clever', 4822), ('questionable', 4823), ('roles', 4824), ('neither', 4825), ('.stevens', 4826), ('pleasurable', 4827), ('psychopathic', 4828), ('north', 4829), ('away', 4830), ('naturalistic', 4831), ('cheesy', 4832), ('fundamentally', 4833), ('literary', 4834), ('british', 4835), ('biopic', 4836), ('liberating', 4837), ('throws', 4838), ('akin', 4839), ('below', 4840), ('spooky', 4841), ('alice', 4842), ('learn', 4843), ('crossover', 4844), ('poignant', 4845), ('men', 4846), ('responsible', 4847), ('evident', 4848), ('wasted', 4849), ('skin', 4850), ('polished', 4851), ('urban', 4852), ('chosen', 4853), ('annoying', 4854), ('pandering', 4855), ('cipher', 4856), ('ah', 4857), ('phone', 4858), ('package', 4859), ('variety', 4860), ('acute', 4861), ('punctuated', 4862), ('sophomore', 4863), ('cleverness', 4864), ('rabbit-proof', 4865), ('wild', 4866), ('leaps', 4867), ('quirky', 4868), ('zippy', 4869), ('actions', 4870), ('contemplation', 4871), ('super-sized', 4872), ('america', 4873), ('helmer', 4874), ('bogdanovich', 4875), ('wait', 4876), ('locations', 4877), ('hideously', 4878), ('first-class', 4879), ('wise', 4880), (',', 4881), ('decades', 4882), ('vu', 4883), ('.new', 4884), ('crystal', 4885), ('masochism', 4886), ('east', 4887), ('partnerships', 4888), ('band', 4889), ('speaks', 4890), ('joyless', 4891), ('inc.', 4892), ('employ', 4893), ('moment', 4894), ('hospital', 4895), ('jason', 4896), ('bueller', 4897), ('lust', 4898), ('tart', 4899), ('center', 4900), ('murky', 4901), ('shot', 4902), ('valiantly', 4903), ('balanced', 4904), ('fluid', 4905), ('onscreen', 4906), ('false', 4907), ('scorn', 4908), ('.daughter', 4909), ('sour', 4910), ('penchant', 4911), ('craft', 4912), ('philip', 4913), ('she', 4914), ('long-suffering', 4915), ('criticism', 4916), ('decision', 4917), ('nair', 4918), ('spice', 4919), ('.steven', 4920), ('grief', 4921), ('blend', 4922), ('scarcely', 4923), ('richness', 4924), ('spellbinding', 4925), ('scores', 4926), ('shades', 4927), ('blip', 4928), ('.blue', 4929), ('funnier', 4930), ('shocking', 4931), ('hong', 4932), ('sensuous', 4933), ('explanation', 4934), ('abc', 4935), ('.``', 4936), ('taut', 4937), ('weaponry', 4938), ('.each', 4939), ('depicts', 4940), ('freud', 4941), ('.interesting', 4942), ('outcome', 4943), ('featuring', 4944), ('thematically', 4945), ('desperation', 4946), ('adult', 4947), ('loosely', 4948), ('economical', 4949), ('top-billed', 4950), ('holds', 4951), ('picture-perfect', 4952), ('dashing', 4953), ('contrivance', 4954), ('gunplay', 4955), ('exhausted', 4956), ('lambs', 4957), ('fingered', 4958), ('attendant', 4959), ('overly-familiar', 4960), ('achievements', 4961), ('possesses', 4962), ('unaffected', 4963), ('atop', 4964), ('shrewd', 4965), ('detriment', 4966), ('baran', 4967), ('display', 4968), ('lola', 4969), ('.smith', 4970), ('textbook', 4971), ('forte', 4972), ('sleeping', 4973), ('developing', 4974), ('frightening', 4975), ('hold', 4976), ('titus', 4977), ('self-indulgence', 4978), ('.viewers', 4979), ('revelatory', 4980), ('rotten', 4981), ('austin', 4982), ('sensuality', 4983), ('base', 4984), ('cary', 4985), ('animals', 4986), ('gasp', 4987), ('technique', 4988), ('.their', 4989), ('swept', 4990), ('.may', 4991), ('leaks', 4992), ('digital', 4993), ('passion', 4994), ('gunfire', 4995), ('eyes', 4996), ('searching', 4997), ('exceptionally', 4998), ('portraying', 4999), ('exclamation', 5000), ('able', 5001), ('competence', 5002), ('h.g.', 5003), ('appalling', 5004), ('learned', 5005), ('deceptively', 5006), ('entire', 5007), ('damme', 5008), ('squeeze', 5009), ('darling', 5010), ('preposterous', 5011), ('disgusting', 5012), ('backdrop', 5013), ('requires', 5014), ('greene', 5015), ('satisfy', 5016), ('church', 5017), ('inappropriate', 5018), ('dean', 5019), ('harrison', 5020), ('footage', 5021), ('.gaghan', 5022), ('spiced', 5023), ('raymond', 5024), ('humanizing', 5025), ('hammer', 5026), ('remake', 5027), ('.supposedly', 5028), ('build-up', 5029), ('trimmings', 5030), ('arnie', 5031), ('integrity', 5032), ('worm', 5033), ('fanciful', 5034), ('middle-of-the-road', 5035), ('trip', 5036), ('trappings', 5037), ('good-natured', 5038), ('betrayal', 5039), ('simpleminded', 5040), ('falling', 5041), ('self-conscious', 5042), ('painting', 5043), ('newfoundland', 5044), ('boots', 5045), ('300', 5046), ('?you', 5047), ('rattling', 5048), ('mine', 5049), ('red', 5050), ('spin', 5051), ('freddie', 5052), ('.beneath', 5053), ('collect', 5054), ('wayne', 5055), ('enjoyed', 5056), ('inexplicably', 5057), ('entry', 5058), ('toback', 5059), ('turkey', 5060), ('know', 5061), ('inability', 5062), ('carpenter', 5063), ('hotel', 5064), ('embarrassment', 5065), ('determined', 5066), ('limp', 5067), ('legendary', 5068), ('franchise', 5069), ('calvin', 5070), ('prism', 5071), ('latest', 5072), ('tomorrow', 5073), ('kid', 5074), ('help', 5075), ('creations', 5076), ('in', 5077), ('gradually', 5078), ('.less', 5079), ('labored', 5080), ('cliche-ridden', 5081), ('baggage', 5082), ('principal', 5083), ('.well', 5084), ('suits', 5085), ('dignity', 5086), ('sounds', 5087), ('hawk', 5088), ('glee', 5089), ('dead-on', 5090), ('.ah', 5091), ('occasional', 5092), ('blanket', 5093), ('monstrous', 5094), ('globe', 5095), ('milk', 5096), ('thornberrys', 5097), ('tasty', 5098), ('lane', 5099), ('backdrops', 5100), ('consequences', 5101), ('equalizer', 5102), ('virtue', 5103), ('seeking', 5104), ('sickly', 5105), ('motherhood', 5106), ('solutions', 5107), ('freight', 5108), ('amaro', 5109), ('inside', 5110), ('computer', 5111), ('raging', 5112), ('anticipated', 5113), ('tour', 5114), ('working', 5115), ('conventional', 5116), ('rock-solid', 5117), ('glib', 5118), ('postcard', 5119), ('centering', 5120), ('...its', 5121), ('ian', 5122), ('pacino', 5123), ('enjoying', 5124), ('victim', 5125), ('sermon', 5126), ('execution', 5127), ('complex', 5128), ('barrymore', 5129), ('nowhere', 5130), ('featured', 5131), ('thoughtfully', 5132), ('trust', 5133), ('hopkins', 5134), ('insists', 5135), ('.there', 5136), ('at', 5137), ('format', 5138), ('half', 5139), ('fatale', 5140), ('foster', 5141), ('evil', 5142), ('splitting', 5143), ('predict', 5144), ('tarantino', 5145), ('joe', 5146), ('price', 5147), ('disparate', 5148), ('vulgar', 5149), ('memorable', 5150), ('ditched', 5151), ('unlimited', 5152), ('soccer', 5153), ('regard', 5154), ('butter', 5155), ('alluring', 5156), ('animation', 5157), ('encouraging', 5158), ('relentless', 5159), ('wit', 5160), ('guess', 5161), ('few', 5162), ('chances', 5163), ('well-made', 5164), ('purposes', 5165), ('88-minute', 5166), ('cloying', 5167), ('sugarman', 5168), ('dash', 5169), ('.maryam', 5170), ('engagingly', 5171), ('irony', 5172), ('chou', 5173), ('image', 5174), ('sam', 5175), ('.true', 5176), ('vision', 5177), ('jr.', 5178), ('behold', 5179), ('ability', 5180), ('architecture', 5181), ('objects', 5182), ('appreciate', 5183), ('access', 5184), ('respect', 5185), ('hates', 5186), ('so', 5187), ('movie', 5188), ('accessible', 5189), ('helm', 5190), ('require', 5191), ('accomplishes', 5192), ('campy', 5193), ('chokes', 5194), ('.though', 5195), ('piffle', 5196), ('door', 5197), ('chomp', 5198), ('yorker', 5199), ('dance', 5200), ('mixture', 5201), ('present', 5202), ('assuming', 5203), ('sanctimonious', 5204), ('flaccid', 5205), ('tenacious', 5206), ('lies', 5207), ('incongruous', 5208), ('.gooding', 5209), ('satisfies', 5210), ('.everyone', 5211), ('oddly', 5212), ('several', 5213), ('serviceable', 5214), ('bracingly', 5215), ('goods', 5216), ('diggs', 5217), ('children', 5218), ('dad', 5219), ('astute', 5220), ('workplace', 5221), ('desired', 5222), ('thinly', 5223), ('.leave', 5224), ('loopy', 5225), ('escapism', 5226), ('benefits', 5227), ('productions', 5228), ('worse', 5229), ('benigni', 5230), ('detract', 5231), ('ambitions', 5232), ('plots', 5233), ('artifice', 5234), ('caddyshack', 5235), ('tedious', 5236), ('.-', 5237), ('companion', 5238), ('messy', 5239), ('first', 5240), ('seasonal', 5241), ('.possibly', 5242), ('jeremy', 5243), ('commended', 5244), ('effect', 5245), ('season', 5246), ('debate', 5247), ('night', 5248), ('.kids', 5249), ('tom', 5250), ('harvard', 5251), ('intro', 5252), ('windows', 5253), ('experiment', 5254), ('warned', 5255), ('avoids', 5256), ('wesley', 5257), ('sights', 5258), ('emphasizing', 5259), ('cast', 5260), ('savour', 5261), ('.many', 5262), ('recognizable', 5263), ('.filmmaker', 5264), ('screenplays', 5265), ('certainly', 5266), ('koury', 5267), ('damn', 5268), ('originality', 5269), ('core', 5270), ('derrida', 5271), ('.filled', 5272), ('further', 5273), ('career', 5274), ('.especially', 5275), ('showing', 5276), ('off-beat', 5277), ('edition', 5278), ('.take', 5279), ('fantastic', 5280), (\"o'fallon\", 5281), ('pun', 5282), ('distract', 5283), ('jews', 5284), ('wander', 5285), ('guilty-pleasure', 5286), ('by', 5287), ('90', 5288), ('lapses', 5289), ('projects', 5290), ('accent', 5291), ('amir', 5292), ('else', 5293), ('musicians', 5294), ('tall', 5295), ('pays', 5296), ('ray', 5297), ('see', 5298), ('scarifying', 5299), ('disappoint', 5300), ('apply', 5301), ('excellent', 5302), ('blow', 5303), ('shared', 5304), ('florid', 5305), ('cost', 5306), ('narcissism', 5307), ('emotionally', 5308), ('nervous', 5309), ('studios', 5310), ('.call', 5311), ('elusive', 5312), ('reminiscent', 5313), ('hilariously', 5314), ('uneven', 5315), ('humor', 5316), ('maddeningly', 5317), ('sensational', 5318), ('audiard', 5319), ('jolt', 5320), ('roberto', 5321), ('submarine', 5322), ('buddy', 5323), ('economic', 5324), ('snore', 5325), ('shaken', 5326), ('glitz', 5327), ('torn', 5328), ('improbable', 5329), ('breakthrough', 5330), ('pathos', 5331), ('ahead', 5332), ('payback', 5333), ('subtle', 5334), ('acceptable', 5335), ('sci-fi', 5336), ('raised', 5337), ('butterflies', 5338), ('eisenstein', 5339), ('.attal', 5340), ('audacious', 5341), ('herzog', 5342), ('traditionally', 5343), ('intelligence', 5344), ('unabashedly', 5345), ('unbridled', 5346), ('neat', 5347), ('guilt', 5348), ('seeming', 5349), ('waydowntown', 5350), ('vertical', 5351), ('nickleby', 5352), ('.narc', 5353), ('scott', 5354), ('deeds', 5355), ('welsh', 5356), ('hitting', 5357), ('expressing', 5358), ('articulates', 5359), ('another', 5360), ('bodies', 5361), ('metropolis', 5362), ('schepisi', 5363), ('.sinks', 5364), ('unintentional', 5365), ('prospect', 5366), ('jerry', 5367), ('finds', 5368), ('sticking', 5369), ('vibrant', 5370), ('poignancy', 5371), ('skins', 5372), ('arbitrary', 5373), ('improves', 5374), ('rob', 5375), ('mark', 5376), ('sway', 5377), ('star', 5378), ('well-intentioned', 5379), ('addict', 5380), ('evans', 5381), ('get', 5382), ('elbows', 5383), ('fighting', 5384), ('disguising', 5385), ('married', 5386), ('thousands', 5387), ('flashes', 5388), ('condescension', 5389), ('infidelity', 5390), ('there', 5391), ('recycled', 5392), ('emerging', 5393), ('voice-over', 5394), ('haul', 5395), ('blasphemous', 5396), ('.sheridan', 5397), ('stroke', 5398), ('picture', 5399), ('backhanded', 5400), ('real-life', 5401), ('variation', 5402), ('underneath', 5403), ('malaise', 5404), ('literally', 5405), ('danger', 5406), ('mild', 5407), ('fans', 5408), ('compassion', 5409), ('undercuts', 5410), ('wen', 5411), ('correct', 5412), ('conceal', 5413), ('unfamiliar', 5414), ('procedure', 5415), ('careens', 5416), ('their', 5417), ('collective', 5418), ('his', 5419), ('brother', 5420), ('zombie', 5421), ('explores', 5422), ('budding', 5423), ('celebrated', 5424), ('nightmare', 5425), ('aggressively', 5426), ('collage', 5427), ('elegance', 5428), ('.nohe', 5429), ('.jackson', 5430), ('dylan', 5431), ('.arteta', 5432), ('5', 5433), ('sees', 5434), ('hugely', 5435), ('cure', 5436), ('carol', 5437), ('appetite', 5438), ('wow', 5439), ('dilemma', 5440), ('undead', 5441), ('easier', 5442), ('invest', 5443), ('tenderness', 5444), ('unprecedented', 5445), ('bale', 5446), ('generosity', 5447), ('self-consciously', 5448), ('one-note', 5449), ('on', 5450), ('mind-numbingly', 5451), ('vs.', 5452), ('executed', 5453), ('1950s', 5454), ('dying', 5455), ('vulgarity', 5456), ('prejudice', 5457), ('self-awareness', 5458), ('.alas', 5459), ('stallone', 5460), ('gondry', 5461), ('favorite', 5462), ('crush', 5463), ('burns', 5464), ('claim', 5465), ('exquisitely', 5466), ('ratliff', 5467), ('forbidden', 5468), ('strangely', 5469), ('soderbergh', 5470), ('distracted', 5471), ('futuristic', 5472), ('imagination', 5473), ('fixating', 5474), ('purportedly', 5475), ('flawless', 5476), ('undone', 5477), ('unknown', 5478), ('prevails', 5479), ('.enjoyably', 5480), ('.according', 5481), ('lose', 5482), ('spits', 5483), ('epiphany', 5484), ('drama', 5485), ('characterizations', 5486), ('gender', 5487), ('nervy', 5488), ('shred', 5489), ('bonus', 5490), ('wallowing', 5491), ('confluence', 5492), ('louis', 5493), ('notably', 5494), ('proportions', 5495), ('.adam', 5496), ('remain', 5497), ('icy', 5498), ('nor', 5499), ('given', 5500), ('complaint', 5501), ('seduce', 5502), (\"n't\", 5503), ('disappointments', 5504), ('flame', 5505), ('overrun', 5506), ('gratingly', 5507), ('villain', 5508), ('tremendous', 5509), ('wilson', 5510), ('.collapses', 5511), ('hear', 5512), ('oddity', 5513), ('porn', 5514), ('stark', 5515), ('feathers', 5516), ('.these', 5517), ('.sweet', 5518), ('sisters', 5519), ('jennifer', 5520), ('instinct', 5521), ('searches', 5522), ('conflict', 5523), ('inhuman', 5524), ('served', 5525), ('money', 5526), ('palette', 5527), ('population', 5528), ('testud', 5529), ('concession', 5530), ('bath', 5531), ('achronological', 5532), ('heaven', 5533), ('neutral', 5534), ('bryan', 5535), ('revel', 5536), ('sport', 5537), ('somber', 5538), ('lan', 5539), ('testimony', 5540), ('as', 5541), ('stretches', 5542), ('secretary', 5543), ('chocolate', 5544), ('assassination', 5545), ('eddie', 5546), ('choices', 5547), ('sincerity', 5548), ('buttons', 5549), ('abstract', 5550), ('tricks', 5551), ('.how', 5552), ('confused', 5553), ('judgment', 5554), ('educational', 5555), ('chief', 5556), ('nonconformist', 5557), ('brian', 5558), ('falters', 5559), ('destiny', 5560), ('largely', 5561), ('cover', 5562), ('kinetic', 5563), ('fabulous', 5564), ('lovable', 5565), ('racial', 5566), ('seconds', 5567), ('trace', 5568), ('incompetent', 5569), ('hip-hop', 5570), ('franklin', 5571), ('rap', 5572), ('pluto', 5573), ('enjoys', 5574), ('choose', 5575), ('proved', 5576), ('lengthy', 5577), ('strenuously', 5578), ('touch', 5579), ('concentration', 5580), ('fighter', 5581), ('impart', 5582), ('reasonably', 5583), ('paradoxically', 5584), ('...a', 5585), ('rise', 5586), ('gel', 5587), ('comics', 5588), ('shamelessly', 5589), ('curves', 5590), ('.so', 5591), ('eyelids', 5592), ('grit', 5593), ('swank', 5594), ('circus', 5595), ('bluster', 5596), ('phoenix', 5597), ('.shallow', 5598), ('dud', 5599), ('house', 5600), ('outsiders', 5601), ('faso', 5602), ('breakdown', 5603), ('president', 5604), ('class', 5605), ('fate', 5606), ('light-hearted', 5607), ('daily', 5608), ('.whether', 5609), ('twaddle', 5610), ('bread', 5611), ('easy', 5612), ('bill', 5613), ('?when', 5614), ('terry', 5615), ('idiosyncratic', 5616), (\"'ve\", 5617), ('appears', 5618), ('desiccated', 5619), ('eager', 5620), ('.kung', 5621), ('scream', 5622), ('dollars', 5623), ('ironically', 5624), ('consideration', 5625), ('tailor', 5626), ('mendes', 5627), ('experienced', 5628), ('larger', 5629), ('feelings', 5630), ('surrounded', 5631), ('haneke', 5632), ('mannerisms', 5633), ('unknowable', 5634), ('exploitation', 5635), ('grownups', 5636), ('smiles', 5637), ('constructed', 5638), ('tuned', 5639), ('.warm', 5640), ('expression', 5641), ('gianni', 5642), ('sinks', 5643), ('loaded', 5644), ('transforms', 5645), ('store', 5646), ('elegiac', 5647), ('goodness', 5648), ('races', 5649), ('wears', 5650), ('pitiful', 5651), ('boat', 5652), ('scripting', 5653), ('simplicity', 5654), ('powerfully', 5655), ('mummy', 5656), ('ferocity', 5657), ('mired', 5658), ('.essentially', 5659), ('open', 5660), ('setting', 5661), ('anchors', 5662), ('ineptly', 5663), ('blatant', 5664), ('rivalry', 5665), ('supply', 5666), ('tunisian', 5667), ('spectacularly', 5668), ('frighteningly', 5669), ('crammed', 5670), ('intentions', 5671), ('taken', 5672), ('existence', 5673), ('rambling', 5674), ('monsters', 5675), ('lifeless', 5676), ('vehicle', 5677), ('languorous', 5678), ('lyricism', 5679), ('course', 5680), ('\\\\*\\\\*\\\\*', 5681), ('straight', 5682), ('larry', 5683), ('predictable', 5684), ('enjoyably', 5685), ('confront', 5686), ('grips', 5687), ('risky', 5688), ('.kurys', 5689), ('bizarre', 5690), ('enigma', 5691), ('.coppola', 5692), ('flaws', 5693), ('charisma', 5694), ('likes', 5695), ('point-of-view', 5696), ('creates', 5697), ('were', 5698), ('cynical', 5699), ('unsympathetic', 5700), ('versions', 5701), ('authenticity', 5702), ('incorporates', 5703), ('strongly', 5704), ('extremes', 5705), ('slackers', 5706), ('feminine', 5707), ('main', 5708), ('.paul', 5709), ('screenwriter', 5710), ('surveys', 5711), ('lopez', 5712), ('transcend', 5713), ('siegel', 5714), ('answer', 5715), ('anne-sophie', 5716), ('raucous', 5717), ('harbor', 5718), ('needs', 5719), ('runner', 5720), ('fontaine', 5721), ('jackass', 5722), ('forgiven', 5723), ('catch', 5724), ('ego', 5725), ('lurid', 5726), ('collaborators', 5727), ('tiresomely', 5728), ('flow', 5729), ('sarandon', 5730), ('reruns', 5731), ('.ozpetek', 5732), ('necessarily', 5733), ('superior', 5734), ('player', 5735), ('adams', 5736), ('defiance', 5737), ('respond', 5738), ('long', 5739), ('hiding', 5740), ('fabric', 5741), ('this', 5742), ('heft', 5743), ('philadelphia', 5744), ('.nearly', 5745), ('per', 5746), ('well-developed', 5747), ('out', 5748), ('espionage', 5749), ('manipulative', 5750), ('gain', 5751), ('sophisticated', 5752), ('sloppy', 5753), ('jack', 5754), ('national', 5755), ('damaged', 5756), ('historic', 5757), ('drumline', 5758), ('roughshod', 5759), ('commercial', 5760), ('multiple', 5761), ('african-americans', 5762), ('unable', 5763), ('fanatics', 5764), ('control', 5765), ('english', 5766), ('rest', 5767), ('rooms', 5768), ('kinda', 5769), ('dragon', 5770), ('farrelly', 5771), ('walk', 5772), ('b-movie', 5773), ('attract', 5774), ('.both', 5775), ('ups', 5776), ('ms.', 5777), ('pitfalls', 5778), ('impulses', 5779), ('fun', 5780), ('.mindless', 5781), ('terrorism', 5782), ('problems', 5783), ('simple', 5784), ('niro', 5785), ('sustain', 5786), ('probably', 5787), ('courage', 5788), ('lived', 5789), ('determination', 5790), ('switches', 5791), ('alagna', 5792), ('fervently', 5793), ('shines', 5794), ('smartly', 5795), ('travesty', 5796), ('wistful', 5797), ('leonard', 5798), ('helped', 5799), ('cold', 5800), ('!it', 5801), ('borders', 5802), ('visceral', 5803), ('ticket', 5804), ('politics', 5805), ('jessica', 5806), ('throwback', 5807), ('taiwanese', 5808), ('undoubtedly', 5809), ('mockumentary', 5810), ('chicago', 5811), ('cloyingly', 5812), ('gross', 5813), ('spike', 5814), ('crassly', 5815), ('goose', 5816), ('evolution', 5817), ('charismatic', 5818), ('high', 5819), ('giggles', 5820), ('knowing', 5821), ('lowbrow', 5822), ('joan', 5823), ('tensions', 5824), ('stillborn', 5825), ('introduce', 5826), ('scottish', 5827), ('midway', 5828), ('steers', 5829), ('member', 5830), ('orders', 5831), ('confronting', 5832), ('.represents', 5833), ('deliciously', 5834), ('.maggie', 5835), ('spears', 5836), ('idiotic', 5837), ('wastes', 5838), ('youthful', 5839), ('science', 5840), ('accomplishments', 5841), ('shape', 5842), ('environment', 5843), ('chills', 5844), ('impossible', 5845), ('altman', 5846), ('streak', 5847), ('dampened', 5848), ('renner', 5849), ('sorely', 5850), ('theme', 5851), ('are', 5852), ('spiffy', 5853), ('li', 5854), ('imagery', 5855), ('sneaky', 5856), ('bringing', 5857), ('brains', 5858), ('tolkien', 5859), ('higher', 5860), ('can', 5861), ('irresistibly', 5862), ('regain', 5863), ('.best', 5864), ('.every', 5865), ('connected', 5866), ('wondering', 5867), ('himself', 5868), ('revealed', 5869), ('identity', 5870), ('impersonation', 5871), ('marginally', 5872), ('subplot', 5873), ('targeted', 5874), ('iran', 5875), ('fix', 5876), ('conan', 5877), ('formulaic', 5878), ('laid', 5879), ('sordid', 5880), ('screenwriters', 5881), ('scooby', 5882), ('ingratiating', 5883), ('dirty', 5884), ('corner', 5885), ('stultifying', 5886), ('excuse', 5887), ('top', 5888), ('unmemorable', 5889), ('conceits', 5890), ('dass', 5891), ('averting', 5892), ('rising', 5893), ('.rubbo', 5894), ('succeed', 5895), ('janice', 5896), ('veers', 5897), ('unleashes', 5898), ('central', 5899), ('leavened', 5900), ('excruciating', 5901), ('inspires', 5902), ('sorvino', 5903), ('.completely', 5904), ('affable', 5905), ('well-executed', 5906), ('inspired', 5907), ('nudity', 5908), ('slapdash', 5909), ('thinking', 5910), ('gorgeous', 5911), ('ragged', 5912), ('fantasized', 5913), ('ad', 5914), ('credible', 5915), ('ensures', 5916), ('.now', 5917), ('choreography', 5918), ('air', 5919), ('heartening', 5920), ('include', 5921), ('wayward', 5922), ('afloat', 5923), ('detective', 5924), ('gets', 5925), ('context', 5926), ('creeps', 5927), ('.maelstrom', 5928), ('expecting', 5929), ('gaudy', 5930), ('health', 5931), ('wahlberg', 5932), ('regards', 5933), ('low-rent', 5934), ('deja', 5935), ('hayek', 5936), ('consciousness', 5937), ('ourselves', 5938), ('torture', 5939), ('herself', 5940), ('drowns', 5941), ('enhances', 5942), ('transformation', 5943), ('resident', 5944), ('critical', 5945), ('brawny', 5946), ('fierce', 5947), ('elfriede', 5948), ('episodes', 5949), ('pristine', 5950), ('redundancy', 5951), ('unrealized', 5952), ('school', 5953), ('ridiculous', 5954), ('biography', 5955), ('self-glorification', 5956), ('aid', 5957), ('superficiality', 5958), ('captivating', 5959), ('tarkovsky', 5960), ('capability', 5961), ('lynch', 5962), ('mixed', 5963), ('becomes', 5964), ('chou-chou', 5965), ('hide', 5966), ('heroic', 5967), ('affection', 5968), ('sabotaged', 5969), ('timely', 5970), ('demographically', 5971), ('nonstop', 5972), ('minority', 5973), ('sparks', 5974), ('articulate', 5975), ('pointless', 5976), ('brittle', 5977), ('?--', 5978), ('diversion', 5979), ('junkie', 5980), ('modesty', 5981), ('sumptuous', 5982), ('loss', 5983), ('weight', 5984), ('santa', 5985), ('non-stop', 5986), ('final', 5987), ('infused', 5988), ('education', 5989), ('affleck', 5990), ('pop', 5991), ('.buy', 5992), ('foundation', 5993), ('unfulfilled', 5994), ('freaky', 5995), ('sobering', 5996), ('once', 5997), ('solely', 5998), ('.or', 5999), ('touches', 6000), ('grey', 6001), ('washed', 6002), ('colorful', 6003), ('.directors', 6004), ('cable', 6005), ('dv', 6006), ('portrait', 6007), ('birds', 6008), ('.almost', 6009), ('precarious', 6010), ('perverse', 6011), ('ample', 6012), ('discovery', 6013), ('wore', 6014), ('penn', 6015), ('expected', 6016), ('sequels', 6017), ('fly', 6018), ('ill-conceived', 6019), ('bloated', 6020), ('unlikable', 6021), ('panoramic', 6022), ('mary', 6023), ('squareness', 6024), ('staged', 6025), ('invention', 6026), ('dubious', 6027), ('streets', 6028), ('eye-popping', 6029), ('wanting', 6030), ('us', 6031), ('terrific', 6032), ('unfocused', 6033), ('.predictable', 6034), ('admirable', 6035), ('finding', 6036), ('lunch', 6037), ('.`', 6038), ('.it', 6039), ('denied', 6040), ('exhausting', 6041), ('clue', 6042), ('plummets', 6043), ('picked', 6044), ('stage', 6045), ('remains', 6046), ('sexy', 6047), ('fellowship', 6048), ('hedonistic', 6049), ('police', 6050), ('construct', 6051), ('!the', 6052), ('survived', 6053), ('edward', 6054), ('reduce', 6055), ('emptiness', 6056), ('.austin', 6057), ('produce', 6058), ('holy', 6059), ('.entirely', 6060), ('gadgets', 6061), ('with', 6062), ('fit', 6063), ('effecting', 6064), ('constructs', 6065), ('awe', 6066), ('wood', 6067), ('parable', 6068), ('battle', 6069), ('mistake', 6070), ('matinee', 6071), ('you', 6072), ('last-minute', 6073), ('every', 6074), ('william', 6075), ('director', 6076), ('impossibly', 6077), ('pregnant', 6078), ('alive', 6079), ('.obvious', 6080), ('histrionics', 6081), ('martial', 6082), ('characterization', 6083), ('film', 6084), ('espn', 6085), ('japanese', 6086), ('reveals', 6087), ('cherry', 6088), ('pastry', 6089), ('stiff', 6090), ('tout', 6091), ('stunning', 6092), ('fat', 6093), ('.until', 6094), ('u.s.', 6095), ('.soderbergh', 6096), ('truck', 6097), ('reaction', 6098), ('brothers', 6099), ('.something', 6100), ('wiseman', 6101), ('covers', 6102), ('inquiry', 6103), ('holly', 6104), ('unimaginable', 6105), ('incredibly', 6106), ('bone', 6107), ('closely', 6108), ('moody', 6109), ('sweet-and-sour', 6110), ('post-production', 6111), ('farts', 6112), ('rating', 6113), ('buñuel', 6114), ('nelson', 6115), ('extra', 6116), ('nights', 6117), ('strong', 6118), ('slick', 6119), ('sitcom', 6120), ('lizard', 6121), ('revealing', 6122), ('elicit', 6123), ('stuffed', 6124), ('compensate', 6125), ('defies', 6126), ('tawdry', 6127), ('trilogy', 6128), ('morality', 6129), ('saga', 6130), ('serial', 6131), ('kahlo', 6132), ('actors', 6133), ('dull', 6134), ('outbursts', 6135), ('pryor', 6136), ('approached', 6137), ('explore', 6138), ('before', 6139), ('relying', 6140), ('fashioned', 6141), ('kitchen', 6142), ('favour', 6143), ('combustible', 6144), ('dust', 6145), ('kinky', 6146), ('glorified', 6147), ('parent-child', 6148), ('relevant', 6149), ('participants', 6150), ('\\\\/', 6151), ('claustrophobic', 6152), ('pileup', 6153), ('robin', 6154), ('wreck', 6155), ('isolation', 6156), ('difficulties', 6157), ('name', 6158), ('.shot', 6159), ('trees', 6160), ('players', 6161), ('possibly', 6162), ('station', 6163), ('frequent', 6164), ('drugs', 6165), ('.mattei', 6166), ('opposite', 6167), ('tragic', 6168), ('conceptual', 6169), ('excruciatingly', 6170), ('symbolic', 6171), ('suitably', 6172), (\"''i\", 6173), ('austen', 6174), ('flicks', 6175), ('strange', 6176), ('freeman', 6177), ('continuity', 6178), ('justice', 6179), ('capra', 6180), ('leigh', 6181), ('tunes', 6182), ('elling', 6183), ('tackling', 6184), ('perhaps', 6185), ('surrealism', 6186), ('dramatic', 6187), ('machismo', 6188), ('bollywood', 6189), ('accidental', 6190), ('.death', 6191), ('druggy', 6192), ('gaining', 6193), ('relentlessly', 6194), ('six', 6195), ('ideal', 6196), ('essential', 6197), ('notion', 6198), ('passages', 6199), ('unbearable', 6200), ('last', 6201), ('auteil', 6202), ('not', 6203), ('focuses', 6204), ('minutes', 6205), ('begun', 6206), ('stopped', 6207), ('pokes', 6208), ('adds', 6209), ('fluke', 6210), ('!its', 6211), ('dot', 6212), ('appropriate', 6213), ('.that', 6214), ('scorsese', 6215), ('groups', 6216), ('.entertaining', 6217), ('recall', 6218), ('diary', 6219), ('endeavour', 6220), ('crushingly', 6221), ('floor', 6222), ('bittersweet', 6223), ('card', 6224), ('retooled', 6225), ('performed', 6226), ('!this', 6227), ('mysteries', 6228), ('sincere', 6229), ('structured', 6230), ('witness', 6231), ('pianist', 6232), ('eight', 6233), ('up', 6234), ('stasis', 6235), ('incorporate', 6236), ('offend', 6237), ('furiously', 6238), ('ballot', 6239), ('ignite', 6240), ('buffs', 6241), ('resist', 6242), ('boomer', 6243), ('entranced', 6244), ('rare', 6245), ('jacquot', 6246), ('baby', 6247), ('roberts', 6248), ('rent', 6249), ('funniest', 6250), ('ladder', 6251), ('racist', 6252), ('.he', 6253), ('producer', 6254), ('writer', 6255), ('dressed', 6256), ('purists', 6257), ('.mildly', 6258), ('insecurity', 6259), ('attention', 6260), ('mission', 6261), ('recommendation', 6262), ('hot-button', 6263), ('quirks', 6264), ('driven', 6265), ('process', 6266), ('self-preservation', 6267), ('motown', 6268), ('schindler', 6269), ('religious', 6270), ('forgoes', 6271), ('days', 6272), ('mtv', 6273), ('noticing', 6274), ('debut', 6275), ('mugging', 6276), ('screenwriting', 6277), ('ranks', 6278), ('adaptation', 6279), ('shortcomings', 6280), ('framed', 6281), ('trotting', 6282), ('repeatedly', 6283), ('lagaan', 6284), ('singularly', 6285), ('without', 6286), ('deft', 6287), ('.wilco', 6288), ('aware', 6289), ('unintentionally', 6290), ('treads', 6291), ('.barely', 6292), ('fiction', 6293), ('hill', 6294), ('revels', 6295), ('state', 6296), ('.fear', 6297), ('decency', 6298), ('constantly', 6299), ('inoffensive', 6300), ('.romantic', 6301), ('rose', 6302), ('net', 6303), ('angel', 6304), ('scooby-doo', 6305), ('medical', 6306), ('poetry', 6307), ('writer-director', 6308), ('nachtwey', 6309), ('possibilities', 6310), ('overboard', 6311), ('minute', 6312), ('farcical', 6313), ('forgiveness', 6314), ('ruthless', 6315), ('hippie', 6316), ('athleticism', 6317), ('struggles', 6318), ('1958', 6319), ('neatly', 6320), ('string', 6321), ('delectable', 6322), ('institution', 6323), ('.spielberg', 6324), ('pessimistic', 6325), ('subtext', 6326), ('naughty', 6327), ('thrill', 6328), ('over', 6329), ('guarded', 6330), ('talents', 6331), ('south', 6332), ('installment', 6333), ('determine', 6334), ('information', 6335), ('ultimate', 6336), ('deep', 6337), ('.twenty', 6338), ('pinocchio', 6339), ('?please', 6340), ('trenchant', 6341), ('animatronic', 6342), ('.neither', 6343), ('graphic', 6344), ('frank', 6345), ('capturing', 6346), ('oscar', 6347), ('didacticism', 6348), ('9\\\\/11', 6349), ('operates', 6350), ('frame', 6351), ('dilutes', 6352), ('whodunit', 6353), ('three-dimensional', 6354), ('harmless', 6355), ('form', 6356), ('suggested', 6357), ('games', 6358), ('.shanghai', 6359), ('solemn', 6360), (')', 6361), ('.part', 6362), ('expect', 6363), ('.mckay', 6364), ('jarring', 6365), ('korea', 6366), ('happens', 6367), ('want', 6368), ('lumbering', 6369), ('unfaithful', 6370), ('walked', 6371), ('along', 6372), ('.parts', 6373), ('cuteness', 6374), ('suck', 6375), ('bordering', 6376), ('humour', 6377), ('jaded', 6378), ('paint-by-numbers', 6379), ('behan', 6380), ('defeats', 6381), ('.kapur', 6382), ('distraction', 6383), ('competition', 6384), ('meet', 6385), ('energetic', 6386), ('.rodriguez', 6387), ('explosive', 6388), ('70s', 6389), ('impressions', 6390), ('delights', 6391), ('accuse', 6392), ('elevates', 6393), ('woo', 6394), ('subtitles', 6395), ('170', 6396), ('unpleasant', 6397), ('strung-together', 6398), ('escape', 6399), ('lame', 6400), ('.delivers', 6401), ('bewitched', 6402), ('deception', 6403), ('reggio', 6404), ('evolved', 6405), ('.bravo', 6406), ('mr.', 6407), ('pulled', 6408), ('surprising', 6409), ('frozen', 6410), ('offbeat', 6411), ('dances', 6412), ('wholesome', 6413), ('serenity', 6414), ('.witty', 6415), ('84', 6416), ('.thumbs', 6417), ('thumbs', 6418), ('cultures', 6419), ('conventions', 6420), ('1\\\\/2', 6421), ('etc.', 6422), ('insomnia', 6423), ('.funny', 6424), ('lackluster', 6425), ('opaque', 6426), ('seesawing', 6427), ('kang', 6428), ('worlds', 6429), ('does', 6430), ('rebel', 6431), ('refuses', 6432), ('departs', 6433), ('hope', 6434), ('sign', 6435), ('warren', 6436), ('infantile', 6437), ('warm', 6438), ('greater', 6439), ('marquis', 6440), ('ship', 6441), ('significantly', 6442), ('level', 6443), ('units', 6444), ('satisfying', 6445), ('subtly', 6446), ('adaptations', 6447), ('author', 6448), ('goldmember', 6449), ('consumed', 6450), ('ozpetek', 6451), ('overwritten', 6452), ('nourishing', 6453), ('addresses', 6454), ('creepy', 6455), ('saving', 6456), ('section', 6457), ('explains', 6458), ('.serious', 6459), ('ninety', 6460), ('idemoto', 6461), ('specimen', 6462), ('onto', 6463), ('straining', 6464), ('.cold', 6465), ('haunted', 6466), ('intellectuals', 6467), ('#', 6468), ('though', 6469), ('those', 6470), ('highly', 6471), ('.they', 6472), ('circuit', 6473), ('haphazard', 6474), ('seat', 6475), ('michael', 6476), ('far-fetched', 6477), ('finale', 6478), ('plympton', 6479), ('plumbs', 6480), ('glass', 6481), ('stand-up', 6482), ('badly', 6483), ('prefer', 6484), (\"'ll\", 6485), ('creativity', 6486), ('muddle', 6487), ('camera', 6488), ('backed', 6489), ('reluctant', 6490), ('prim', 6491), ('humorous', 6492), ('friend', 6493), ('itself', 6494), ('honest', 6495), ('spectacular', 6496), ('besides', 6497), ('bark', 6498), ('environmental', 6499), ('where', 6500), ('tripe', 6501), ('freundlich', 6502), ('gaghan', 6503), ('storm', 6504), ('pace', 6505), ('expedience', 6506), ('halfway', 6507), ('unflinching', 6508), ('lift', 6509), ('uncommonly', 6510), ('slender', 6511), ('ingenuity', 6512), ('ram', 6513), ('sacrificed', 6514), ('wisely', 6515), ('cute', 6516), ('above', 6517), ('optimistic', 6518), ('margarita', 6519), ('reached', 6520), ('dragons', 6521), ('stages', 6522), ('helping', 6523), ('predecessor', 6524), ('sprecher', 6525), ('fires', 6526), ('spielberg', 6527), ('clinical', 6528), ('.evelyn', 6529), ('cremaster', 6530), ('searing', 6531), ('figuring', 6532), ('dancing', 6533), ('leading', 6534), ('considers', 6535), ('suited', 6536), ('kahn', 6537), (\"'a\", 6538), ('website', 6539), ('tired', 6540), ('undercover', 6541), ('barrels', 6542), ('fascinating', 6543), ('.ultimately', 6544), ('flair', 6545), ('unsatisfying', 6546), ('9-11', 6547), ('worn-out', 6548), ('boilerplate', 6549), ('column', 6550), ('survival', 6551), ('finished', 6552), ('boys', 6553), ('darkly', 6554), ('instincts', 6555), ('compelling', 6556), ('tells', 6557), ('degree', 6558), ('coping', 6559), ('mediocre', 6560), ('razzle-dazzle', 6561), ('.anyone', 6562), ('overlooked', 6563), ('droll', 6564), ('aims', 6565), ('.same', 6566), ('doug', 6567), ('willingness', 6568), ('todd', 6569), ('finally', 6570), ('strangeness', 6571), ('bold', 6572), ('dumb', 6573), ('chicken', 6574), ('superficial', 6575), ('dragonfly', 6576), ('fine', 6577), ('vignettes', 6578), ('learning', 6579), ('riveted', 6580), ('intimacy', 6581), ('dysfunction', 6582), ('resonate', 6583), ('worn', 6584), ('.wow', 6585), ('couple', 6586), ('cartoons', 6587), ('comments', 6588), ('seeing', 6589), ('believer', 6590), ('couples', 6591), ('drive', 6592), ('picnic', 6593), ('reno', 6594), ('breathtaking', 6595), ('apted', 6596), ('fingers', 6597), ('nuanced', 6598), ('accept', 6599), ('desperately', 6600), ('expose', 6601), ('hustler', 6602), ('held', 6603), ('.fortunately', 6604), ('direct', 6605), ('profile', 6606), ('flip-flop', 6607), ('green', 6608), ('bogus', 6609), ('exterior', 6610), ('explaining', 6611), ('self-esteem', 6612), ('too', 6613), ('shameless', 6614), ('topics', 6615), ('background', 6616), ('channel', 6617), ('suspended', 6618), ('all', 6619), ('repeated', 6620), ('bloody', 6621), ('heartache', 6622), ('mile', 6623), ('somewhat', 6624), ('menacing', 6625), ('marvelously', 6626), ('wilde', 6627), ('riveting', 6628), ('.reyes', 6629), ('exploitative', 6630), ('.intelligent', 6631), ('moviegoing', 6632), ('.changing', 6633), ('charm', 6634), ('hollow', 6635), ('people', 6636), ('synthetic', 6637), ('dumbed-down', 6638), ('hard', 6639), ('waits', 6640), ('started', 6641), ('acts', 6642), ('heady', 6643), ('modest', 6644), ('secondary', 6645), ('?no', 6646), ('assumption', 6647), ('totally', 6648), ('4ever', 6649), ('learns', 6650), ('meaningless', 6651), ('illogical', 6652), ('repetitive', 6653), ('makers', 6654), ('affords', 6655), ('irrational', 6656), ('real-time', 6657), ('chan', 6658), ('scenario', 6659), ('absurdity', 6660), ('prolonged', 6661), ('scratching', 6662), ('compulsively', 6663), ('mill', 6664), ('smoother', 6665), ('shootings', 6666), ('expressions', 6667), ('bumbling', 6668), ('steamy', 6669), ('keen', 6670), ('treasure', 6671), ('felt', 6672), ('substantial', 6673), ('half-bad', 6674), ('ludicrous', 6675), ('bothered', 6676), ('norton', 6677), ('.originality', 6678), ('.while', 6679), ('protagonists', 6680), ('maids', 6681), ('frighten', 6682), ('frothy', 6683), ('bitter', 6684), ('feet', 6685), ('prison', 6686), ('letterman', 6687), ('competent', 6688), ('stein', 6689), ('zeal', 6690), ('toothless', 6691), ('contact', 6692), ('gripping', 6693), ('arrest', 6694), ('.generic', 6695), ('devastatingly', 6696), ('counterparts', 6697), ('pulling', 6698), ('heated', 6699), ('guise', 6700), ('sand', 6701), ('grown-up', 6702), ('headed', 6703), ('after-school', 6704), ('excessively', 6705), ('hypertime', 6706), ('caine', 6707), ('exposé', 6708), ('fascination', 6709), ('giving', 6710), ('walt', 6711), ('drug', 6712), ('appeals', 6713), ('narrated', 6714), ('spite', 6715), ('christmas', 6716), ('chaotic', 6717), ('ignore', 6718), ('horse', 6719), ('outlandish', 6720), ('dramedy', 6721), ('purity', 6722), ('transcendent', 6723), ('cliché', 6724), ('reliance', 6725), ('.screenwriter', 6726), ('stereotype', 6727), ('crowd', 6728), ('cerebral', 6729), ('careful', 6730), ('beacon', 6731), ('deaths', 6732), ('x', 6733), ('tearing', 6734), ('folk', 6735), ('exploration', 6736), ('erotically', 6737), ('aloof', 6738), ('ramsay', 6739), ('what', 6740), ('eating', 6741), ('permits', 6742), ('camaraderie', 6743), ('shooting', 6744), ('assumes', 6745), ('wounds', 6746), ('four', 6747), ('elegantly', 6748), ('reynolds', 6749), ('embracing', 6750), ('recent', 6751), ('naturally', 6752), ('tu', 6753), ('taboo', 6754), ('grab', 6755), ('middle-class', 6756), ('gonna', 6757), ('terribly', 6758), ('equivalent', 6759), ('loved', 6760), ('awake', 6761), ('rip-off', 6762), ('majority', 6763), ('constant', 6764), ('confidence', 6765), ('western', 6766), ('dover', 6767), ('z-boys', 6768), ('right-thinking', 6769), ('novels', 6770), ('clooney', 6771), ('war', 6772), ('melt', 6773), ('spins', 6774), ('praise', 6775), ('sticks', 6776), ('brink', 6777), ('phones', 6778), ('sick', 6779), ('mercilessly', 6780), ('hastily', 6781), ('jeff', 6782), ('asking', 6783), ('soulful', 6784), ('provoke', 6785), ('art', 6786), ('anywhere', 6787), ('friel', 6788), ('chuck', 6789), ('.other', 6790), ('savor', 6791), ('river', 6792), ('predicament', 6793), ('villains', 6794), ('lewis', 6795), ('shapeless', 6796), ('pulse', 6797), ('supernatural', 6798), ('segment', 6799), ('lightly', 6800), ('costner', 6801), ('exactly', 6802), ('explicit', 6803), ('credit', 6804), ('desperate', 6805), ('strengths', 6806), ('rewritten', 6807), ('insipid', 6808), ('observations', 6809), ('buried', 6810), ('tick', 6811), ('hopeful', 6812), ('try', 6813), ('trials', 6814), ('hefty', 6815), ('garbage', 6816), ('dana', 6817), ('admittedly', 6818), ('hour-and-a-half', 6819), ('one-of-a-kind', 6820), ('slasher', 6821), ('robust', 6822), ('sensation', 6823), ('bros.', 6824), ('triumph', 6825), ('.vividly', 6826), ('byler', 6827), ('self', 6828), ('tossed', 6829), ('mike', 6830), ('.stale', 6831), ('manners', 6832), ('attraction', 6833), ('comically', 6834), ('paint-by-number', 6835), ('phoniness', 6836), ('affirming', 6837), ('idiots', 6838), ('capacity', 6839), (\"'\", 6840), ('bites', 6841), ('taps', 6842), ('bolero', 6843), ('hurley', 6844), ('stimulating', 6845), ('m', 6846), ('michelle', 6847), ('.ong', 6848), ('worst', 6849), ('collision', 6850), ('offer', 6851), ('trade', 6852), ('game', 6853), ('prep-school', 6854), ('brim', 6855), ('lapaglia', 6856), ('involve', 6857), ('indulgent', 6858), ('huston', 6859), ('surprised', 6860), ('promise', 6861), ('spader', 6862), ('anymore', 6863), ('antonia', 6864), ('native', 6865), ('save', 6866), ('two-dimensional', 6867), ('julianne', 6868), ('willing', 6869), ('purpose', 6870), ('fondness', 6871), ('sucked', 6872), ('precision', 6873), ('posing', 6874), ('comic', 6875), ('seven', 6876), ('marshall', 6877), ('le', 6878), ('weepy', 6879), ('perceptive', 6880), ('entertainingly', 6881), ('confined', 6882), ('beginners', 6883), ('gantz', 6884), ('.sitting', 6885), ('triumphantly', 6886), ('rarity', 6887), ('dubbed', 6888), ('underlying', 6889), ('wrong', 6890), ('.slap', 6891), ('young', 6892), ('page', 6893), ('peter', 6894), ('palatable', 6895), ('chronicle', 6896), ('political', 6897), ('laborious', 6898), ('cut', 6899), ('nobody', 6900), ('ford', 6901), ('equilibrium', 6902), ('unfolds', 6903), ('.bolstered', 6904), ('.hugely', 6905), ('afghan', 6906), ('brings', 6907), ('revisionist', 6908), ('preaching', 6909), ('fast-paced', 6910), ('documentary', 6911), ('frontal', 6912), ('lazy', 6913), ('qualify', 6914), ('accompanies', 6915), ('lieutenant', 6916), ('punch', 6917), ('seriousness', 6918), ('christopher', 6919), ('symbols', 6920), ('tormented', 6921), ('hubert', 6922), ('desert', 6923), ('shearer', 6924), ('cliches', 6925), ('mystery', 6926), ('liberties', 6927), ('psychodrama', 6928), ('gentle', 6929), ('very', 6930), ('arrived', 6931), ('vaguely', 6932), ('evoke', 6933), ('resentment', 6934), ('boorishness', 6935), ('ice', 6936), ('vampires', 6937), ('high-concept', 6938), ('uncinematic', 6939), ('slapstick', 6940), ('unimaginative', 6941), ('.deliberately', 6942), ('valley', 6943), ('halloween', 6944), ('campaign', 6945), ('windtalkers', 6946), ('spread', 6947), ('inspiration', 6948), ('development', 6949), ('sting', 6950), ('grown-ups', 6951), ('trifle', 6952), ('laughs', 6953), ('talk', 6954), ('.dogtown', 6955), ('perils', 6956), ('relaxed', 6957), ('.fast', 6958), ('undernourished', 6959), ('stoppard', 6960), ('field', 6961), ('upscale', 6962), ('mentally', 6963), ('anybody', 6964), ('light', 6965), ('janklowicz-mann', 6966), ('warrior', 6967), ('glum', 6968), ('athletes', 6969), ('slapping', 6970), ('depict', 6971), ('.her', 6972), ('breathes', 6973), ('said', 6974), ('extension', 6975), ('bubbles', 6976), ('creative', 6977), ('caper', 6978), ('uncertain', 6979), ('tight', 6980), ('inane', 6981), ('steven', 6982), ('sun', 6983), ('frustration', 6984), ('whom', 6985), ('list', 6986), ('frida', 6987), ('saved', 6988), ('marks', 6989), ('dominated', 6990), ('.remarkable', 6991), ('hero', 6992), ('performance', 6993), ('shyamalan', 6994), ('fragmented', 6995), ('fluent', 6996), ('paean', 6997), ('vh1', 6998), ('desolate', 6999), ('hack', 7000), ('mel', 7001), ('rehash', 7002), ('seal', 7003), ('!a', 7004), ('grating', 7005), ('individuals', 7006), ('colour', 7007), ('depths', 7008), ('exceedingly', 7009), ('2000', 7010), ('bible', 7011), ('resonance', 7012), ('winner', 7013), ('delivers', 7014), ('fresh-faced', 7015), ('julia', 7016), ('both', 7017), ('humble', 7018), ('lint', 7019), ('abhorrent', 7020), ('performers', 7021), ('tattered', 7022), ('attempt', 7023), ('bed', 7024), ('chimes', 7025), ('place', 7026), (\"'d\", 7027), ('year', 7028), ('realistically', 7029), ('gusto', 7030), ('mad', 7031), ('appealing', 7032), ('defiantly', 7033), ('.instead', 7034), ('passing', 7035), ('literature', 7036), ('ask', 7037), ('corpse', 7038), ('downhill', 7039), ('self-aware', 7040), ('cinema', 7041), ('gong', 7042), ('buy', 7043), ('listening', 7044), ('noyce', 7045), ('laugh', 7046), ('possibility', 7047), ('property', 7048), ('kiddies', 7049), ('example', 7050), ('applying', 7051), ('david', 7052), ('flashback', 7053), ('treading', 7054), ('primary', 7055), ('expert', 7056), ('pesky', 7057), ('exceptional', 7058), ('narrative', 7059), ('again', 7060), ('ripe', 7061), ('dahmer', 7062), ('starring', 7063), ('finger', 7064), ('nonsense', 7065), ('mermaid', 7066), ('exceeds', 7067), ('holofcener', 7068), ('solving', 7069), ('clichés', 7070), ('back', 7071), ('nicholas', 7072), ('right', 7073), ('gibson', 7074), ('flailing', 7075), ('eyre', 7076), ('kill', 7077), ('african', 7078), ('grand', 7079), ('obligatory', 7080), ('besotted', 7081), ('throughout', 7082), ('stoops', 7083), ('future', 7084), ('egoyan', 7085), ('leaves', 7086), ('.talk', 7087), ('uniformly', 7088), ('kissing', 7089), ('snooze', 7090), ('mamet', 7091), ('so-called', 7092), ('westerners', 7093), ('!true', 7094), ('snatch', 7095), ('gap', 7096), ('escapes', 7097), ('owen', 7098), ('remember', 7099), ('innovative', 7100), ('equal', 7101), ('developed', 7102), ('2', 7103), ('larky', 7104), ('sandra', 7105), ('hit-and-miss', 7106), ('tremors', 7107), ('distinguish', 7108), ('movie-star', 7109), ('miss', 7110), ('.by', 7111), ('world', 7112), ('changing', 7113), ('facetious', 7114), ('made-for-tv', 7115), ('hang', 7116), ('trimming', 7117), ('hallmarks', 7118), ('short', 7119), ('pauly', 7120), ('reminded', 7121), ('soul-searching', 7122), ('natured', 7123), ('case', 7124), ('leather', 7125), ('palpable', 7126), ('kurt', 7127), ('impressively', 7128), ('win', 7129), ('coming', 7130), ('.at', 7131), ('heyday', 7132), ('fest', 7133), ('bar', 7134), ('detailing', 7135), ('liotta', 7136), ('teenage', 7137), ('asleep', 7138), ('musset', 7139), ('disappointed', 7140), ('liberation', 7141), ('proceedings', 7142), ('total', 7143), ('fourth', 7144), ('orange', 7145), ('interpersonal', 7146), ('tacky', 7147), ('exploit', 7148), ('plod', 7149), ('pyrotechnics', 7150), ('business', 7151), ('tears', 7152), ('water', 7153), ('13', 7154), ('paulette', 7155), ('alternate', 7156), ('loathsome', 7157), ('local', 7158), ('.much', 7159), ('.beautifully', 7160), ('threadbare', 7161), ('sexuality', 7162), ('mid', 7163), ('imagined', 7164), ('illustrates', 7165), ('acquainted', 7166), ('richard', 7167), ('shallow', 7168), ('forum', 7169), ('longest', 7170), ('minds', 7171), ('duck', 7172), ('rewarding', 7173), ('hype', 7174), ('diverting', 7175), ('douglas', 7176), ('obsessive', 7177), ('think', 7178), ('tsai', 7179), ('rocks', 7180), ('delight', 7181), ('willis', 7182), ('measured', 7183), ('hawke', 7184), ('factors', 7185), ('impress', 7186), ('thrown', 7187), ('discontent', 7188), ('hal', 7189), ('warmed', 7190), ('compliment', 7191), ('strangers', 7192), ('bio-pic', 7193), ('proof', 7194), ('!...', 7195), ('ebullient', 7196), ('mcculloch', 7197), ('product', 7198), ('fart', 7199), ('conscious', 7200), ('easily', 7201), ('tanks', 7202), ('human', 7203), ('portrays', 7204), ('combination', 7205), ('gut-wrenching', 7206), ('jean', 7207), ('waited', 7208), ('painfully', 7209), ('flatly', 7210), ('superfluous', 7211), ('laurence', 7212), ('jelinek', 7213), ('virtues', 7214), ('inelegant', 7215), ('maintaining', 7216), ('brendan', 7217), ('functions', 7218), ('travails', 7219), ('artful', 7220), ('anchoring', 7221), ('piece', 7222), ('subjects', 7223), ('adorable', 7224), ('provocative', 7225), ('detail', 7226), ('donovan', 7227), ('overlong', 7228), ('chair', 7229), ('exists', 7230), ('pause', 7231), ('hawn', 7232), (';', 7233), ('sadness', 7234), ('heroine', 7235), ('hunk', 7236), ('sing', 7237), ('fits', 7238), ('describes', 7239), ('.hip-hop', 7240), ('giddy', 7241), ('treatment', 7242), ('retelling', 7243), ('sophistication', 7244), (\"''it\", 7245), ('jealousy', 7246), ('age', 7247), ('.wiseman', 7248), ('collection', 7249), ('procession', 7250), ('endeavor', 7251), ('librarian', 7252), ('layer', 7253), ('roots', 7254), ('lacking', 7255), ('fascinated', 7256), ('impenetrable', 7257), ('movie-of-the-week', 7258), ('jumbled', 7259), ('pickup', 7260), ('kieslowski', 7261), ('mug', 7262), ('cagney', 7263), ('maze', 7264), ('names', 7265), ('spend', 7266), ('deuces', 7267), ('flavorless', 7268), ('here', 7269), ('blood', 7270), ('invited', 7271), ('.young', 7272), ('of', 7273), ('images', 7274), ('.captures', 7275), ('boost', 7276), ('countless', 7277), ('exception', 7278), ('full-bodied', 7279), ('feast', 7280), ('origins', 7281), ('spontaneity', 7282), ('brush', 7283), ('.maintains', 7284), ('suburban', 7285), ('sorrow', 7286), ('sharper', 7287), ('parochial', 7288), ('sharp', 7289), ('been', 7290), ('juliette', 7291), ('overexposed', 7292), ('strongest', 7293), ('vintage', 7294), ('score', 7295), ('substance', 7296), ('generous', 7297), ('paying', 7298), ('.would', 7299), ('still', 7300), ('either', 7301), ('resolution', 7302), ('outright', 7303), ('adequate', 7304), ('philosophy', 7305), ('absurdly', 7306), ('deteriorates', 7307), ('memento', 7308), ('21st', 7309), ('pure', 7310), ('laugh-out-loud', 7311), ('.sex', 7312), ('perfect', 7313), ('.gorgeous', 7314), ('misfire', 7315), ('dead-end', 7316), ('flawed', 7317), ('doze', 7318), ('carries', 7319), ('110', 7320), ('approaching', 7321), ('group', 7322), ('permeates', 7323), ('château', 7324), ('digits', 7325), ('uninvolving', 7326), ('.wonder', 7327), ('racing', 7328), ('small-town', 7329), ('boisterous', 7330), ('other', 7331), ('placing', 7332), ('directly', 7333), ('labute', 7334), ('earlier', 7335), ('wonder', 7336), ('cletis', 7337), ('.however', 7338), ('standard', 7339), ('flying', 7340), ('interpretations', 7341), ('self-consciousness', 7342), ('log', 7343), ('fizzle', 7344), ('bullock', 7345), ('heads', 7346), ('anomie', 7347), ('liza', 7348), ('spell', 7349), ('seldahl', 7350), ('lyrical', 7351), ('three-hour', 7352), ('charms', 7353), ('beaten', 7354), ('architect', 7355), ('.constantly', 7356), ('worthy', 7357), ('often-funny', 7358), ('creatures', 7359), ('affected', 7360), ('funny', 7361), ('smiling', 7362), ('turpin', 7363), (\"'the\", 7364), ('unusually', 7365), ('for', 7366), ('.your', 7367), ('points', 7368), ('blame', 7369), ('honor', 7370), ('phony', 7371), ('sluggish', 7372), ('gifted', 7373), ('kapur', 7374), ('oprah', 7375), ('deeply', 7376), ('&', 7377), ('.enigma', 7378), ('.never', 7379), ('versus', 7380), ('gave', 7381), ('girl', 7382), ('walsh', 7383), ('sense', 7384), ('aside', 7385), ('version', 7386), ('.otherwise', 7387), ('howler', 7388), ('responsibility', 7389), ('lessons', 7390), ('$', 7391), ('appreciated', 7392), ('stays', 7393), ('amalgam', 7394), ('.like', 7395), ('.hashiguchi', 7396), ('smirk', 7397), ('.hardly', 7398), ('.indeed', 7399), ('tone', 7400), ('poem', 7401), ('talky', 7402), ('lesser', 7403), ('focus', 7404), ('goo', 7405), ('famous', 7406), ('calls', 7407), ('el', 7408), ('bogs', 7409), ('types', 7410), ('ring', 7411), ('comedy', 7412), ('jacques', 7413), ('gary', 7414), ('day-lewis', 7415), ('.too', 7416), ('however', 7417), ('inauthentic', 7418), ('poets', 7419), ('miami', 7420), ('readily', 7421), ('daytime', 7422), ('reign', 7423), ('mcdowell', 7424), ('followed', 7425), ('soufflé', 7426), ('bodice-ripper', 7427), ('compared', 7428), ('stars', 7429), ('comedian', 7430), ('.sayles', 7431), ('derek', 7432), ('hit', 7433), ('setpieces', 7434), ('stylings', 7435), ('drags', 7436), ('.bring', 7437), ('obviousness', 7438), ('plays', 7439), ('skims', 7440), ('awry', 7441), ('composition', 7442), ('powers', 7443), ('seen', 7444), ('inconsistent', 7445), ('nicholson', 7446), ('clumsy', 7447), ('urgent', 7448), ('sublime', 7449), ('spoof', 7450), ('uncharted', 7451), ('hollywood', 7452), ('dealers', 7453), ('longing', 7454), ('nonexistent', 7455), ('terrorists', 7456), ('sensationalism', 7457), ('ease', 7458), ('redemption', 7459), ('conjured', 7460), ('melancholic', 7461), ('satirical', 7462), ('unsurprising', 7463), ('lie', 7464), ('racism', 7465), ('neverland', 7466), ('bull', 7467), ('superman', 7468), ('disney', 7469), ('spider-man', 7470), ('privileged', 7471), ('how', 7472), ('contraption', 7473), ('edited', 7474), ('persona', 7475), ('abyss', 7476), ('consuming', 7477), ('lengths', 7478), ('commands', 7479), ('instead', 7480), ('anime', 7481), ('affectionate', 7482), ('concept', 7483), ('read', 7484), ('impeccable', 7485), ('glimpse', 7486), ('horrible', 7487), ('believing', 7488), ('conversations', 7489), ('.told', 7490), ('faith', 7491), ('suspect', 7492), ('choreographed', 7493), ('classic', 7494), ('stories', 7495), ('.she', 7496), ('fill', 7497), ('general', 7498), ('siege', 7499), ('heartbreaking', 7500), ('all-time', 7501), ('.romanek', 7502), ('advertised', 7503), ('meditative', 7504), ('nothing', 7505), ('passably', 7506), ('precious', 7507), ('rip', 7508), ('sketchy', 7509), ('.except', 7510), ('ethereal', 7511), ('cram', 7512), ('recommend', 7513), ('start', 7514), ('conflicted', 7515), ('assured', 7516), ('flat', 7517), ('michel', 7518), ('well-written', 7519), ('.nicole', 7520), ('cheery', 7521), ('broadway', 7522), ('settles', 7523), ('something', 7524), ('freedom', 7525), ('indifferent', 7526), ('guest', 7527), ('embraced', 7528), ('swim', 7529), ('sure', 7530), ('.frank', 7531), ('jumbo', 7532), ('?yes', 7533), ('....', 7534), ('grinning', 7535), ('verges', 7536), ('target', 7537), ('thriller', 7538), ('philippe', 7539), ('.yes', 7540), ('copy', 7541), ('.meticulously', 7542), ('100-minute', 7543), ('glimmer', 7544), ('frenetic', 7545), ('.charming', 7546), ('update', 7547), ('hitchcock', 7548), ('prurient', 7549), ('pedigree', 7550), ('suggest', 7551), ('important', 7552), ('moralistic', 7553), ('engaging', 7554), ('sundance', 7555), ('fall', 7556), ('diaries', 7557), ('will', 7558), ('historical', 7559), ('offerings', 7560), ('.contains', 7561), ('rewarded', 7562), ('watched', 7563), ('bettany', 7564), ('outrageous', 7565), ('canned', 7566), ('.exactly', 7567), ('honesty', 7568), ('inuit', 7569), ('fulfilling', 7570), ('jacobson', 7571), ('nijinsky', 7572), ('labour', 7573), ('throw', 7574), (\"'has\", 7575), ('visible', 7576), ('nomination', 7577), ('meat', 7578), ('gimmick', 7579), ('quirkiness', 7580), ('upon', 7581), ('saucy', 7582), ('enjoyable', 7583), ('paper-thin', 7584), ('imbued', 7585), ('.because', 7586), ('harsh', 7587), ('recalls', 7588), ('labor', 7589), ('currently', 7590), ('close', 7591), ('crafted', 7592), ('fare', 7593), ('sweetest', 7594), ('report', 7595), ('preceded', 7596), ('charge', 7597), ('award', 7598), ('captain', 7599), ('coppola', 7600), ('zhang', 7601), ('step', 7602), ('bankrupt', 7603), ('.on', 7604), ('autobiographical', 7605), ('curiosity', 7606), ('having', 7607), ('apart', 7608), ('95', 7609), ('lot', 7610), ('coherent', 7611), ('arc', 7612), ('ben', 7613), ('campanella', 7614), ('well-done', 7615), ('voyeuristic', 7616), ('these', 7617), ('worshipful', 7618), ('grasp', 7619), ('screening', 7620), ('border', 7621), ('a', 7622), ('morrison', 7623), ('lily', 7624), ('mother', 7625), ('rousing', 7626), ('.very', 7627), ('super', 7628), ('hatred', 7629), ('behave', 7630), ('demonstration', 7631), ('valiant', 7632), ('black-and-white', 7633), ('individual', 7634), ('.proof', 7635), ('tissues', 7636), ('compendium', 7637), ('bikes', 7638), ('christianity', 7639), ('vice', 7640), ('updating', 7641), ('sex', 7642), ('queen', 7643), ('impostor', 7644), ('stifling', 7645), ('warriors', 7646), ('sparse', 7647), ('addition', 7648), ('history', 7649), ('viscerally', 7650), ('absurdities', 7651), ('seinfeld', 7652), ('heightened', 7653), ('informed', 7654), ('neighborhood', 7655), ('make', 7656), ('avoid', 7657), ('intense', 7658), ('slim', 7659), ('.noyce', 7660), ('established', 7661), ('exquisite', 7662), ('canadian', 7663), ('bride', 7664), ('path', 7665), ('tender', 7666), ('technically', 7667), ('breed', 7668), ('.made', 7669), ('modernize', 7670), ('thesis', 7671), ('chases', 7672), ('troopers', 7673), ('little', 7674), ('propaganda', 7675), ('resemblance', 7676), ('masterpiece', 7677), ('.formula', 7678), ('one-liners', 7679), ('williams', 7680), ('showcases', 7681), ('needlessly', 7682), ('fork', 7683), ('dark', 7684), ('contempt', 7685), ('rental', 7686), ('empire', 7687), ('teeming', 7688), ('stomach', 7689), ('a-list', 7690), ('compromised', 7691), ('clad', 7692), ('smack', 7693), ('died', 7694), ('chouraqui', 7695), ('reduces', 7696), ('china', 7697), ('quickly', 7698), ('haynes', 7699), ('also', 7700), ('senses', 7701), ('terms', 7702), ('playful', 7703), ('dynamic', 7704), ('way', 7705), ('absolute', 7706), ('unfortunate', 7707), ('luck', 7708), ('mall', 7709), ('korean', 7710), ('politically', 7711), ('become', 7712), ('slap-happy', 7713), ('significance', 7714), ('guessing', 7715), ('spark', 7716), ('arrive', 7717), ('disturbing', 7718), ('arts', 7719), ('attempted', 7720), ('subtler', 7721), ('finely', 7722), ('enormously', 7723), ('intrigue', 7724), ('happily', 7725), ('rigid', 7726), ('warner', 7727), ('naive', 7728), ('sugar', 7729), ('sweat', 7730), ('following', 7731), ('blows', 7732), ('status', 7733), ('drawing', 7734), ('widow', 7735), ('abandon', 7736), ('.payne', 7737), ('latter', 7738), ('disgust', 7739), ('liability', 7740), ('creating', 7741), ('hour', 7742), ('problematic', 7743), ('looked', 7744), ('standup', 7745), ('ya-ya', 7746), ('until', 7747), ('volume', 7748), ('.makes', 7749), ('blandness', 7750), ('any', 7751), ('twist', 7752), ('soar', 7753), ('extreme', 7754), ('off-kilter', 7755), ('diva', 7756), ('metropolitan', 7757), ('self-satisfied', 7758), ('rumor', 7759), ('delightfully', 7760), ('devito', 7761), ('guilty', 7762), ('pushed', 7763), ('great-grandson', 7764), ('routine', 7765), ('invincible', 7766), ('anne', 7767), ('jimmy', 7768), ('ascends', 7769), ('whimsical', 7770), ('und', 7771), ('toss', 7772), ('atrocious', 7773), ('whale', 7774), ('known', 7775), ('rendering', 7776), ('.given', 7777), ('nostalgia', 7778), ('hitler', 7779), ('well-acted', 7780), ('kevin', 7781), ('ears', 7782), ('cal', 7783), ('bluescreen', 7784), ('invaluable', 7785), ('tearjerker', 7786), ('slathered', 7787), ('hammy', 7788), ('prose', 7789), ('inject', 7790), ('direct-to-video', 7791), ('conditioning', 7792), ('threw', 7793), ('joke', 7794), ('superbly', 7795), ('lawrence', 7796), ('difference', 7797), ('enthusiasm', 7798), ('.lazy', 7799), ('facet', 7800), ('uniquely', 7801), ('universal', 7802), ('years', 7803), ('smacks', 7804), ('drab', 7805), ('warning', 7806), ('worth', 7807), ('dreck', 7808), ('won', 7809), ('close-ups', 7810), ('sidesplitting', 7811), ('load', 7812), ('turning', 7813), ('weirdo', 7814), ('distance', 7815), ('let', 7816), ('snipes', 7817), ('so-bad-it', 7818), ('cia', 7819), ('.alternately', 7820), ('chilly', 7821), ('firing', 7822), ('dude', 7823), ('childish', 7824), ('.morvern', 7825), ('.shyamalan', 7826), ('utterly', 7827), ('barf', 7828), ('needy', 7829), ('cranky', 7830), ('skills', 7831), ('work-in-progress', 7832), ('explored', 7833), ('pleasure', 7834), ('research', 7835), ('awakening', 7836), ('credibility', 7837), ('blockbuster', 7838), ('.thanks', 7839), ('performing', 7840), ('opens', 7841), ('alienating', 7842), ('assembly', 7843), ('puff', 7844), ('mindless', 7845), ('maudlin', 7846), ('add', 7847), ('megaplex', 7848), ('dragged', 7849), ('journalistic', 7850), ('verve', 7851), ('refugees', 7852), ('carved', 7853), ('meaty', 7854), ('use', 7855), ('convictions', 7856), ('common', 7857), ('elegant', 7858), ('mannered', 7859), ('values', 7860), ('deserving', 7861), ('bouncing', 7862), ('judd', 7863), ('missing', 7864), ('lion', 7865), ('death', 7866), ('performances', 7867), ('tension', 7868), ('consequence', 7869), ('tuxedo', 7870), ('moved', 7871), ('written', 7872), ('spends', 7873), ('dreary', 7874), ('good', 7875), ('chuckles', 7876), ('moving', 7877), ('near-masterpiece', 7878), ('theaters', 7879), ('nouvelle', 7880), ('michell', 7881), ('small', 7882), ('chasm', 7883), ('failure', 7884), ('fancy', 7885), ('indecent', 7886), ('fears', 7887), ('barriers', 7888), ('trailer', 7889), ('uncanny', 7890), ('concoction', 7891), ('white', 7892), ('round', 7893), ('processor', 7894), ('.sad', 7895), ('jones', 7896), ('.does', 7897), ('neil', 7898), ('flowers', 7899), ('davis', 7900), ('accuracy', 7901), ('stunts', 7902), ('ensemble', 7903), ('gloomy', 7904), ('chemistry', 7905), ('golden', 7906), ('circle', 7907), ('punishment', 7908), ('seriously', 7909), ('literate', 7910), ('driver', 7911), ('rampant', 7912), ('artistes', 7913), ('allowing', 7914), ('sociological', 7915), ('owes', 7916), ('old', 7917), ('soap', 7918), ('generation', 7919), ('signposts', 7920), ('uplifting', 7921), ('which', 7922), ('brilliantly', 7923), ('resourceful', 7924), ('tends', 7925), ('suspenseful', 7926), ('ultimately', 7927), ('britney', 7928), ('pungent', 7929), ('stuff', 7930), ('exuberance', 7931), ('shabby', 7932), ('toro', 7933), ('husband', 7934), ('spy', 7935), ('ordinary', 7936), ('effects', 7937), ('struggling', 7938), ('mormon', 7939), ('enormous', 7940), ('meaning', 7941), ('attacks', 7942), ('.trying', 7943), ('dogtown', 7944), ('fuss', 7945), ('distinguished', 7946), ('gas', 7947), ('fraser', 7948), ('breath', 7949), ('stake', 7950), ('devoid', 7951), ('exploitive', 7952), ('theories', 7953), ('respite', 7954), ('ingredients', 7955), ('dry', 7956), ('act', 7957), ('empty', 7958), ('comprehension', 7959), ('brutality', 7960), ('feral', 7961), ('simpsons', 7962), ('sleazy', 7963), ('fewer', 7964), ('wells', 7965), ('similarly', 7966), ('fluffy', 7967), ('occupied', 7968), ('design', 7969), ('industry', 7970), ('tiniest', 7971), ('generates', 7972), ('existing', 7973), ('first-time', 7974), ('trots', 7975), ('.none', 7976), ('than', 7977), ('lend', 7978), ('setups', 7979), ('sarah', 7980), ('intolerable', 7981), ('increase', 7982), ('wanted', 7983), ('overly', 7984), ('digressions', 7985), ('.fontaine', 7986), ('flight', 7987), ('feat', 7988), ('taking', 7989), ('dares', 7990), ('humanity', 7991), ('masterfully', 7992), ('wang', 7993), ('episodic', 7994), ('cheaper', 7995), ('festival', 7996), ('numbered', 7997), ('orgy', 7998), ('la', 7999), ('walter', 8000), ('sending', 8001), ('chooses', 8002), ('san', 8003), ('discussion', 8004), ('shakespeare', 8005), ('fish-out-of-water', 8006), ('paced', 8007), ('set', 8008), ('`', 8009), ('biographical', 8010), ('shows', 8011), ('ploddingly', 8012), ('retooling', 8013), ('incident', 8014), ('rooted', 8015), ('coulda', 8016), ('dummies', 8017), ('brand', 8018), ('da', 8019), ('creeping', 8020), ('solondz', 8021), ('rote', 8022), ('kafka', 8023), ('insecure', 8024), ('physically', 8025), ('cocky', 8026), ('occurs', 8027), ('figures', 8028), ('insistence', 8029), ('smile', 8030), ('thrusts', 8031), ('understands', 8032), ('create', 8033), ('whimper', 8034), ('ethical', 8035), ('fax', 8036), ('jet', 8037), ('allows', 8038), ('chateau', 8039), ('may', 8040), ('epps', 8041), ('bore', 8042), ('inert', 8043), ('papin', 8044), ('skies', 8045), ('sake', 8046), ('knockout', 8047), ('alexander', 8048), ('grows', 8049), ('mainly', 8050), ('smoking', 8051), ('exist', 8052), ('defeated', 8053), ('sad', 8054), ('emphasis', 8055), ('nasty', 8056), ('encounter', 8057), ('vulnerability', 8058), ('low', 8059), ('stretched', 8060), ('.psychologically', 8061), ('artsy', 8062), ('depends', 8063), ('snake', 8064), ('call', 8065), ('action', 8066), ('afterschool', 8067), ('illustrating', 8068), ('rodriguez', 8069), ('ecological', 8070), ('sillier', 8071), ('singer', 8072), ('shoulders', 8073), ('ended', 8074), ('liu', 8075), ('allegedly', 8076), ('goes', 8077), ('oppressive', 8078), ('panic', 8079), ('eccentric', 8080), ('tang', 8081), ('splendor', 8082), ('plight', 8083), ('reduced', 8084), ('15', 8085), ('.after', 8086), ('reach', 8087), ('inventive', 8088), ('rich', 8089), ('ruined', 8090), ('find', 8091), ('.fluffy', 8092), ('bartleby', 8093), ('outer', 8094), ('program', 8095), ('rappers', 8096), ('.but', 8097), ('.exciting', 8098), ('perdition', 8099), ('landscape', 8100), ('hoary', 8101), ('ellen', 8102), ('comedies', 8103), ('waiting', 8104), ('town', 8105), ('delivered', 8106), ('crisis', 8107), ('analytical', 8108), ('what-if', 8109), ('correctness', 8110), ('united', 8111), ('shatters', 8112), ('dramatically', 8113), ('believable', 8114), ('disjointed', 8115), ('smash', 8116), ('2002', 8117), ('factor', 8118), ('intimate', 8119), ('pertinent', 8120), ('intricately', 8121), ('part', 8122), ('pleasantly', 8123), ('.what', 8124), ('miracle', 8125), ('told', 8126), ('redeeming', 8127), ('powerpuff', 8128), ('quality', 8129), ('colors', 8130), ('ties', 8131), ('demme', 8132), ('unwatchable', 8133), ('kinds', 8134), ('depiction', 8135), ('cop', 8136), ('fragile', 8137), ('poverty', 8138), ('lives', 8139), ('difficulty', 8140), ('joyous', 8141), ('tough', 8142), ('xxx', 8143), ('drawn', 8144), ('sloppily', 8145), ('god', 8146), ('stylized', 8147), ('humdrum', 8148), ('meandering', 8149), ('.worth', 8150), ('.davis', 8151), ('expensive', 8152), ('chain', 8153), ('?it', 8154), ('.peter', 8155), ('chick', 8156), ('60', 8157), ('self-important', 8158), ('millions', 8159), ('.the', 8160), ('sturm', 8161), ('recycle', 8162), ('drooling', 8163), ('.standing', 8164), ('weirdness', 8165), ('topic', 8166), ('accents', 8167), ('scrooge', 8168), ('situations', 8169), ('mixing', 8170), ('presentation', 8171), ('bogged', 8172), ('signs', 8173), ('jumps', 8174), ('payami', 8175), ('unforced', 8176), ('palestinian', 8177), ('.you', 8178), ('struggle', 8179), ('conveying', 8180), ('grandeur', 8181), ('directing', 8182), ('growth', 8183), ('kathy', 8184), ('puberty', 8185), ('.maid', 8186), ('hyped', 8187), ('lends', 8188), ('pie', 8189), ('collateral', 8190), ('indie', 8191), ('slam-bang', 8192), ('irritating', 8193), ('works', 8194), ('max', 8195), ('noble', 8196), ('deniro', 8197), ('plot', 8198), ('walks', 8199), ('predecessors', 8200), ('freshness', 8201), ('despair', 8202), ('shoddy', 8203), ('sade', 8204), ('innocence', 8205), ('ryan', 8206), ('artistically', 8207), ('area', 8208), ('instantly', 8209), ('kept', 8210), ('low-key', 8211), ('30', 8212), ('interviews', 8213), ('wallet', 8214), ('juwanna', 8215), ('expiration', 8216), ('positively', 8217), ('workout', 8218), ('definitive', 8219), ('crowd-pleaser', 8220), ('moviegoers', 8221), ('actress', 8222), ('redundant', 8223), ('extravagant', 8224), ('musings', 8225), ('amateurish', 8226), ('callow', 8227), ('recommended', 8228), ('number', 8229), ('missed', 8230), ('interpretation', 8231), ('stretch', 8232), ('sly', 8233), ('nuance', 8234), ('.poignant', 8235), ('documentaries', 8236), ('males', 8237), ('kane', 8238), ('choice', 8239), ('life-affirming', 8240), ('celebration', 8241), ('houses', 8242), ('professional', 8243), ('plucking', 8244), ('interestingly', 8245), ('lacks', 8246), ('downward', 8247), ('hodgepodge', 8248), ('treated', 8249), ('account', 8250), ('.labute', 8251), ('fact', 8252), ('required', 8253), ('thirst', 8254), ('features', 8255), ('conspicuous', 8256), ('since', 8257), ('.deliciously', 8258), ('recognize', 8259), ('.hoffman', 8260), ('woefully', 8261), ('.foster', 8262), ('seek', 8263), ('interest', 8264), ('sack', 8265), ('compromise', 8266), ('kieran', 8267), ('starts', 8268), ('television', 8269), ('therefore', 8270), ('masquerade', 8271), ('charlie', 8272), ('tempting', 8273), ('mars', 8274), ('angels', 8275), ('duke', 8276), ('boobs', 8277), ('.proves', 8278), ('gaps', 8279), ('distant', 8280), ('cheat', 8281), ('smartest', 8282), ('absurdist', 8283), ('towards', 8284), ('?who', 8285), ('psychedelic', 8286), ('.whenever', 8287), ('jane', 8288), ('porridge', 8289), ('igby', 8290), ('lonely', 8291), ('misfortune', 8292), ('burn', 8293), ('reverent', 8294), ('crazed', 8295), ('accurately', 8296), ('late', 8297), ('gentility', 8298), ('bathos', 8299), ('election', 8300), ('loyal', 8301), ('high-profile', 8302), ('wars', 8303), ('provides', 8304), ('injects', 8305), ('outtakes', 8306), ('belly', 8307), ('cannibal', 8308), ('waterlogged', 8309), ('merit', 8310), ('immature', 8311), ('magical', 8312), ('lifestyle', 8313), ('best', 8314), ('soars', 8315), ('castro', 8316), ('sappy', 8317), ('schmidt', 8318), ('sacrificing', 8319), ('forward', 8320), ('feardotcom', 8321), ('snow', 8322), ('sizzle', 8323), (\"'in\", 8324), ('humorless', 8325), ('sends', 8326), ('derives', 8327), ('norwegian', 8328), ('.lan', 8329), ('memorial', 8330), ('indian', 8331), ('later', 8332), ('forget', 8333), ('yellow', 8334), ('aftertaste', 8335), ('throwaway', 8336), ('favored', 8337), ('phenomenal', 8338), ('lingering', 8339), ('.two', 8340), ('friendships', 8341), ('interaction', 8342), ('.rarely', 8343), ('supremely', 8344), ('witch', 8345), ('jonathan', 8346), ('restroom', 8347), ('technology', 8348), ('james', 8349), ('crimen', 8350), ('.earnest', 8351), ('problem', 8352), ('sufficient', 8353), ('.without', 8354), ('intellect', 8355), ('demise', 8356), ('shadyac', 8357), ('chinese', 8358), ('break', 8359), ('changes', 8360), ('columbus', 8361), ('scenery', 8362), ('evidence', 8363), ('dating', 8364), ('landscapes', 8365), ('harm', 8366), ('.poor', 8367), ('ambition', 8368), ('eminently', 8369), ('exercise', 8370), ('your', 8371), ('induces', 8372), ('cheapo', 8373), ('damage', 8374), ('unusual', 8375), ('records', 8376), ('superstar', 8377), ('dickens', 8378), ('puts', 8379), ('edges', 8380), ('sibling', 8381), ('trapped', 8382), ('eerily', 8383), ('gangster', 8384), ('koepp', 8385), ('candid', 8386), ('nary', 8387), ('narratively', 8388), ('apparently', 8389), ('silliness', 8390), ('giant', 8391), ('climactic', 8392), ('thinness', 8393), ('sugary', 8394), ('sanguine', 8395), ('slow', 8396), ('1984', 8397), ('gosford', 8398), ('mountain', 8399), ('observant', 8400), ('persuasive', 8401), ('word', 8402), ('shop', 8403), ('harris', 8404), ('.blade', 8405), ('belongs', 8406), ('employs', 8407), ('hartley', 8408), ('fire', 8409), ('production', 8410), ('stop', 8411), ('priceless', 8412), ('uncomfortable', 8413), ('pants', 8414), ('new', 8415), ('chiefly', 8416), ('objectivity', 8417), ('destruction', 8418), ('released', 8419), ('lord', 8420), ('brash', 8421), ('irrepressible', 8422), ('host', 8423), ('random', 8424), ('blood-curdling', 8425), ('function', 8426), ('happened', 8427), ('ghosts', 8428), ('double', 8429), ('tattoo', 8430), ('portray', 8431), ('lead', 8432), ('imitation', 8433), ('turmoil', 8434), ('sassy', 8435), ('send', 8436), ('around', 8437), ('dani', 8438), ('irwin', 8439), ('realization', 8440), ('secret', 8441), ('watch', 8442), ('.rich', 8443), ('london', 8444), ('succumb', 8445), ('fragmentary', 8446), ('settle', 8447), ('.devos', 8448), ('signals', 8449), ('peploe', 8450), ('million', 8451), ('westbrook', 8452), ('.spider-man', 8453), ('abrupt', 8454), ('news', 8455), ('inexplicable', 8456), ('wisdom', 8457), ('speculative', 8458), ('de', 8459), ('junior', 8460), ('monty', 8461), ('typical', 8462), ('bourgeois', 8463), ('.broomfield', 8464), ('ferrara', 8465), ('alienation', 8466), ('facing', 8467), ('ambitious', 8468), ('candy', 8469), ('cq', 8470), ('somewhere', 8471), ('category', 8472), ('uncompromising', 8473), ('gyllenhaal', 8474), ('sentiment', 8475), ('intellectually', 8476), ('contrast', 8477), ('viewed', 8478), ('front', 8479), ('lobby', 8480), ('screwball', 8481), ('root', 8482), ('.williams', 8483), ('iii', 8484), ('clean', 8485), ('parents', 8486), ('wind', 8487), ('post-feminist', 8488), ('luridly', 8489), ('champion', 8490), ('morning', 8491), ('intact', 8492), ('manhood', 8493), ('no-brainer', 8494), ('atmosphere', 8495), ('.in', 8496), ('event', 8497), ('hurt', 8498), ('failings', 8499), ('flamboyant', 8500), ('ocean', 8501), ('stale', 8502), ('christian', 8503), ('aaliyah', 8504), ('plotline', 8505), ('panache', 8506), ('boy', 8507), ('good-looking', 8508), ('bent', 8509), ('eastern', 8510), ('folks', 8511), ('week', 8512), ('narrator', 8513), ('wound', 8514), ('subgenre', 8515), ('.ice', 8516), ('geriatric', 8517), ('brooks', 8518), ('jerking', 8519), ('riffs', 8520), ('.overall', 8521), ('metaphorical', 8522), ('.(', 8523), ('transporter', 8524), ('shock', 8525), ('errol', 8526), ('optimism', 8527), ('argument', 8528), ('opposed', 8529), ('labyrinthine', 8530), ('quitting', 8531), ('heart-wrenching', 8532), ('source', 8533), ('ill-fitting', 8534), ('penetrating', 8535), ('no-nonsense', 8536), ('sven', 8537), ('explain', 8538), ('triumphs', 8539), ('irksome', 8540), ('rush', 8541), ('.big', 8542), ('relief', 8543), ('achieves', 8544), ('conquer', 8545), ('undisputed', 8546), ('speed', 8547), ('brown', 8548), ('coast', 8549), ('ultra-violent', 8550), ('ethnic', 8551), ('vacuum', 8552), ('drang', 8553), ('references', 8554), ('characterized', 8555), ('jettisoned', 8556), ('adrian', 8557), ('accepts', 8558), ('crafty', 8559), ('tries', 8560), ('elvis', 8561), ('?i', 8562), ('scenes', 8563), ('vibe', 8564), ('liman', 8565), ('tackles', 8566), ('.exhilarating', 8567), ('embraces', 8568), ('velocity', 8569), ('verge', 8570), ('schwarzenegger', 8571)])"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83VZ5SVeulpH"
      },
      "source": [
        "def create_embedding_matrix(word2index,embedding_dict,dimension):\n",
        "    embedding_matrix=np.zeros((len(word2index),dimension))\n",
        "\n",
        "    for word,index in word2index.items():\n",
        "        if word in embedding_dict:\n",
        "            embedding_matrix[index]=embedding_dict[word]\n",
        "    return embedding_matrix\n",
        " \n",
        "# text=[\"The cat sat on mat\",\"we can play with model\"]\n",
        " \n",
        "# tokenizer=tf.keras.preprocessing.text.Tokenizer(split=\" \")\n",
        "# tokenizer.fit_on_texts(text)\n",
        " \n",
        "# text_token=tokenizer.texts_to_sequences(text)\n",
        " \n",
        "embedding_matrix=create_embedding_matrix(word2index=word2id,embedding_dict=glove_embedding,dimension=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1eGDMapsl7O",
        "outputId": "00f0ab1d-39e1-4feb-ac0a-8909962bb3d8"
      },
      "source": [
        "embedding_matrix.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8572"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaXIDkYPsl_W"
      },
      "source": [
        "vocab_size=embedding_matrix.shape[0]\n",
        "vector_size=embedding_matrix.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5AF78tes3yo",
        "outputId": "3c8f2037-66f2-40cc-9077-f5ad49b284d6"
      },
      "source": [
        "print(embedding_matrix.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8572, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZOa5dvNlInW"
      },
      "source": [
        "\n",
        " \n",
        "embedding=nn.Embedding(num_embeddings=vocab_size,embedding_dim=vector_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4du2eYslT8Y"
      },
      "source": [
        "embedding.weight=nn.Parameter(torch.tensor(embedding_matrix,dtype=torch.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6icVgpeOloDz"
      },
      "source": [
        "embedding.weight.requires_grad=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGh3Do7bukSh"
      },
      "source": [
        "# def get_tokens_ids(word2id, df, length=32):\n",
        "#     token_ids=[]\n",
        "#     labels=[]\n",
        "#     # corpus= list(df.sentence)\n",
        "#     targets = list(df.label)\n",
        "#     max_len=52\n",
        "\n",
        "# #     sent_tokens_= []\n",
        "#     for i in range(len(df)):\n",
        "#       sentence=df.sentence.iloc[i].lower()\n",
        "#       input_tokens = list(list(filter(('').__ne__, sentence.split(\" \"))))\n",
        "#       if max_len> len(input_tokens):\n",
        "#           max_len= len(input_tokens)\n",
        "# #        sent_tokens.append(input_tokens)\n",
        "#       input_ids=[word2id[word] if word in word2id else 1 for word in input_tokens]\n",
        "  \n",
        "#       if len(input_ids) < length:\n",
        "#           input_ids = input_ids + [0] * (length - len(input_ids)) # PAD tokens at the end\n",
        "#       else:\n",
        "#           input_ids = input_ids[:length]\n",
        "          \n",
        "#       token_ids.append(input_ids)\n",
        "#       labels.append(targets[i])\n",
        "#     token_ids =torch.LongTensor(token_ids)\n",
        "#     labels = torch.LongTensor(labels)\n",
        "#     return max_len, token_ids, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clNx5sLsukZk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "76ed78523e9f49d9aa33597d12814e17",
            "880c591e25e049a1b43b131cbcaeece4",
            "bd7fa21cef2a40a6895542fb5f9efc5c",
            "e1bd892d78544ffb981687bec0eb7fca",
            "57939930f8744c0f81754e704aa851c4",
            "9396f93d9ae74486a5bc5553e2e047c2",
            "643d6f34d22a45ec841020bf0b275584",
            "7b618d5d6e1d47ddb8c40b757bee2ead",
            "67454987b54140ecbe376830d8b02668",
            "9606c1fbb96542f1a35da57282af127e",
            "d87ab20d6ee44413a6ff95e2c0004a75"
          ]
        },
        "id": "LLA_kxcuzphS",
        "outputId": "823ea024-5865-4349-da8b-ccb7becfb668"
      },
      "source": [
        "sst_dataset = load_dataset('sst')\n",
        "\n",
        "\n",
        "train_df=pd.DataFrame.from_dict(sst_dataset['train'])\n",
        "train_df['label'] = train_df['label'].apply(lambda x: round(x))\n",
        "\n",
        "val_df=pd.DataFrame.from_dict(sst_dataset['validation'])\n",
        "val_df['label'] = val_df['label'].apply(lambda x: round(x))\n",
        "\n",
        "test_df=pd.DataFrame.from_dict(sst_dataset['test'])\n",
        "test_df['label'] = test_df['label'].apply(lambda x: round(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No config specified, defaulting to: sst/default\n",
            "Reusing dataset sst (/root/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76ed78523e9f49d9aa33597d12814e17",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSkBKHqyukfI",
        "outputId": "d45b491d-d6e6-440b-8ccf-98c6b4e95451"
      },
      "source": [
        "max_len, data, labels =get_tokens_ids(word2id, train_df, 32)\n",
        "val_max_len, val_data, val_labels =get_tokens_ids(word2id, val_df, 32)\n",
        "test_max_len, test_data, test_labels =get_tokens_ids(word2id, test_df, 32)\n",
        "# print(test_data.shape)\n",
        "# print(test_labels.shape)\n",
        "# print(test_max_len)\n",
        "# print(data.shape)\n",
        "# print(labels.shape)\n",
        "print(max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8tAMXvIlz9U",
        "outputId": "ac99edc9-4050-41df-c8a9-9f2c9d9d1dc8"
      },
      "source": [
        "embedding_vec=embedding(torch.LongTensor(data))\n",
        "print(embedding)\n",
        "print(embedding_vec.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding(8572, 100)\n",
            "torch.Size([8544, 32, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lhdg4ILCwYbi",
        "outputId": "c58f4db7-4d9f-4149-d86a-2aecf87ed6bd"
      },
      "source": [
        "embedding_vec[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        [-0.6839,  0.3918,  0.5367,  ..., -0.1415,  1.3115,  0.3148],\n",
              "        [-0.5426,  0.4148,  1.0322,  ..., -1.2969,  0.7622,  0.4635],\n",
              "        ...,\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.1381, -1.2345, -0.3397,  ..., -0.1517, -0.0621, -1.2900],\n",
              "        [ 0.6328, -0.5065, -0.3616,  ...,  0.1686,  0.0148, -0.7369]])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHwZpIyOt0aW"
      },
      "source": [
        "# train_set = TensorDataset(data, labels)\n",
        "# valid_set = TensorDataset(val_data, val_labels)\n",
        "# test_set = TensorDataset(test_data, test_labels)\n",
        "\n",
        "# batch_size = 32\n",
        "\n",
        "# train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
        "# valid_loader = DataLoader(valid_set, shuffle=True, batch_size=batch_size)\n",
        "# test_loader = DataLoader(test_set, shuffle=False, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQP0R-Pht0fy"
      },
      "source": [
        "import math\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, d, dropout = None):\n",
        "\n",
        "        super(LSTM, self).__init__()\n",
        "        self.input_size = d\n",
        "        self.hidden_size = d\n",
        "        self.output_size = 2\n",
        "        self.drop = dropout\n",
        "        self.embedding = nn.Embedding(len(vocab), self.input_size)\n",
        "        # i_t, c_t, f_t, o_t\n",
        "        self.W = nn.Parameter(torch.Tensor(self.input_size, self.hidden_size * 4))\n",
        "        self.U = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size * 4))\n",
        "        self.b = nn.Parameter(torch.Tensor(self.hidden_size * 4))\n",
        "\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.linear = nn.Linear(self.hidden_size, self.output_size, bias=True) \n",
        "        self.init_weights()\n",
        "        self.embedding.weight=nn.Parameter(torch.tensor(embedding_matrix,dtype=torch.float32))\n",
        "\n",
        "        \n",
        "        self.embedding.weight.requires_grad=False\n",
        "                \n",
        "    def init_weights(self):\n",
        "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for weight in self.parameters():\n",
        "            weight.data.uniform_(-stdv, stdv)\n",
        "         \n",
        "    def forward(self, x):\n",
        "\n",
        "        emb = self.embedding(x)\n",
        "        batch_size = emb.shape[0]\n",
        "\n",
        "        h_t, c_t = (torch.zeros(batch_size, self.hidden_size).to(emb.device), \n",
        "                        torch.zeros(batch_size, self.hidden_size).to(emb.device))\n",
        "          \n",
        "        ds = self.hidden_size\n",
        "        for t in range(emb.shape[1]):\n",
        "            emb_t = emb[:, t, :]\n",
        "            gate = emb_t @ self.W + h_t @ self.U + self.b\n",
        "            i_t, f_t, g_t, o_t = (\n",
        "                torch.sigmoid(gate[:, :ds]), \n",
        "                torch.sigmoid(gate[:, ds:ds*2]),  \n",
        "                torch.tanh(gate[:, ds*2:ds*3]),\n",
        "                torch.sigmoid(gate[:, ds*3:]), \n",
        "            )\n",
        "            c_t = f_t * c_t + i_t * g_t\n",
        "            h_t = o_t * torch.tanh(c_t)\n",
        "\n",
        "        if (self.drop != None):\n",
        "          h_t = self.dropout(h_t)\n",
        "          out = self.linear(h_t)\n",
        "        else:\n",
        "          out = self.linear(h_t)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXWkRurcYPGs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "9689c5de89f84b13985a2610d8a1d313",
            "24503e44982349f88202f2ac5f134c5d",
            "3e560d6f559946d38f3d83afafebbbff",
            "d794b264dc8d408da2bd626fe891dfa4",
            "4a3be46d5ba64e1f975d26a183de7a95",
            "9165b9e490b44d249910e7ce03b2d984",
            "6b8543c81b654904821020d377acc2b2",
            "743409abc24740f9934cda54d756aa62",
            "a78ca3fee82f4a9a939e7e16ebde8498",
            "e9240153b022496094e76eab5857c358",
            "90fdd4db3cbc48c88dd72ff03eeb8480"
          ]
        },
        "outputId": "46273be4-a92b-4796-e017-2b6c89717be3"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "sst_dataset = load_dataset('sst')\n",
        "\n",
        "\n",
        "train_df=pd.DataFrame.from_dict(sst_dataset['train'])\n",
        "train_df['label'] = train_df['label'].apply(lambda x: round(x))\n",
        "\n",
        "val_df=pd.DataFrame.from_dict(sst_dataset['validation'])\n",
        "val_df['label'] = val_df['label'].apply(lambda x: round(x))\n",
        "\n",
        "test_df=pd.DataFrame.from_dict(sst_dataset['test'])\n",
        "test_df['label'] = test_df['label'].apply(lambda x: round(x))\n",
        "\n",
        "max_len, data, labels =get_tokens_ids(word2id, train_df, 16)\n",
        "val_max_len, val_data, val_labels =get_tokens_ids(word2id, val_df, 16)\n",
        "test_max_len, test_data, test_labels =get_tokens_ids(word2id, test_df, 16)\n",
        "# print(test_data.shape)\n",
        "# print(test_labels.shape)\n",
        "# print(test_max_len)\n",
        "# print(data.shape)\n",
        "# print(labels.shape)\n",
        "print(max_len)\n",
        "\n",
        "\n",
        "train_set = TensorDataset(data, labels)\n",
        "valid_set = TensorDataset(val_data, val_labels)\n",
        "test_set = TensorDataset(test_data, test_labels)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_set, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_set, shuffle=False, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No config specified, defaulting to: sst/default\n",
            "Reusing dataset sst (/root/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9689c5de89f84b13985a2610d8a1d313",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uW1TcL1YPGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c63ad42e-a593-4ce3-b505-49a19e49a407"
      },
      "source": [
        "d = 100 # size of word-embedding\n",
        "num_epochs = 50\n",
        "model = LSTM(d).cuda()\n",
        "train(model, train_loader, valid_loader, num_epochs, 'glove_lstm_best_model.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:07<00:00, 38.07it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 128.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 50.70, Val_Acc- 50.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 38.69it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 133.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 49.58, Val_Acc- 52.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 38.99it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 137.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 52.10, Val_Acc- 49.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 39.24it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 135.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: Training_Loss- 0.022, Val_Loss- 0.022, Training_Acc- 52.24, Val_Acc- 53.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 38.43it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 136.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 54.99, Val_Acc- 57.49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 39.08it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 135.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5: Training_Loss- 0.021, Val_Loss- 0.022, Training_Acc- 57.78, Val_Acc- 57.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 39.24it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 139.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6: Training_Loss- 0.020, Val_Loss- 0.018, Training_Acc- 63.32, Val_Acc- 71.21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 38.58it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 129.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7: Training_Loss- 0.019, Val_Loss- 0.019, Training_Acc- 67.56, Val_Acc- 68.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:07<00:00, 37.98it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 134.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8: Training_Loss- 0.018, Val_Loss- 0.017, Training_Acc- 70.87, Val_Acc- 73.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 40.12it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 130.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9: Training_Loss- 0.017, Val_Loss- 0.017, Training_Acc- 71.66, Val_Acc- 73.66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 39.47it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 127.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10: Training_Loss- 0.017, Val_Loss- 0.017, Training_Acc- 71.91, Val_Acc- 74.11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 39.90it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 135.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 11: Training_Loss- 0.017, Val_Loss- 0.017, Training_Acc- 73.00, Val_Acc- 74.57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 40.39it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 138.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 12: Training_Loss- 0.017, Val_Loss- 0.016, Training_Acc- 73.30, Val_Acc- 75.39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 40.45it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 136.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 13: Training_Loss- 0.016, Val_Loss- 0.018, Training_Acc- 74.34, Val_Acc- 71.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 40.64it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 133.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 14: Training_Loss- 0.016, Val_Loss- 0.016, Training_Acc- 74.74, Val_Acc- 75.39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 40.44it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 144.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 15: Training_Loss- 0.016, Val_Loss- 0.017, Training_Acc- 74.78, Val_Acc- 75.02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 39.90it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 104.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 16: Training_Loss- 0.016, Val_Loss- 0.017, Training_Acc- 75.00, Val_Acc- 72.57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 40.26it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 137.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 17: Training_Loss- 0.016, Val_Loss- 0.016, Training_Acc- 76.16, Val_Acc- 76.29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 40.03it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 123.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 18: Training_Loss- 0.015, Val_Loss- 0.016, Training_Acc- 76.26, Val_Acc- 75.84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 39.39it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 137.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 19: Training_Loss- 0.015, Val_Loss- 0.016, Training_Acc- 76.23, Val_Acc- 76.02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 39.49it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 130.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 20: Training_Loss- 0.015, Val_Loss- 0.016, Training_Acc- 76.28, Val_Acc- 75.66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 39.59it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 137.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 21: Training_Loss- 0.015, Val_Loss- 0.017, Training_Acc- 76.07, Val_Acc- 72.21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 39.09it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 139.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 22: Training_Loss- 0.015, Val_Loss- 0.017, Training_Acc- 77.25, Val_Acc- 74.21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 39.84it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 126.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 23: Training_Loss- 0.015, Val_Loss- 0.016, Training_Acc- 76.84, Val_Acc- 76.29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 41.01it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 108.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 24: Training_Loss- 0.015, Val_Loss- 0.016, Training_Acc- 77.18, Val_Acc- 75.02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 40.45it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 143.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 25: Training_Loss- 0.015, Val_Loss- 0.016, Training_Acc- 77.08, Val_Acc- 74.66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 40.05it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 148.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 26: Training_Loss- 0.015, Val_Loss- 0.015, Training_Acc- 77.98, Val_Acc- 76.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 40.28it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 140.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 27: Training_Loss- 0.014, Val_Loss- 0.016, Training_Acc- 78.07, Val_Acc- 74.93\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 40.56it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 136.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 28: Training_Loss- 0.014, Val_Loss- 0.016, Training_Acc- 77.77, Val_Acc- 76.39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 39.45it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 123.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 29: Training_Loss- 0.014, Val_Loss- 0.016, Training_Acc- 78.50, Val_Acc- 75.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 39.22it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 128.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 30: Training_Loss- 0.014, Val_Loss- 0.018, Training_Acc- 78.48, Val_Acc- 70.21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 38.55it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 120.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 31: Training_Loss- 0.014, Val_Loss- 0.016, Training_Acc- 78.80, Val_Acc- 75.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 38.35it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 139.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 32: Training_Loss- 0.014, Val_Loss- 0.016, Training_Acc- 78.55, Val_Acc- 75.84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 39.14it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 127.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 33: Training_Loss- 0.014, Val_Loss- 0.016, Training_Acc- 79.03, Val_Acc- 76.29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 40.13it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 131.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 34: Training_Loss- 0.014, Val_Loss- 0.016, Training_Acc- 79.79, Val_Acc- 75.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 39.76it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 136.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 35: Training_Loss- 0.014, Val_Loss- 0.016, Training_Acc- 79.61, Val_Acc- 76.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 40.34it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 133.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 36: Training_Loss- 0.013, Val_Loss- 0.016, Training_Acc- 79.58, Val_Acc- 75.84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 39.70it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 128.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 37: Training_Loss- 0.013, Val_Loss- 0.016, Training_Acc- 80.27, Val_Acc- 76.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 40.37it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 135.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 38: Training_Loss- 0.013, Val_Loss- 0.016, Training_Acc- 80.13, Val_Acc- 75.66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 40.62it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 136.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 39: Training_Loss- 0.013, Val_Loss- 0.017, Training_Acc- 80.63, Val_Acc- 75.66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 39.18it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 133.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 40: Training_Loss- 0.013, Val_Loss- 0.016, Training_Acc- 80.81, Val_Acc- 75.84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 39.05it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 130.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 41: Training_Loss- 0.013, Val_Loss- 0.016, Training_Acc- 81.09, Val_Acc- 76.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 38.77it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 132.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 42: Training_Loss- 0.013, Val_Loss- 0.018, Training_Acc- 81.37, Val_Acc- 75.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 39.08it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 130.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 43: Training_Loss- 0.013, Val_Loss- 0.017, Training_Acc- 81.37, Val_Acc- 75.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 38.56it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 142.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 44: Training_Loss- 0.012, Val_Loss- 0.016, Training_Acc- 82.07, Val_Acc- 76.39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 38.99it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 136.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 45: Training_Loss- 0.012, Val_Loss- 0.016, Training_Acc- 82.14, Val_Acc- 75.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 38.76it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 128.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 46: Training_Loss- 0.012, Val_Loss- 0.017, Training_Acc- 82.33, Val_Acc- 75.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 39.22it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 126.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 47: Training_Loss- 0.012, Val_Loss- 0.017, Training_Acc- 82.27, Val_Acc- 74.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 38.51it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 133.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 48: Training_Loss- 0.012, Val_Loss- 0.018, Training_Acc- 83.12, Val_Acc- 74.21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [00:06<00:00, 38.47it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 133.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 49: Training_Loss- 0.012, Val_Loss- 0.018, Training_Acc- 83.31, Val_Acc- 76.02\n",
            "Best accuracy at epoch: 41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDrECw72YPGt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3086f2ce-3c51-430b-ce5d-3e468e1a1247"
      },
      "source": [
        "test(model, test_loader, file = 'glove_lstm_best_model.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [00:00<00:00, 113.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0162, Accuracy: 1722/2210 (77.92%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6NGWgyZYPGt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0169b394-49e9-4a96-f390-e617d683b1e0"
      },
      "source": [
        "test(model, valid_loader, file = 'glove_lstm_best_model.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:00<00:00, 106.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0164, Accuracy: 845/1101 (76.75%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0dXliqJYPGt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBOn8zzTQTVO"
      },
      "source": [
        "#### $\\color{red}{\\text{Solution 5.1}}$\n",
        "\n",
        "<font color='red'>We kept the same lstm model as in previous section then initialized the embedding matrix with the GLOVE embedding and frozen it during training. By doing so the model significantly outperformed the previous methods on validation and test dataset). The best performance has been obtained with sequence length set 24 which is 78.56% and 76.88 for validation and test respectively. Those result are obtained by training the model on local machine. By only using the pretrained embedding  representation we went from the worst model to the best model with LSTM<font>\n",
        "    \n",
        "Sequences length=52 validation accuracy =50.86 test accuracy=51.67 best epoch =45\n",
        "    \n",
        "Sequences length=40 validation accuracy =60.67 test accuracy=62.53 best epoch =33\n",
        "    \n",
        "Sequences length=32 validation accuracy =78.29 test accuracy=76.24 best epoch =50 \n",
        "    \n",
        "Sequences length=16 validation accuracy=76.75 test accuracy=777.92 best epoch =42\n",
        "    \n",
        "Sequences length=8 validation accuracy =69.75 test accuracy=70.27 best epoch =34 \n",
        "    \n",
        "Sequences length=24 validation accuracy =78.56 test accuracy=76.88 best epoch =30\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krhQwwjNloHz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV1FTPo5zprp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSCxYR2leG6S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NhXgVNkeG9b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJAH95q5eHAR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BHMlaYoZceC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}